chunk_id,chunk_source,chunk_text,question,answer
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '0f064687-3f51-7c2c-9ad1-d77b09f66b36', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA_7', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'MSFT_8']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ']",,
"['48cdef22-dce9-70f6-f48f-4ade4165f71b', 'a6816efd-0b2a-a798-f112-cf2ebc36aeb0', 'b7b86963-f371-4628-52cf-58dc3dc7d28f', 'c778838f-5a8e-29d9-7945-b1804ff1cc42', 'f322f75f-55d7-29ae-4045-d7ba8cd3153b']","['AMD_1A', 'Meta and Microsoft Introduce the Next Generation of Llama', 'How to Invest in Microsoft Stock (MSFT)', 'New Tools to Support Independent Research', 'AMD vs. Nvidia: How to choose the right graphics card for your PC']","['Update on February 15, 2024 at 7:00AM PT:\n\nWe want to make more data from our platforms available to academic researchers so they can pursue public interest research, while doing so in a way that respects both people’s privacy and our compliance obligations.\n\nIn the months since we rolled out our Meta Content Library tool we’ve been gathering feedback from researchers to ensure the sort of publicly-accessible data they need is available to them in a way that’s effective for their research. Based on that feedback, we are adding some new data and features.\n\nOne of the biggest requests was to make content from public figures more accessible to researchers so it is easier to study the impact their activity on Facebook and Instagram has on politics, society and culture. So, in the coming weeks, we’re making it possible for researchers to download certain publicly-accessible content posted by public figures and widely-known figures and entities. This data will be accessible in a downloadable CSV format through the Meta Content Library user interface and won’t require access through a virtual clean room.\n\nIn the next few months, we’ll also be adding ‘comments’ as a new data type within the Meta Content Library. This will help researchers study how people around the world receive, discuss and reinterpret content across publicly-accessible pages and posts. We’ll be starting with comments from public forums on Facebook, which researchers will be able to analyze within ICPSR’s virtual clean room.\n\nOur Third Party Fact-Checking partners will also have access to Meta Content Library to help them investigate and debunk misinformation. We hope these powerful search capabilities will help them do this more efficiently, particularly during key moments such as elections.\n\nOriginally published on November 21, 2023 at 3:00AM PT:\n\nTo understand the impact social media apps like Facebook and Instagram have on the world, it’s important to support rigorous, independent research. That’s why Meta has been committed to an open and privacy-protective approach to research for many years, including making tools available to support public interest research, such as the US 2020 studies.\n\nOver the past few months we gave Beta access to our new Meta Content Library and API tools. After multiple rounds of feedback with researchers and other stakeholders, we are now in a position to roll these tools out more broadly.\n\nMeta Content Library & API\n\nOur Meta Content Library and API tools provide access to near real-time public content from Pages, Posts, Groups and Events on Facebook, as well as from creator and business accounts on Instagram. Details about the content, such as the number of reactions, shares, comments and, for the first time, post view counts are also available. Researchers can search, explore and filter that content on both a graphical User Interface (UI) or through a programmatic API.\n\nTogether, these tools provide the most comprehensive access to publicly-available content across Facebook and Instagram of any research tool we have built to date. They also help us meet new regulatory requirements, data-sharing and transparency compliance obligations. Introducing these tools to researchers early in the development process gave us the opportunity to improve them before making them more widely available. We will continue to make improvements as we collect more feedback from researchers.\n\nIndividuals from qualified institutions pursuing scientific or public interest research topics will be able to apply for access to these tools through partners with deep expertise in secure data sharing for research, starting with the University of Michigan’s Inter-university Consortium for Political and Social Research. This is a first-of-its-kind partnership that will enable researchers to analyze data from the API in ICPSR’s Social Media Archive’s (SOMAR) Virtual Data Enclave.\n\nSocial Capital Research\n\nLast year, in collaboration with Raj Chetty and Harvard’s Opportunity Insights Program, we released a landmark study to measure the drivers of economic mobility in the US using information from 21 billion friendships on Facebook, which found that social connections play an important role in helping communities rise out of poverty.\n\nWe’re now expanding this research program with Harvard to better understand the drivers of economic mobility around the world by using insights from our platform on the dynamics of social networks, as well as publicly available data on socioeconomics and schools. We plan to examine cross-class friendships across the United Kingdom in collaboration with experts at the Behavioural Insights Team, Royal Society of Arts, Stripe Partners and Neighbourly Lab.\n\nAs well as expanding to more countries, we also plan to do more research into the role social connections play in economic opportunity including business creation, attending college, and getting a job. Building on our work looking at how social connections benefit people, we will continue to study how social networks help communities recover from crises and help displaced populations and migrants.', 'For example, our Client segment revenue decreased due to a decline in the PC market in the second half of 2022 and the first half of 2023, and our Embedded segment revenue decreased as a result of an inventory correction in several end markets in the second half of 2023. We may build inventories during periods of anticipated growth, and the cancellation or deferral of product orders or overproduction due to failure of anticipated orders to materialize could result in excess or obsolete inventory, which could result in write-downs of inventory and an adverse effect on gross margins. Our customers may also experience a shortage of, or delay in receiving certain components to build their products, which in turn may affect the demand for or the timing of our products. For instance, OEMs have and continue to experience industry-wide challenges securing matched component sets to build their products. Excess or obsolete inventory have resulted in, and may in the future result in, write-downs of the value of our inventory. For example, in the third quarter of 2022, we recorded certain charges primarily for inventory, pricing and related reserves in the Gaming and Client segments. Factors that may result in excess or obsolete inventory, a reduction in the average selling price, or a reduction in our gross margin include: a sudden or significant decrease in demand for our products; a production or design defect in our products; a higher incidence of inventory obsolescence because of rapidly changing technology and customer requirements; a failure to accurately estimate customer demand for our products, including for our older products as our new products are introduced; or our competitors introducing new products or taking aggressive pricing actions. Our ability to design and introduce new products in a timely manner includes the use of third-party intellectual property. In the design and development of new and enhanced products, we rely on third-party intellectual property such as development and testing tools for software and hardware. Furthermore, certain product features may rely on intellectual property acquired from third parties that incorporate into our software or hardware. The design requirements necessary to meet customer demand for more features and greater functionality from semiconductor products may exceed the capabilities of the third-party intellectual property or development or testing tools available to us. If the third-party intellectual property that we use becomes unavailable, is not available with required functionality or performance in the time frame, manufacturing technology, or price point needed for our new products or fails to produce designs that meet customer demands, or laws are adopted that affect our use of third party intellectual property in certain regions or products, our business could be materially adversely affected. We depend on third-party companies for the design, manufacture and supply of motherboards, software, memory and other computer platform components to support our business and products. We depend on third-party companies for the design, manufacture and supply of motherboards, graphics cards, software (e.g., BIOS, operating systems, drivers), memory and other components that we use to design, support and sell, and our customers utilize to support and/or use our product offerings. We also rely on our AIB partners to support our products. In addition, our microprocessors are not designed to function with motherboards and chipsets designed to work with Intel microprocessors. If the designers, manufacturers, AIBs and suppliers of motherboards, graphics cards, software, memory and other components cease or reduce their design, manufacture or production of current or future products that are based on, utilized in, or support our products, or laws are adopted that result in the same, our business could be materially adversely affected. If we lose Microsoft Corporation&#8217;s support for our products or other software vendors do not design and develop software to run on our products, our ability to sell our products could be materially adversely affected. Our ability to innovate beyond the x86 instruction set controlled by Intel depends partially on Microsoft designing and developing its operating systems to run on or support our x86-based microprocessor products. With respect to our graphics products, we depend in part on Microsoft to design and develop its operating system to run on or support our graphics products. Similarly, the success of our products in the market, such as our APU products, is dependent on independent software providers designing and developing software to run on our products. If Microsoft does not continue to design and develop its operating systems so that they work with our x86 instruction sets or does not continue to develop and maintain their operating systems to support our graphics products, independent software providers may forego designing their software applications to take advantage of our innovations and customers may not purchase PCs with our products. In addition, some software drivers licensed for use with our products are certified by Microsoft. If Microsoft did not certify a driver, or if we otherwise fail to retain the support of Microsoft or other software vendors, our ability to market our products would be materially adversely affected. Our reliance on third-party distributors and AIB partners subjects us to certain risks. We market and sell our products directly and through third-party distributors and AIB partners pursuant to agreements that can generally be terminated for convenience by either party upon prior notice. These agreements are non-exclusive and permit both our distributors and AIB partners to offer our competitors&#8217; products. We are dependent on our distributors and AIB partners to supplement our direct marketing and sales efforts. If any significant distributor or AIB partner or a substantial number of our distributors or AIB partners terminated their relationship with us, decided to market our competitors&#8217; products over our products or decided not to market our products at all, our ability to bring our products to market would be impacted and we would be materially adversely affected. We extend credit to certain of our distributors and AIB partners. If we are unable to collect accounts receivable from our significant distributors and/or AIB partners or incur higher allowances for credit losses, it could have a material adverse effect on our business. ', 'Recent breakthroughs in AI, and generative AI in particular, have captured the public’s imagination and demonstrated what those developing these technologies have long known — they have the potential to help people do incredible things, create a new era of economic and social opportunities, and give individuals, creators, and businesses new ways to express themselves and connect with people.\n\nWe believe an open approach is the right one for the development of today’s AI models, especially those in the generative space where the technology is rapidly advancing. By making AI models available openly, they can benefit everyone. Giving businesses, startups, entrepreneurs, and researchers access to tools developed at a scale that would be challenging to build themselves, backed by computing power they might not otherwise access, will open up a world of opportunities for them to experiment, innovate in exciting ways, and ultimately benefit from economically and socially.\n\nAnd we believe it’s safer. Opening access to today’s AI models means a generation of developers and researchers can stress test them, identifying and solving problems fast, as a community. By seeing how these tools are used by others, our own teams can learn from them, improve those tools, and fix vulnerabilities.\n\nMeta has put exploratory research, open source, and collaboration with academic and industry partners at the heart of our AI efforts for over a decade. We’ve seen first-hand how innovation in the open can lead to technologies that benefit more people. Dozens of large language models have already been released and are driving progress by developers and researchers. They’re being used by businesses as core ingredients for new generative AI-powered experiences. We’ve been blown away by the huge demand for Llama 1 from researchers — with more than 100,000 requests for access to the large language model — and the amazing things they’ve achieved by building on top of it.\n\nWe’re now ready to open source the next version of Llama 2 and are making it available free of charge for research and commercial use. We’re including model weights and starting code for the pretrained model and conversational fine-tuned versions too. As Satya Nadella announced on stage at Microsoft Inspire, we’re taking our partnership to the next level with Microsoft as our preferred partner for Llama 2 and expanding our efforts in generative AI. Starting today, Llama 2 is available in the Azure AI model catalog, enabling developers using Microsoft Azure to build with it and leverage their cloud-native tools for content filtering and safety features. It is also optimized to run locally on Windows, giving developers a seamless workflow as they bring generative AI experiences to customers across different platforms. Llama 2 is available through Amazon Web Services (AWS), Hugging Face, and other providers too.\n\nPeople and businesses have benefited from the longstanding partnership between Microsoft and Meta. Together we’ve introduced an open ecosystem for interchangeable AI frameworks, and we’ve co-authored research papers to advance the state of the art in AI. We’ve collaborated to scale the adoption of PyTorch — today’s leading AI framework created by Meta and the AI community — on Azure, and we’re among the founding members of the PyTorch Foundation. Microsoft and Meta recently joined a cohort of supporters that endorse the Partnership on AI’s framework for collective action in the creation and sharing of synthetic media. Our partnership extends outside of AI and into the metaverse too to deliver immersive experiences for the future of work and play.\n\nNow, with this expanded partnership, Microsoft and Meta are supporting an open approach to provide increased access to foundational AI technologies to the benefits of businesses globally. It’s not just Meta and Microsoft that believe in democratizing access to today’s AI models. We have a broad range of diverse supporters around the world who believe in this approach too — including companies that have given us early feedback and are excited to build new products with Llama 2, cloud providers that will include Llama 2 in their offerings for customers, research institutions who are collaborating with us on the safe and responsible deployment of large generative models, and people across tech, academia, and policy who see the benefits as we do.\n\nA Focus on Responsibility\n\nOur open source approach promotes transparency and access. We know that while AI has brought huge advances to society, it also comes with risk. We are committed to building responsibly and are providing a number of resources to help those who use Llama 2 do so too.\n\nRed-Teaming Exercises: Our fine-tuned models have been red-teamed — tested for safety — through internal and external efforts. The team worked to generate adversarial prompts to facilitate model fine-tuning. In addition, we commissioned third parties to conduct external adversarial testing across our fine-tuned models to similarly identify gaps in performance. These safety fine-tuning processes are iterative; we will continue to invest in safety through fine-tuning and benchmarking and plan to release updated fine-tuned models based on these efforts.\n\nTransparency Schematic: We explain our fine-tuning and evaluation methods for the model and identify its shortcomings. Our transparency schematic, which is located within the research paper , discloses known challenges and issues we’ve experienced and provides insight into mitigations taken and future ones we intend to explore.\n\nResponsible Use Guide: We created this guide as a resource to support developers with best practices for responsible development and safety evaluations. It outlines best practices reflective of current, state-of-the-art research on responsible generative AI discussed across the industry and the AI research community.\n\nAcceptable Use Policy: We put a policy in place that prohibits certain use cases to help ensure that these models are being used fairly and responsibly.\n\nMeta has also created new initiatives to harness the insight and creativity of individuals, researchers, and developers around the world to get feedback on how the models are performing and how they might be improved.\n\nOpen Innovation AI Research Community: Today, we also launched a new partnership program for academic researchers that aims to deepen our understanding of the responsible development and sharing of large language models. Researchers may apply to join a community of practitioners to share learnings on this important topic, and the community will form a research agenda to pursue going forward.\n\nLlama Impact Challenge: We want to activate the community of innovators who aspire to use Llama to solve hard problems. We are launching a challenge to encourage a diverse set of public, non-profit, and for-profit entities to use Llama 2 to address environmental, education and other important challenges. The challenge rules will be available prior to the start of it.\n\nConclusion\n\nThroughout our company’s history, we’ve experienced the benefits of an open source approach when innovating in other areas of the business. Our engineers developed and shared frameworks that are now industry standards — like React, a leading framework for making web and mobile applications, and PyTorch, which is now the leading framework for AI. These became commonly used infrastructure for the entire technology industry. We believe that openly sharing today’s large language models will support the development of helpful and safer generative AI too.\n\nWe look forward to seeing what the world builds with Llama 2.', ""When you buy through our links, Business Insider may earn an affiliate commission. Learn more\n\nIn the world of PC gaming, AMD and Nvidia dominate the graphics card market. Whether it's a custom computer or a pre-built model, a graphics card is essential for rendering games in high quality, and cards from either Nvidia or AMD are what you'll find in all of the best gaming PCs and best gaming laptops.\n\nBoth brands offer a range of graphics cards with entry-level models starting at around $270 and high-end cards costing $1,500 or more. AMD and Nvidia also allow other manufacturers to sell third-party versions of their cards based on their original specs. This can create price variations among models with similar capabilities, since third-party manufacturers may add features like extra fans or lighting.\n\nWhile there are lots of graphics cards to choose from, it's still possible to compare each brand's overall performance in relation to their price. Premium Nvidia graphics cards are typically viewed as the most powerful when it comes to advanced features, while the best AMD cards have a reputation for being significantly more affordable and energy efficient.\n\nBelow, we've broken down details on all the latest graphics cards from Nvidia and AMD, and compare how they stack up.\n\nAdvertisement\n\nAMD vs. Nvidia: Price and features\n\nAMD and Nvidia both offer a range of graphics cards for different budgets and performance needs. Nvidia's current lineup is called the GeForce RTX 40 series, while AMD's lineup is called the Radeon RX 7000 series. Here's a rundown of each series.\n\nNote: The cards listed below are for desktop computers. Both brands also make mobile versions of their cards that PC manufacturers can integrate into their gaming laptops, but performance may vary.\n\nAdvertisement\n\nNvidia GeForce RTX 40 series graphics cards\n\nThe Nvidia GeForce RTX 4090 is the company's most powerful graphics card. Nvidia\n\nNvidia's RTX 40 series debuted in fall 2022 with the release of the flagship GeForce RTX 4080 ($1,199) and the premium RTX 4090 ($1,599); four more affordable RTX 40 series cards arrived in 2023.\n\nRTX 40 series cards share a wide range of features, including raytracing, an advanced lighting feature that requires a compatible graphics card, and DLSS 3.0, the latest version of Nvidia's AI-enhanced upscaling technology that makes games easier to run at high frame rates.\n\nOther Nvidia features are designed to benefit content creators; RTX cards include support for AI-based noise removal for your microphone and virtual backgrounds for your webcam, as well as face tracking and auto-focus. However, AMD reports that its graphics cards actually render video faster than the RTX 40 series with common editing programs like Adobe Premiere Pro and DaVinci Resolve Studio.\n\nAdvertisement\n\nAMD Radeon RX 7000 series graphics cards\n\nAn AMD Radeon RX 7000 series card being used with an AMD Ryzen CPU. XFX\n\nAMD launched the Radeon RX 7000 series of graphics cards in December 2022 with the RX 7900 XT ($899) and 7900 XTX ($999), followed by the release of several lower priced cards in 2023, including the 7700XT and 7800XT which are set to launch on September 6.\n\nAMD cards offer similar performance to Nvidia cards in most games, and usually for a lower price. For example, Tom's Hardware ranks the RX 7900 XT ($999) ahead of the RTX 4080 ($1,199) in terms of overall performance, despite the AMD card typically being $200 cheaper. However, Nvidia cards tend to reveal bigger advantages when you play newer games with more advanced graphical features.\n\nLike the RTX 40 series, AMD's RX 7000 cards do feature ray tracing, but ray tracing performance generally lags behind the RTX 40 series with slower frame rates. The RX 7000 series also has an AI-based rendering feature to improve frame rates, called FSR, but it's not quite as developed as Nvidia's DLSS.\n\nIf you're looking to play newer releases like Cyberpunk 2077 or Allen Wake 2, a weaker AMD card may struggle to deliver graphics at the highest possible quality. That said, AMD does partner with some developers to boost performance on AMD hardware; for example, Microsoft's Starfield was designed with support for AMD's FSR at release, but not DLSS.\n\nAMD also supports a feature called Smart Access Memory to improve performance when you pair its latest CPUs and GPUs together. This feature allows the CPU to use more of the graphics card's memory. However, some Nvidia and Intel hardware can take advantage of a similar feature, called Resizable Bar, so the underlying tech isn't AMD exclusive.\n\nAMD benchmark data that shows RX 7000 graphics cards outperforming Nvidia hardware exclusively use AMD processors during testing, so if you have an Intel processor, you may want to look at publicly sourced benchmarks before buying an AMD card.\n\n*The target resolution and refresh rates for each graphics card were determined based on benchmarks shared by Nvidia, AMD, and crowd sourced data from the public. The maximum frame rate and resolution possible with each card will vary based on the game.\n\nAdvertisement\n\nAMD vs. Nvidia: Which graphics card should you choose?\n\nUltimately, choosing between an AMD or Nvidia graphics card comes down to your personal needs, budget, and preferences. Those building their own PC with a smaller budget may prefer the affordability of AMD graphics cards, while those willing to pay more to play brand-new games with graphics that can best the PlayStation 5 or Xbox Series X will likely want an Nvidia 4080 or 4090 card to maximize performance.\n\nOf course, high-end AMD cards like the RX 7900 XT or RX 7900 XTX are still capable of playing the latest releases, but Nvidia's top models have an edge when you enable advanced features like ray tracing.\n\nFAQs\n\nAdvertisement\n\nWhat should you know before buying a graphics card?\n\nBefore you buy any graphics card, you should make sure that it's a good fit for your computer. Using an older CPU or motherboard with a brand-new graphics card can limit your overall performance and create bottlenecks that prevent you from getting the most out of your card.\n\nCheck that your motherboard supports the latest specifications, like PCIe 4.0. Newer graphics cards also demand lots of power, so make sure your power supply has enough juice to keep your computer running.\n\nFinally, always measure the inside of your case to make sure the graphics card will physically fit during installation, as different cases can position the graphics card at different angles. Different manufacturers also make different sized versions of the same graphics card to add extra fans or lighting."", '3 Most Important Financial Statements\n\nEmotions in Investing: How to Manage Stock Market Anxiety & Stress\n\nFutures Trading: Everything You Need to Know\n\nFor Investors: Business Valuation 101\n\n11 Up-and-Coming Stocks to Invest In\n\nWhen to Sell Stocks — for Profit or Loss\n\nAccounts That Earn Compounding Interest\n\nHow Many Shares Should I Buy of a Stock?\n\nSelling Stock: How Capital Gains Are Taxed\n\nMarket Order vs. Limit Order\n\nHow Are Stock Prices Determined?\n\nWhat Is a Good Return on Investment?\n\nDay Trading Definition: Why It Differs From Investing\n\nThe Definitive Guide: How to Value a Stock\n\nWhat Happens When a Stock Is Delisted?\n\nGAAP vs. Non-GAAP: Everything You Need to Know\n\nShould I Buy Stock Now or Wait?\n\nA Beginner\'s Guide to Understanding Financial News\n\nTechnical Analysis for the Long-Term Investor\n\nHow to Calculate Cost Basis for Inherited Stock\n\nWhat Are Share Repurchases?\n\nHow to Research Stocks\n\nAverage Stock Market Return\n\nHow to Short a Stock\n\nStock vs. Share: What\'s the Difference?\n\nHow to Find Investment Ideas\n\nInvestment Strategies for the Long Term\n\nWhat is the Difference Between Simple & Compound Interest?\n\nWhy Is It Important to Invest in Stocks?\n\nWhat Makes a Stock Price Go Up?\n\nHow to Pick a Stock for the First Time\n\nCan You Owe Money on Stocks?\n\nOptions vs. Stocks: What\'s the Difference?\n\nTaxes on Investments: Understanding the Basics\n\nHow Many Stocks Should You Own?\n\nSocially Responsible Investing\n\nHow to Gift Stock\n\nHow to Invest in Stocks: A Step-by-Step Guide\n\nHow to Calculate Volatility of a Stock\n\nHow to Calculate Total Stock Returns\n\nHow to Calculate Take-Home Pay\n\nTax Loss Harvesting\n\nHow to Invest in Amazon Stock\n\nHow to Invest in Tesla Stock\n\nHow to Buy Nvidia Stock (NVDA)\n\nHow to Invest in Disney Stock\n\nHow to Invest in Google Stock\n\nHow to Invest in Berkshire Hathaway Stock\n\nHow to Invest in Johnson & Johnson Stock\n\nHow to Invest in Exxon Stock\n\nHow to Invest in Facebook Stock\n\nHow to Invest in Stripe\n\nHow to Invest in Apple Stock\n\nHow to Invest in Databricks\n\nHow to Invest in Epic Games\n\nHow to Invest in Ford Stock\n\nHow to Invest in PayPal Stock\n\nHow to Invest in Etsy Stock\n\nHow to Buy Pinterest Stock in 2024\n\nHow to Invest in Block Stock\n\nHow to Invest in OpenAI\n\nHow to Invest in SpaceX in 2024\n\nHow to Invest in Mistral AI in 2024\n\nHow to Invest in C3.ai\n\nHow to Invest in Shopify in 2024\n\nHow to Invest in Costco in 2024\n\nHow to Invest in Netflix in 2024\n\nHow to Invest in Aldi in 2024\n\nHere\'s How to Calculate Future Expected Stock Price\n\nConverting Daily Returns to Annual Returns: Formula, Process, and Example\n\nHow to Calculate Average Stock Price: A Step-By-Step Guide\n\nMillion-Dollar Portfolio: How to Get There\n\nBest Master Limited Partnership Stocks to Buy in 2024\n\nUpcoming Stock Splits to Pay Attention to\n\nApple\'s Stock Split History\n\nCall vs. Put Options\n\nHow to Trade Options\n\nFutures vs. Options: What\'s the Difference?\n\nUnderstanding the Differences Between GAAP and IFRS\n\nHow to Invest in Reddit Stock\n\nHow to Invest in Coca-Cola Stock (NYSE:KO)\n\nHow to Invest in Discord\n\nHow to Invest in Twilio Stock\n\nHow to Invest in Upstart\n\nHow to Invest in Intuitive Surgical\n\nHow to Invest in Carnival Cruise Lines\n\nHow to Invest in Rivian\n\nHow to Invest in SoFi Stock\n\nHow to Invest in Plug\n\nHow to Invest in CRISPR Therapeutics Stock\n\nHow to Invest in Cava\n\nHow to Invest in Nio\n\nHow to Invest in Advanced Micro Devices\n\nHow to Invest in Nu Holdings\n\nHow to Invest in Palantir Technologies Stock\n\nHow to Invest in Coinbase Stock\n\nHow to Invest in AT&T Stock\n\nHow to Invest in Pepsi Stock\n\nHow to Invest in Walmart (NYSE:WMT)\n\nHow to Invest in Palo Alto Networks Stock\n\nHow to Invest in Arm Stock\n\nHow to Invest in Instacart\n\nHow to Invest in Klarna Stock\n\nHow to Invest in The Boring Company\n\nHow to Invest in Rippling Stock Pre-IPO\n\nHow to Invest in Blue Origin\n\nHow to Invest in Upside Foods\n\nHow to Invest in Zipline\n\nNeuralink Stock: How to Invest Before the IPO\n\nInvesting in Ripple Stock\n\nHow to Invest in Canva\n\nHow to Invest in Fanatics Stock\n\nHow to Invest in Revolut\n\nHow to Invest in Chime Stock\n\nHow to Invest in Impossible Foods\n\nHow to Invest in Forge Global\n\nHow to Invest in Tilray Stock\n\nHow to Invest in AMC\n\nHow to Invest in General Electric (GE)\n\nHow to Invest in Northrop Grumman (NOC)\n\nHow to Invest in Boeing\n\nHow to Invest in Kenvue\n\nHow to Invest in Bank of America\n\nHow to Invest in Comcast\n\nHow to Invest in Snap\n\nHow to Invest in QuantumScape\n\nHow to Invest in Lockheed Martin\n\nHow to Invest in Birkenstock\n\nHow to Invest in Snowflake\n\nHow to Invest in Taiwan Semiconductor\n\nYour Guide to Investing: ""Magnificent Seven"" Stocks\n\nHow to Invest in Intel\n\nHow to Invest in IBM\n\nHow to Invest in Liquid Death\n\nHow to Invest in Northvolt\n\nHow to Invest in Flexport in 2024\n\nHow to Invest in Nikola\n\nHow to Invest in Verizon in 2024\n\nHow to Invest in Skims in 2024\n\nHow to Invest in Waystar Technologies\n\nHow to Invest in BMC Software\n\nHow to Invest in Unity Software\n\nHow to Invest in Canopy Growth\n\nSHEIN IPO: Investing in SHEIN\n\nHow to Invest in Panera Bread\n\nHow to Invest in Starlink in 2024\n\nHow to Invest in Publix\n\nHow to Invest in Ikea\n\nHow to Invest in Marvel\n\nHow to Invest in Deloitte\n\nHow to Invest in Cargill\n\nHow to Invest in Lyft\n\nHow to Invest in Uber\n\nHow to Invest in Mars Stock\n\nHow to Invest in H-E-B Grocery\n\nWhat Does Disney Own?\n\nWhat Does Coca-Cola Own?\n\nWhat Does Pepsi Own?\n\nWhat Does Procter & Gamble Own?\n\nWhat Does Altria Own?\n\nBuying Trader Joe\'s Stock: Is It Public?\n\nHow to Invest in the Lego Company\n\nHow to Invest in the NFL\n\nHow to Invest in Hulu Stock\n\nHow to Invest in Arctic Wolf\n\nHow to Invest in Rubrik Pre-IPO\n\nHow to Invest in ServiceTitan Pre-IPO\n\nHow to Invest in Checkout.com Pre-IPO\n\nHow to Invest in Plaid Pre-IPO\n\nHow to Invest in Redwood Materials Stock\n\nWhat Happens to the Ownership of Stocks After a Person Dies?']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '37338206-39d2-f336-4501-4a46adb2ee1c', '591c2bb5-1433-43c4-3c95-43e8b4164fba', '6dfdcb26-c454-0d98-c37c-324dd95f3039', 'ffe46ef0-5a92-9ff9-8fb1-c56744912b45']","['AMD Unveils Ryzen Mobile 7040U Series: Phoenix To Fly Into Thin Notebooks', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'MSFT_8', 'AMD Powers Hitachi Astemo Next-Generation Forward Camera System for Enhanced Vehicle Safety Through AI Object Detection']","[""Back at CES 2023, AMD announced the first wave of Ryzen Mobile parts based on its Zen 4 architecture, the Ryzen Mobile 7040HS series. Based on AMD's Phoenix silicon, which uses TSMC's 4 nm process node to mix Zen 4 CPU cores with AMD's RDNA 3 graphics compute units all in a single, monolithic die, Phoenix is the next generation of high efficiency, highly-integrated AMD silicon. And today, AMD is revealing that Phoenix is going to spread its wings a little farther, with the announcement of the Ryzen Mobile 7040U series for ultraportable notebooks.\n\nBringing AMD's latest generation technologies down to the thin and light laptop market, the Ryzen Mobile 7040U series follows AMD's traditional cascading launch mobile launch strategy, delivering new silicon into increasingly lower powered devices as chip production ramps up and OEMs finish putting together new designs. Whereas the original 7040HS series is aimed at higher-power, higher performing laptops, the 7040U series tunes the same same silicon for more modest TDPs in the 15 Watt to 30 Watt range, making it better suited for use in ultraportable thin and light laptops – and fully exploiting the efficiency advantages of Zen 4.\n\nWe've been expecting the Ryzen Mobile 7040U series for quite some time now – AMD made it clear as far back as CES that a traditional U-series lineup was in the works, but until now we just didn't know when to expect it. Though considering that you still can't buy a 7040HS laptop today, today's 7040U announcement from AMD should not be taken as a sign that 7040U laptops are going to be on retail shelves any time in the immediate future.\n\nAMD Ryzen 7040U Series: Up to 8-Cores With RDNA 3 Graphics\n\nAMD's Ryzen Mobile 7040 series spans multiple key mobile product categories, ranging from the entry-level, which AMD segments as 'everyday computing' to its 'extreme gaming and creator' lineup for high-end and powerful gaming laptops. At the bottom of AMD's Pheonix Point series for mobile, the new AMD Ryzen Mobile 7040U series is comprised of four SKUs, which range from 8-core parts down to 4-cores; all of which include AMD's RDNA 3 integrated graphics. Phoenix also introduces AMD's Ryzen AI technology, an FPGA-based AI engine developed by Xilinx, which AMD claims are the first AI processor of its kind and is designed to accelerate AI workloads.\n\nAs they announced at CES 2023, AMD has updated its mobile naming scheme to make it somewhat easier for users to decipher what all the digits and characters in the product name mean. For the Ryzen Mobile 7040U series, the first digit represents the model year, with 7 being used for 2023, while the second digit represents the market segment, e.g., Ryzen 7 = 7, Ryzen 5 = 5/6, and Ryzen 3 = 3/4. The third digit (4) represents the CPU architecture of the product, so in the case of the 7040, it uses its latest Zen 4 cores.\n\nThe last character (suffix) is perhaps the most important indicator of the market segment, as it relates to the TDP and form factor, as the U relates to being a 15-30 W part. For those of you playing at home, this is a slight increase in the TDP window over previous generations – where the U series was 15-28 W – though with laptop vendors able to set their TDPs wherever they like, official TDPs are more of loose guidelines these days anyhow.\n\nAMD Ryzen 7040U Mobile CPUs (Phoenix 4nm) AnandTech C/T Base\n\nFreq (MHz) Turbo\n\nFreq\n\n(MHz) iGPU iGPU CUs iGPU Freq L3 Cache\n\n(MB) TDP Ryzen 7 7840U 8/16 3300 5100 Radeon 780M 12 Up to 2.7 GHz 16 15-30W Ryzen 5 7640U 6/12 3500 4900 Radeon 760M 8 Up to 2.6 GHz 16 15-30W Ryzen 5 7540U 6/12 3200 4900 Radeon 740M 4 Up to 2.5 GHz 16 15-30W Ryzen 3 7440U 4/8 3000 4700 Radeon 740M 4 Up to 2.5 GHz 8 15-30W\n\nLooking at the four Ryzen 7040U SKUs for thin and light AMD-based notebooks, all four of its 'Pheonix' based APUs include AMD's RDNA 3 Radeon 700M series integrated graphics. Starting with the premier model, the Ryzen 7 7840U is an 8C/16T part with a base frequency of 3.3 GHz and a turbo frequency of up to 5.1 GHz. It has a combined total cache of 24 MB, with 16 MB of L3 cache for the entire chip and 1 MB of L2 cache per core, for a total of 8 MB of L2 cache.\n\nMoving down the stack is a pair of Ryzen 5 models, the Ryzen 5 7640U and Ryzen 7540U, both of which include 6 CPU cores. The Ryzen 5 7640U is the faster of the two chips, with a 300 MHz bump on CPU base frequency over the 7540U (3.5 v.s 3.2 GHz), though both APUs have a turbo frequency of up to 4.9 GHz. Curiously, AMD is also using this point as the dividing line between what parts do or do not get the Ryzen AI co-processor; the upper-tier 7640U comes with it, but the lower-tier 7540U does not. Past that, the Ryzen 5 7640U and Ryzen 5 7540U are 6-core parts, so they have 16 MB of L3 cache and 6 MB of L2 cache.\n\nAs these are Ryzen 5 mobile Zen 4 APUs, they include AMD's Radeon 700M graphics. The Ryzen 5 7640U has the better iGPU of the two, with the Radeon 760M with 8 CUs with a maximum frequency of up to 2.6 GHz. In comparison, the Ryzen 5 7540U has the lower spec Radeon 740M with 4 CUs, although both iGPUs feature the same 16 ROPs/2 RB+ blocks.\n\nThe entry-level option to AMD's Zen 4 7040U series chips is the Ryzen 3 7440U, which is a quad-core APU (4C/8T) with a base frequency of 3.0 GHz, a turbo frequency of up to 4.7 GHz. This part also includes the Radeon 740M (4 CU) integrated graphics. As this is a 4-core part, AMD has significantly reduced the amount of available cache, for a combined total of 12 MB that's split into 8 MB of L3 cache and 4 MB of L2 cache.\n\n\n\nBlock diagram of the AMD Radeon 780M integrated graphics\n\nIt's worth pointing out that the Radeon 780M with 12 compute units (CU) has four Render Backends (RB+) blocks within the silicon, while both the Radeon 760M (8 CU) and Radeon 740M (4 CU) feature just two RB+ blocks. Compared to the Ryzen Mobile 6000 series, AMD has also improved the graphics frequencies, with the Radeon 780M clocking up to 2.7 GHz, which is 300 MHz faster than the Radeon 680M, which hit up to 2.4 GHz.\n\nAMD Ryzen 7040U With Ryzen AI: One Xilinx XDNA Block Included\n\nAMD's acquisition of Xilinx, which closed in February of last year, means they have been able to feed Xilinx's expertise and architecture into its latest Zen 4 products. The most prominent example is what AMD calls Ryzen AI, which is part of Xilinx's XDNA architecture. This XDNA-based architecture has been enabled within two of the four Ryzen 7040U series SKUs, with the top two SKUs, the Ryzen 7 7840U and Ryzen 5 7640U, getting access to the Ryzen AI block integrated into the silicon. The inclusion of 'Ryzen AI' is to bolster the capability of AMD's Phoenix processors in AI inference workloads, offering more efficient task-specific silicon than what the CPU or GPU are capable of.\n\nAnother interesting highlight of AMD Ryzen AI is that it directly supports Microsoft's Studio Effects pack within Windows 11, which AMD claims can only be enabled by a dedicated engine like AMD Ryzen AI. While an interesting inclusion to the silicon for AI workloads, AMD hasn't provided or published any expected performance figures to accompany the announcement.\n\nWhile we typically take a robust stance in digesting in-house performance figures, we usually don't take these at face value with in-house benchmarks optimizing things for favorable results. AMD did, however, provide some compute, and gaming performance figures comparing the performance of the Ryzen 7 7840U to Intel's Core i7-1360P and compute performance against Apple's M2 silicon.\n\nAMD is claiming up to 175% gains in Passmark 10 performance over Apple's M2 chip while offering up to 228% Media Encode performance over the Core i7-1360P; these are undoubtedly best-case figures and are to be taken with a pinch of salt. Interestingly in the gaming performance figures, which it put up its Ryzen 7 7840U with Radeon 780M integrated graphics again Intel's Core i7-1360P with Iris Xe graphics, it's not too surprising to see that the Radeon 780M performed between 130% and 239% better than Intel in specific titles. If nothing else, AMD typically invests in more GPU silicon for their high-end mobile processors.\n\nRegarding battery life, AMD states that it has heavily invested in efficiency leadership designed to bolster battery life by implementing Smart Power Management. As with previous announcements of its 7040HS series, AMD has yet to indicate how long battery life might be. Still, as partners and notebook vendors start to integrate Ryzen 7040U APUs with Zen 4 into their solutions, we'll eventually see how efficient AMD's Ryzen Mobile 7040U 15-30 W chips are compared to the previous generation.\n\nRyzen 7040U Launch: No Date as of Yet, But Expected Very Soon\n\nOne of the most significant talking points surrounding AMD's Ryzen 7040 mobile series is when they will launch. Early indications from AMD stated that we should start seeing broader adoption of its 7040 chips sometime in March. AMD announced to us in mid-March that it had pushed back the launch of its Ryzen Mobile 7040HS series until April.\n\nAs for the AMD Ryzen Mobile 7040U series, AMD isn't announcing any kind of release date or expected availability date at this time. Given the timing of AMD's announcement – a few weeks before Computex – we expect we'll find out more about the specific laptops in development and their expected release dates at that show."", 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'AMD Powers Hitachi Astemo Next-Generation Forward Camera System for Enhanced Vehicle Safety Through AI Object Detection\n\nAMD Automotive XA Zynq UltraScale+ MPSoC in Hitachi Astemo stereo camera platform provides a 3X wider detection area than prior generation cameras\n\nSANTA CLARA, Calif., Sept. 05, 2023 (GLOBE NEWSWIRE) -- AMD (NASDAQ: AMD) today announced that leading mobility supplier Hitachi Astemo has selected AMD adaptive computing technology to power its new, stereo-format, forward-looking camera for adaptive cruise control and autonomous emergency braking, improving the vision capabilities and helping to increase the safety of next-generation vehicles. The AMD Automotive XA Zynq™ UltraScale+™ multi-processor system-on-a-chip (MPSoC) provides both stereo and monocular image processing in the camera, enabling it to detect objects over 120 degrees — a 3X wider angle than its previous-generation cameras — to enhance overall safety.\n\n\n\n“The AMD Automotive XA Zynq UltraScale+ MPSoC is incredibly versatile and allows us to add multiple safety-critical features in our forward camera system,” said Makoto Kudo, deputy head of ECU solution business unit, Powertrain and Safety Systems Business Division, Hitachi Astemo Limited. “AMD high-performance, highly scalable, programmable silicon offers distinct benefits for the extremely complex image signal processing requirements of our forward camera system. The flexibility and capabilities of the Zynq UltraScale+ MPSoC platform and its ability to meet stringent functional safety requirements led us to work with AMD.”\n\n“Hitachi Astemo has clearly demonstrated its technological leadership with the development of this stereo forward camera that utilizes AMD adaptive computing technology,” said Yousef Khalilollahi, corporate vice president, APAC Sales, AMD. “Increased safety and accident avoidance are key tenets to automotive technologies, and AMD is proud to offer the foundational technology in these camera systems.”\n\nCamera systems are a critical part of autonomous driving and advanced driver-assistance systems in vehicles. Forward cameras play a key role in these systems, enabling vehicles to reliably detect objects and people. The Hitachi Astemo system powered by AMD combines stereo camera image-processing algorithms with artificial intelligence to provide object detection that will also enable video-based driver-assistance systems.\n\nAMD in Automotive\n\nAs the pace of innovation continues to accelerate in the automotive industry, the need for high-performance compute, compute acceleration and graphics technologies is increasing. AMD is a leader at this inflection point, with a broad line of high-performance CPUs, GPUs, FPGAs and Adaptive SoCs. From powering in-vehicle infotainment systems to advanced driver-assistance systems, autonomous driving and networking applications where functional safety is of paramount importance, AMD provides carmakers with a one-stop shop for silicon and software solutions. For more information, visit the AMD Automotive website.\n\nSupporting Resources:\n\nLearn more about the Zynq UltraScale+ MPSoC product family\n\nFollow AMD on LinkedIn\n\nFollow AMD on Twitter\n\n\n\nAbout AMD\n\nFor more than 50 years AMD has driven innovation in high-performance computing, graphics and visualization technologies. Billions of people, leading Fortune 500 businesses and cutting-edge scientific research institutions around the world rely on AMD technology daily to improve how they live, work and play. AMD employees are focused on building leadership high-performance and adaptive products that push the boundaries of what is possible. For more information about how AMD is enabling today and inspiring tomorrow, visit the AMD (NASDAQ: AMD) website, blog, LinkedIn and Twitter pages.\n\n©2023 Advanced Micro Devices, Inc. All rights reserved. AMD, the AMD Arrow logo, Zynq, UltraScale+, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Other names are for informational purposes only and may be trademarks of their respective owners.\n\nContact:\n\nDavid Szabados\n\nAMD Communications\n\n(408) 472-2439\n\ndavid.szabados@amd.com\n\n\n\nSuresh Bhaskaran\n\nAMD Investor Relations\n\n(408) 749-2845\n\nSuresh.bhaskaran@amd.com\n\n', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', '&#8226; Enterprise Services, including Enterprise Support Services, Industry Solutions (formerly Microsoft Consulting Services), and Nuance professional services. More Personal Computing Our More Personal Computing segment consists of products and services that put customers at the center of the experience with our technology. This segment primarily comprises: &#8226; Windows, including Windows OEM licensing and other non-volume licensing of the Windows operating system; Windows Commercial, comprising volume licensing of the Windows operating system, Windows cloud services, and other Windows commercial offerings; patent licensing; and Windows Internet of Things. &#8226; Devices, including Surface, HoloLens, and PC accessories. PART II Item 8 &#160; &#8226; Gaming, including Xbox hardware and Xbox content and services, comprising first- and third-party content (including games and in-game content), Xbox Game Pass and other subscriptions, Xbox Cloud Gaming, advertising, third-party disc royalties, and other cloud services. &#8226; Search and news advertising, comprising Bing (including Bing Chat), Microsoft News, Microsoft Edge, and third-party affiliates. Revenue and costs are generally directly attributed to our segments. However, due to the integrated structure of our business, certain revenue recognized and costs incurred by one segment may benefit other segments. Revenue from certain contracts is allocated among the segments based on the relative value of the underlying products and services, which can include allocation based on actual prices charged, prices when sold separately, or estimated costs plus a profit margin. Cost of revenue is allocated in certain cases based on a relative revenue methodology. Operating expenses that are allocated primarily include those relating to marketing of products and services from which multiple segments benefit and are generally allocated based on relative gross margin. In addition, certain costs are incurred at a corporate level and allocated to our segments. These allocated costs generally include legal, including settlements and fines, information technology, human resources, finance, excise taxes, field selling, shared facilities services, customer service and support , and severance incurred as part of a corporate program. Each allocation is measured differently based on the specific facts and circumstances of the costs being allocated and is generally based on relative gross margin or relative headcount. Segment revenue and operating income were as follows during the periods presented: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Year Ended June 30, &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Revenue &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes &#160; $ 69,274 &#160; &#160; $ 63,364 &#160; &#160; $ 53,915 &#160; Intelligent Cloud &#160; &#160; 87,907 &#160; &#160; &#160; 74,965 &#160; &#160; &#160; 59,728 &#160; More Personal Computing &#160; &#160; 54,734 &#160; &#160; &#160; 59,941 &#160; &#160; &#160; 54,445 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total &#160; $ 211,915 &#160; &#160; $ 198,270 &#160; &#160; $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Operating Income &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes $ 34,189 &#160; $ 29,690 &#160; $ 24,351 &#160; Intelligent Cloud &#160; 37,884 33,203 &#160; 26,471 More Personal Computing &#160; 16,450 &#160; &#160; 20,490 &#160; &#160; 19,094 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 88,523 &#160; $ 83,383 &#160; $ 69,916 &#160; &#160; &#160; &#160; ##TABLE_END &#160; No sales to an individual customer or country other than the United States accounted for more than 10% of revenue for fiscal years 2023, 2022, or 2021. Revenue, classified by the major geographic areas in which our customers were located, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; United States (a) $ 106,744 $ 100,218 $ 83,953 Other countries 105,171 98,052 84,135 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; ##TABLE_END &#160; (a) Includes billings to OEMs and certain multinational organizations because of the nature of these businesses and the impracticability of determining the geographic source of the revenue. PART II Item 8 &#160; Revenue, classified by significant product and service offerings, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; Server products and cloud services &#160; $ 79,970 $ 67,350 $ 52,589 Office products and cloud services 48,728 &#160; 44,862 39,872 Windows 21,507 24,732 22,488 Gaming 15,466 &#160; 16,230 &#160; 15,370 LinkedIn &#160; 15,145 &#160; &#160; 13,816 &#160; 10,289 Search and news advertising 12,208 &#160; 11,591 &#160; 9,267 Enterprise Services &#160; &#160; 7,722 &#160; &#160; &#160; 7,407 &#160; &#160; &#160; 6,943 &#160; Devices &#160; &#160; 5,521 &#160; &#160; &#160; 7,306 &#160; &#160; &#160; 7,143 &#160; Dynamics 5,437 4,687 3,754 Other &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; ##TABLE_END &#160; Our Microsoft Cloud revenue, which includes Azure and other cloud services, Office 365 Commercial, the commercial portion of LinkedIn, Dynamics 365, and other commercial cloud properties, was $ 111.6 billion, $ 91.4 billion, and $ 69.1 billion in fiscal years 2023, 2022, and 2021, respectively. These amounts are primarily included in Server products and cloud services, Office products and cloud services, LinkedIn, and Dynamics in the table above. Assets are not allocated to segments for internal reporting presentations. A portion of amortization and depreciation is included with various other costs in an overhead allocation to each segment. ']",,
"['078144b8-1f0e-97f2-448d-3fb5dd160933', '0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '98bbf6ab-43a5-bbd3-0b3e-b06c74380463', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['AMD_1', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'META_7', 'NVDA_7', 'MSFT_1']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', '&#8226; Devices, including Surface, HoloLens, and PC accessories. &#8226; Gaming, including Xbox hardware and Xbox content and services, comprising first- and third-party content (including games and in-game content), Xbox Game Pass and other subscriptions, Xbox Cloud Gaming, advertising, third-party disc royalties, and other cloud services. &#8226; Search and news advertising, comprising Bing (including Bing Chat), Microsoft News, Microsoft Edge, and third-party affiliates. Windows The Windows operating system is designed to deliver a more personal computing experience for users by enabling consistency of experience, applications, and information across their devices. Windows OEM revenue is impacted significantly by the number of Windows operating system licenses purchased by OEMs, which they pre-install on the devices they sell. In addition to computing device market volume, Windows OEM revenue is impacted by: &#8226; The mix of computing devices based on form factor and screen size. &#8226; Differences in device market demand between developed markets and growth markets. &#8226; Attachment of Windows to devices shipped. PART I Item 1 &#160; &#8226; Customer mix between consumer, small and medium businesses, and large enterprises. &#8226; Changes in inventory levels in the OEM channel. &#8226; Pricing changes and promotions, pricing variation that occurs when the mix of devices manufactured shifts from local and regional system builders to large multinational OEMs, and different pricing of Windows versions licensed. &#8226; Constraints in the supply chain of device components. &#8226; Piracy. Windows Commercial revenue, which includes volume licensing of the Windows operating system and Windows cloud services such as Microsoft Defender for Endpoint, is affected mainly by the demand from commercial customers for volume licensing and Software Assurance (&#8220;SA&#8221;), as well as advanced security offerings. Windows Commercial revenue often reflects the number of information workers in a licensed enterprise and is relatively independent of the number of PCs sold in a given year. Patent licensing includes our programs to license patents we own for use across a broad array of technology areas, including mobile devices and cloud offerings. Windows IoT extends the power of Windows and the cloud to intelligent systems by delivering specialized operating systems, tools, and services for use in embedded devices. Devices We design and sell devices, including Surface, HoloLens, and PC accessories. Our devices are designed to enable people and organizations to connect to the people and content that matter most using Windows and integrated Microsoft products and services. Surface is designed to help organizations, students, and consumers be more productive. Growth in Devices is dependent on total PC shipments, the ability to attract new customers, our product roadmap, and expanding into new categories. Gaming Our gaming platform is designed to provide a variety of entertainment through a unique combination of content, community, and cloud services. Our exclusive game content is created through Xbox Game Studios, a collection of first-party studios creating iconic and differentiated gaming experiences. We continue to invest in new gaming studios and content to expand our intellectual property roadmap and leverage new content creators. These unique gaming experiences are the cornerstone of Xbox Game Pass, a subscription service and gaming community with access to a curated library of over 400 first- and third-party console and PC titles. The gamer remains at the heart of the Xbox ecosystem. We are identifying new opportunities to attract gamers across a variety of different end points through our first- and third-party content and business diversification across subscriptions, ads, and digital stores. We&#8217;ve seen new devices from third-party manufacturers along with key PC and mobile end points that help us empower gamers to play in a way that is most convenient to them. We are focused on growing the platform and expanding to new ecosystems to engage as many gamers as possible. Xbox enables people to connect and share online gaming experiences that are accessible on Xbox consoles, Windows-enabled devices, and other devices. Xbox is designed to benefit users by providing access to a network of certified applications and services and to benefit our developer and partner ecosystems by providing access to a large customer base. Xbox revenue is mainly affected by subscriptions and sales of first- and third-party content, as well as advertising. Growth of our Gaming business is determined by the overall active user base through Xbox enabled content, availability of games, providing exclusive game content that gamers seek, the computational power and reliability of the devices used to access our content and services, and the ability to create new experiences through first-party content creators. PART I Item 1 &#160; Search and News Advertising Our Search and news advertising business is designed to deliver relevant search, native, and display advertising to a global audience. Our Microsoft Edge browser and Bing Chat capabilities are key tools to enable user acquisition and engagement, while our technology platform enables accelerated delivery of digital advertising solutions. In addition to first-party tools, we have several partnerships with companies, such as Yahoo, through which we provide and monetize search offerings. Growth depends on our ability to attract new users, understand intent, and match intent with relevant content on advertising offerings. Competition Windows faces competition from various software products and from alternative platforms and devices, mainly from Apple and Google. We believe Windows competes effectively by giving customers choice, value, flexibility, security, an easy-to-use interface, and compatibility with a broad range of hardware and software applications, including those that enable productivity. Devices face competition from various computer, tablet, and hardware manufacturers who offer a unique combination of high-quality industrial design and innovative technologies across various price points. These manufacturers, many of which are also current or potential partners and customers, include Apple and our Windows OEMs. Xbox and our cloud gaming services face competition from various online gaming ecosystems and game streaming services, including those operated by Amazon, Apple, Meta, and Tencent. We also compete with other providers of entertainment services such as video streaming platforms. Our gaming platform competes with console platforms from Nintendo and Sony, both of which have a large, established base of customers. We believe our gaming platform is effectively positioned against, and uniquely differentiated from, competitive products and services based on significant innovation in hardware architecture, user interface, developer tools, online gaming and entertainment services, and continued strong exclusive content from our own first-party game franchises as well as other digital content offerings. ', 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', 'Our AMD Ryzen Z1 Series processors bring high-performance to handheld Windows-based PC gaming platforms. These processors feature &#8220;Zen 4&#8221; processor technology combined with RDNA 3 graphics to deliver fast PC gaming, incredible battery life, and immersive experiences in handheld systems. Commercial CPUs. We offer enterprise-class desktop and mobile PC solutions sold as AMD PRO Mobile and AMD PRO desktop processors with Radeon&#8482; graphics for the commercial market. AMD Ryzen PRO, AMD Threadripper PRO and AMD Athlon PRO processors solutions are designed to provide enterprise customers with the performance, security capabilities and business features such as enhanced security and manageability, platform longevity and extended image stability. Our AMD Ryzen Threadripper PRO 7000 WX-Series processors with &#8220;Zen 4&#8221; core architecture and 5000 WX-Series processors with &#8220;Zen 3&#8221; core architecture provide full-spectrum performance across multiple workstation workloads due to the performance and efficiency of the Zen CPU core with core count scaling up to 96 cores in the 7000 WX-Series. Our Ryzen PRO 7040 Series Mobile processors are built on &#8220;Zen 4&#8221; architecture, AMD RDNA 3 integrated graphics, AMD PRO technologies and Ryzen AI, on select models. Our AMD Ryzen Threadripper PRO 7000 WX-Series processors are built on 5 nm &#8220;Zen 4&#8221; architecture. Chipsets. We offer a full suite of chipset products to support our AMD Ryzen and Threadripper platforms, including chipsets for the AM5 socket like the X670 chipsets which support PCIe &#174; 5.0 (fifth generation Peripheral Component Interconnect Express motherboard interface) designed for enthusiast desktop platforms. In the AM5 platform we also offer B650 chipsets to enable a broader range of solutions in the market. In the AM4 ecosystem for 5000-series processors and prior, we offer the X570, B550 and A520 chipsets. In addition, we continue to offer the B450 chipsets that are combined with AMD Ryzen processors for the AM4 desktop platform for the performance and affordable mainstream platforms segments. In HEDT and Workstation segments, we offer the WRX90 and TRX50 chipsets to support 7000-series Threadripper and Threadripper PRO platforms, as well as the WRX80 chipsets to support the 5000-series Threadripper PRO platforms. Gaming Segment Gaming Market Graphics processing is a fundamental component across many of our products and can be found in APU, GPU, SoC or a combination of a discrete GPU with another product working in tandem. Our customers generally use our graphics solutions to enable or increase the speed of rendering images, to help improve image resolution and color definition and/or to process AI/ML based workloads. We develop our graphics products for use in various computing devices and entertainment platforms, including desktop PCs, notebook PCs, handheld PCs, All-in-Ones (AIOs), professional workstations, and the data center. With each of our graphics products, we have available drivers and supporting software packages that enable the effective use of these products under a variety of operating systems and applications. We have developed AMD RDNA&#8482; 3, a high performing and power efficient graphics architecture, featuring a chiplet design, AI accelerators and the Radiance Display&#8482; Engine. This generation continues to support advanced graphics features introduced with RDNA 2, such as ray tracing, AMD Infinity Cache&#8482; and variable rate shading. The Sony PlayStation &#174; 5 and Microsoft &#174; Xbox Series S&#8482; and X&#8482; game consoles also feature our RDNA graphics architecture. Our APUs deliver visual processing functionality for value and mainstream PCs by integrating a CPU and a GPU on a single chip, while discrete GPUs (which are also known as dGPUs) offer high-performance graphics processing across all platforms. We leverage our core IP, including our graphics and processing technologies to develop semi-custom solutions. Here, semiconductor suppliers work alongside system designers and manufacturers to enhance the performance and overall user experience for semi-custom customers. We have used this collaborative co-development approach with many of today&#8217;s leading game console and handheld PC gaming manufacturers and can also address customer needs in many other markets. We leverage our existing IP to create a variety of products tailored to a specific customer&#8217;s needs, including complex fully-customized SoCs to more modest adaptations and integrations of existing CPU, APU or GPU products. Gaming Products Semi-Custom Products. Our semi-custom products are tailored, high-performance, customer-specific solutions based on our CPU, GPU and multi-media technologies. We work closely with our customers to define solutions to precisely match the requirements of the device or application. We developed the semi-custom SoC products that power both the Sony PlayStation 5 as well as the Microsoft Xbox Series S and X game consoles. We partnered with Valve to create a semi-custom APU optimized for handheld gaming to power the Steam Deck&#8482;. Discrete Desktop and Notebook GPUs . Our AMD Radeon series discrete GPU processors for desktop and notebook PCs support current generation application program interfaces (APIs) like DirectX&#174; 12 Ultimate and Vulkan &#174; , support high-refresh rate displays using AMD FreeSync&#8482;, AMD FreeSync Premium, and AMD FreeSync Premium Pro technologies, and are designed to support VR in PC platforms. Our AMD Radeon Software offers performance enhancing tools and enables new features and customization capabilities to customers and end-users. In addition, we also offer tools for game developers such as our AMD FidelityFX&#8482; open-source image quality software toolkit that helps deliver improved visual quality with minimal performance overhead. FidelityFX Super Resolution (FSR) uses upscaling technologies to help boost frame rates in games. Our FSR 2.0 technology uses temporal data and optimized anti-aliasing to boost frame rates in supported games while delivering similar or better image quality than native resolution without the requirement of dedicated machine learning hardware. Our FSR 3.0 technology combines the upscaling features of prior versions while introducing our AMD Fluid Motion Frames Technology which generates interpolated frames between native frames to increase the frame rate of games for a smoother gaming experience. Varying versions of FSR are supported in over 250 games and multiple products including Radeon GPUs, Ryzen APUs, and many of our Semi-custom solutions. Being an open-source technology FSR works across competing hardware solutions as well. Our AMD Radeon RX 7000 series are built on the high-performance, energy-efficient AMD RDNA3 architecture which provides up to 96 compute units, second generation high-bandwidth, low-latency AMD Infinity Cache technology as well as dedicated AI and ray tracing hardware. ']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '4ed62b68-d0bc-d85e-c5dd-c690c9763bdc', 'adfada1a-9035-2536-c50b-c83d3f18a36a', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'f322f75f-55d7-29ae-4045-d7ba8cd3153b']","['The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'NVDA_7', 'Nvidia (NVDA) Earnings Preview: Huge Revenue Expectations', 'Testing Meta Verified to Help Creators Establish Their Presence', 'AMD vs. Nvidia: How to choose the right graphics card for your PC']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on June 27, 2023 at 7:30 AM PT:\n\nWe’re excited to begin rolling out Meta Verified to most markets globally over the coming months.\n\nWe’ve heard positive feedback from creators in our initial tests and continue to gather input about what’s most valuable for subscribers. We’ll continue to evolve Meta Verified based on these learnings and explore new features and benefits that create more value for subscribers.\n\nUpdate on June 7, 2023 at 7:30 AM PT:\n\nMeta Verified is now available in India and will soon be available in Brazil.\n\nUpdate on May 31, 2023 at 9:00 AM PT:\n\nMeta Verified is now available in Canada.\n\nUpdate on May 16, 2023 at 7:40 AM PT:\n\nMeta Verified is now available in the United Kingdom.\n\nUpdate on March 17, 2023 at 11 AM PT:\n\nWe’re expanding our test of Meta Verified to the US after seeing good results from our early testing. This test in the US will reflect some initial learnings and feedback. We’re removing increased reach as a subscription feature for now, as we gather more feedback and further evolve Meta Verified. We’re exploring elements to add to the subscription as we roll out to more places and will share more when we’re ready.\n\nOriginally published on February 19, 2023 at 12 PM PT:\n\nTo help up-and-coming creators grow their presence and build community faster, today Mark Zuckerberg announced that we’ll begin testing a new offering called Meta Verified, a subscription bundle on Instagram and Facebook that includes a verified badge that authenticates your account with government ID, proactive account protection, access to account support, and increased visibility and reach. We’re starting with a gradual test in Australia and New Zealand later this week to learn what’s most valuable, and we hope to bring Meta Verified to the rest of the world soon.\n\nSome of the top requests we get from creators are for broader access to verification and account support, in addition to more features to increase visibility and reach. Since last year, we’ve been thinking about how to unlock access to these features through a paid offering.\n\nWith Meta Verified, you’ll get:\n\nA verified badge, confirming you’re the real you and that your account has been authenticated with a government ID.¹\n\nMore protection from impersonation with proactive account monitoring for impersonators who might target people with growing online audiences.\n\nHelp when you need it with access to a real person for common account issues.\n\nIncreased visibility and reach with prominence in some areas of the platform– like search, comments and recommendations.²\n\nExclusive features to express yourself in unique ways.³\n\nMeta Verified is available for direct purchase on Instagram or Facebook in Australia and New Zealand starting later this week. People can purchase a monthly subscription for (USD) $11.99 on the web and (USD) $14.99 on iOS and Android.4\n\nAs we test and learn, there will be no changes to accounts on Instagram and Facebook that are already verified based on prior requirements. Long term, we want to build a subscription offering that’s valuable to everyone, including creators, businesses and our community at large. As part of this vision, we are evolving the meaning of verified accounts on our apps so we can expand access to verification and more people can trust the accounts they interact with are authentic.\n\nBuilding Safety from the Beginning\n\nIt’s important to feel confident that your identity and accounts are safe and that the people you’re interacting with are who they say they are. That’s why we’re building a series of checks into Meta Verified before, during, and after someone applies.\n\nTo be eligible, accounts must meet minimum activity requirements, such as prior posting history, and be at least 18 years old .\n\nApplicants are then required to submit a government ID that matches the profile name and photo of the Facebook or Instagram account they’re applying for .\n\nSubscriptions will include proactive monitoring for account impersonation.\n\nWe’re also committed to continuous monitoring and review of reported violations, as well as taking swift action against those who try to evade our systems.\n\nTo learn more about Meta Verified visit Mark Zuckerberg’s Meta Channel on Instagram on your mobile device.\n\n1. Where available, some subscribers may be required to submit a selfie video as part of the authentication process.\n\n2. We’ll offer exclusive stickers on Facebook and Instagram Stories and Facebook Reels, and 100 free stars a month on Facebook so you can show your support for other creators.\n\n3. AUD 19.99 on web, AUD 24.99 on iOS and Android. NZD 23.99 on web, NZD 29.99 on iOS and Android. Subscription features are the same for both web and app purchases.\n\n4. Businesses are not eligible to apply for Meta Verified at this time.', 'Can they beat expectations again?\n\nNvidia is set to report quarterly earnings on Nov. 21 after the stock market closes at 3:20 CDT.\n\nThey are expected to report an earnings-per-share (EPS) of $3.39 on $16.11 billion in revenue.\n\nThe EPS figure is significantly higher this quarter compared to last quarter\'s expectation of $2.07 per share.\n\nThe revenue figure is significantly higher this quarter compared to last quarter\'s expectation of $11.09 billion.\n\nNvidia earnings preview\n\nIf you\'re reading this article, you probably already know that Nvidia (NVDA) has had a stellar 2023. The tech stock opened the year at $210.00, and reached its new all time high of $504.60 today, Nov. 20.\n\nNvidia has been the darling of the artificial intelligence craze, spiking almost $100 after their earnings announcement in May 2023. The stock has rallied almost $100 this month alone, and there are big expectations for the stock this earnings season. I was shocked to see just how much the EPS and revenue figures have increased compared to last quarter.\n\nThe current EPS expectation of $3.39 is over 50% higher than the previous quarter\'s expectation of $2.07 per share.\n\nThe current revenue expectation of $16.11 billion is also almost 50% higher than the previous quarter\'s expectation of $11.09 billion. Just staggering numbers from the chip maker, and it seems as though they\'ll need to exceed these numbers yet again and post a strong guidance for next year if they want to keep this stock price sky high.\n\nThe stock price\'s expected move through this week based on current implied volatility is +-$37.64, which is just over 7% of the current stock price. This is a pretty large expected move for such a high-priced stock. This weekly expected move makes up over 50% of the expected move through the January 2024 monthly cycle, so there is a lot of market movement expected from this earnings announcement alone.\n\nBullish on NVDA stock for earnings\n\nIt\'s no surprise to see NVDA going straight to the moon after the surge of AI demand, and the expectation is that earnings will be very impressive this quarter. If that rings true, and they announce strong expectations for things to continue into next year, we could see little bearish resistance and the stock move higher.\n\nBearish on NVDA stock for earnings\n\nInterestingly enough, it seems there is a lot of fear for downside movement this earnings quarter. At the end of the day, a massive increase in EPS and revenue expectations puts pressure on the company to deliver and paint a positive light. If they miss at all, or exhibit weak guidance for future quarters, we could easily see ""profit taking"" and long positions closed, which could put downside pressure on the stock.\n\nThere is still some turbulence in the sales relationship with China, which NVDA is closely tied to. This adds a layer of complexity to things, but negative political press is usually not good for single name equities regardless of who they are or what they produce. If there is shakiness on the earnings call, we could see the stock move lower.\n\nTune in to Options Trading Concepts Live at 11 a.m. CDT on Nov. 21 for a full options strategy breakdown for NVDA stock ahead of earnings after the close!\n\nMike Butler, tastylive director of market intelligence, has been in the markets and trading for a decade. He appears on Options Trading Concepts Live, airing Monday-Friday. @tradermikeyb\n\nFor live daily programming, market news and commentary, visit tastylive or the YouTube channels tastylive (for options traders), and tastyliveTrending for stocks, futures, forex & macro.\n\nTrade with a better broker, open a tastytrade account today. tastylive, Inc. and tastytrade, Inc. are separate but affiliated companies.', ""When you buy through our links, Business Insider may earn an affiliate commission. Learn more\n\nIn the world of PC gaming, AMD and Nvidia dominate the graphics card market. Whether it's a custom computer or a pre-built model, a graphics card is essential for rendering games in high quality, and cards from either Nvidia or AMD are what you'll find in all of the best gaming PCs and best gaming laptops.\n\nBoth brands offer a range of graphics cards with entry-level models starting at around $270 and high-end cards costing $1,500 or more. AMD and Nvidia also allow other manufacturers to sell third-party versions of their cards based on their original specs. This can create price variations among models with similar capabilities, since third-party manufacturers may add features like extra fans or lighting.\n\nWhile there are lots of graphics cards to choose from, it's still possible to compare each brand's overall performance in relation to their price. Premium Nvidia graphics cards are typically viewed as the most powerful when it comes to advanced features, while the best AMD cards have a reputation for being significantly more affordable and energy efficient.\n\nBelow, we've broken down details on all the latest graphics cards from Nvidia and AMD, and compare how they stack up.\n\nAdvertisement\n\nAMD vs. Nvidia: Price and features\n\nAMD and Nvidia both offer a range of graphics cards for different budgets and performance needs. Nvidia's current lineup is called the GeForce RTX 40 series, while AMD's lineup is called the Radeon RX 7000 series. Here's a rundown of each series.\n\nNote: The cards listed below are for desktop computers. Both brands also make mobile versions of their cards that PC manufacturers can integrate into their gaming laptops, but performance may vary.\n\nAdvertisement\n\nNvidia GeForce RTX 40 series graphics cards\n\nThe Nvidia GeForce RTX 4090 is the company's most powerful graphics card. Nvidia\n\nNvidia's RTX 40 series debuted in fall 2022 with the release of the flagship GeForce RTX 4080 ($1,199) and the premium RTX 4090 ($1,599); four more affordable RTX 40 series cards arrived in 2023.\n\nRTX 40 series cards share a wide range of features, including raytracing, an advanced lighting feature that requires a compatible graphics card, and DLSS 3.0, the latest version of Nvidia's AI-enhanced upscaling technology that makes games easier to run at high frame rates.\n\nOther Nvidia features are designed to benefit content creators; RTX cards include support for AI-based noise removal for your microphone and virtual backgrounds for your webcam, as well as face tracking and auto-focus. However, AMD reports that its graphics cards actually render video faster than the RTX 40 series with common editing programs like Adobe Premiere Pro and DaVinci Resolve Studio.\n\nAdvertisement\n\nAMD Radeon RX 7000 series graphics cards\n\nAn AMD Radeon RX 7000 series card being used with an AMD Ryzen CPU. XFX\n\nAMD launched the Radeon RX 7000 series of graphics cards in December 2022 with the RX 7900 XT ($899) and 7900 XTX ($999), followed by the release of several lower priced cards in 2023, including the 7700XT and 7800XT which are set to launch on September 6.\n\nAMD cards offer similar performance to Nvidia cards in most games, and usually for a lower price. For example, Tom's Hardware ranks the RX 7900 XT ($999) ahead of the RTX 4080 ($1,199) in terms of overall performance, despite the AMD card typically being $200 cheaper. However, Nvidia cards tend to reveal bigger advantages when you play newer games with more advanced graphical features.\n\nLike the RTX 40 series, AMD's RX 7000 cards do feature ray tracing, but ray tracing performance generally lags behind the RTX 40 series with slower frame rates. The RX 7000 series also has an AI-based rendering feature to improve frame rates, called FSR, but it's not quite as developed as Nvidia's DLSS.\n\nIf you're looking to play newer releases like Cyberpunk 2077 or Allen Wake 2, a weaker AMD card may struggle to deliver graphics at the highest possible quality. That said, AMD does partner with some developers to boost performance on AMD hardware; for example, Microsoft's Starfield was designed with support for AMD's FSR at release, but not DLSS.\n\nAMD also supports a feature called Smart Access Memory to improve performance when you pair its latest CPUs and GPUs together. This feature allows the CPU to use more of the graphics card's memory. However, some Nvidia and Intel hardware can take advantage of a similar feature, called Resizable Bar, so the underlying tech isn't AMD exclusive.\n\nAMD benchmark data that shows RX 7000 graphics cards outperforming Nvidia hardware exclusively use AMD processors during testing, so if you have an Intel processor, you may want to look at publicly sourced benchmarks before buying an AMD card.\n\n*The target resolution and refresh rates for each graphics card were determined based on benchmarks shared by Nvidia, AMD, and crowd sourced data from the public. The maximum frame rate and resolution possible with each card will vary based on the game.\n\nAdvertisement\n\nAMD vs. Nvidia: Which graphics card should you choose?\n\nUltimately, choosing between an AMD or Nvidia graphics card comes down to your personal needs, budget, and preferences. Those building their own PC with a smaller budget may prefer the affordability of AMD graphics cards, while those willing to pay more to play brand-new games with graphics that can best the PlayStation 5 or Xbox Series X will likely want an Nvidia 4080 or 4090 card to maximize performance.\n\nOf course, high-end AMD cards like the RX 7900 XT or RX 7900 XTX are still capable of playing the latest releases, but Nvidia's top models have an edge when you enable advanced features like ray tracing.\n\nFAQs\n\nAdvertisement\n\nWhat should you know before buying a graphics card?\n\nBefore you buy any graphics card, you should make sure that it's a good fit for your computer. Using an older CPU or motherboard with a brand-new graphics card can limit your overall performance and create bottlenecks that prevent you from getting the most out of your card.\n\nCheck that your motherboard supports the latest specifications, like PCIe 4.0. Newer graphics cards also demand lots of power, so make sure your power supply has enough juice to keep your computer running.\n\nFinally, always measure the inside of your case to make sure the graphics card will physically fit during installation, as different cases can position the graphics card at different angles. Different manufacturers also make different sized versions of the same graphics card to add extra fans or lighting.""]",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '0f064687-3f51-7c2c-9ad1-d77b09f66b36', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'df56caaf-ca1e-ee8f-eb9a-a15a7d7ce17d']","['AMD Ryzen Ups Its AI Game With Ryzen 8040 Series Mobile CPUs', 'NVDA_7', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'MSFT_8']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'We haven\'t even gotten close to peak AI anything, but you won\'t be able to buy a new laptop next year without seeing it everywhere, notable in its absence as well as its presence. That\'s because the business interests of everybody who wants to sell you hardware or software are in complete alignment, which will result in a gravitational pull we can\'t escape. AMD on Wednesday jumped in that line with its new Ryzen 8040 series of mobile processors at its Advancing AI event.\n\nOn-chip AI acceleration is critical for mobile devices, because it ameliorates the battery-killing nature of continual AI processing, which is far more cost-effective and environmentally better to perform locally than in the cloud -- data centers to support consumer AI use are a black hole of energy usage and expensive to run. The accelerators are dedicated to iterating through and managing memory for the results of the vector calculations of small, pretrained models running on the device.\n\nAll the primary computer manufacturers now include a neural processing unit tile on its flagship processor\'s die. AMD added it with its Ryzen 7040 series, Qualcomm rolled out its Snapdragon Elite in October, Intel announced it as part of the new Meteor Lake architecture (its first chips with the accelerator are rumored to debut next week) and Apple made its Neural Engine a central part of its M series architecture from the start.\n\nIn parallel with its GPU capabilities, branded RDNA, AMD refers to its NPU\'s capabilities XDNA. The Ryzen 7040 series (Phoenix) included the first generation of the NPU. The mobile processors AMD announced Wednesday for its Ryzen 8040 series (Hawk Point) uses the same NPU architecture but offers better performance. AMD rates Phoenix at 10 trillion operations per second (by the NPU alone), while it says Hawk Point delivers 16 TOPS.\n\nRyzen 8040 series mobile CPUs\n\nMax boost (GHz) Cores Threads NPU Power class Integrated graphics Ryzen 9 8945HS 5.2 8 16 Yes 35-54W Radeon 780M Ryzen 7 8845HS 5.1 8 16 Yes 35-54W Radeon 780M Ryzen 7 8840HS 5.1 8 16 Yes 20-30W Radeon 780M Ryzen 7 8840U 5.1 8 16 Yes 15-30W Radeon 780M Ryzen 5 8645HS 5 6 12 Yes 35-54W Radeon 760M Ryzen 5 8640HS 4.9 6 12 Yes 20-30W Radeon 760M Ryzen 5 8640U 4.9 6 12 Yes 15-30W Radeon 760M Ryzen 5 8540U 4.9 6 12 No 15-30W Radeon 740M Ryzen 3 8440U 4.7 4 8 No 15-30W Radeon 740M\n\nLaptops with the first series of Hawk Point chips are expected to be available by the end of March, and the company has its subsequent-gen XDNA 2 slated to ship to laptop manufacturers later in 2024. AMD claims those ""Strix Point"" Ryzen processors will offer three times better performance for generative AI over Hawk Point. And that may complicate your buy-now-or-wait decision.\n\nBecause CPU branding is complicated, don\'t assume that all 8040-series CPUs have the NPU. At the bottom of the stack, the two cheapest processors don\'t have it, which means the NPU may be out of the reach of budget buyers.\n\nThe Acer Nitro V 16, announced Wednesday. Acer\n\nOne of the spotlight products announced, the updated 16-inch Acer Nitro V 16 gaming laptop goes ""up to"" a Ryzen 7 8845HS and an Nvidia GeForce RTX 4060, but a mystery base configuration starts at $1,000. Who knows if that base includes an NPU-equipped CPU or how price scales for the configurations. Acers equipped with the NPU will use it for optimizing battery life and expanded power-management features. The Nitro\'s expected to ship in March, in line with the wait we usually have from announcement to shipping of new chips this time of year.\n\nAnother reason for the aligned push is to motivate software developers to use the application programming interfaces in order to offload much of the inferencing and generative work the way they address the graphics accelerator for a smoother experience with interactive graphics tasks.\n\nThere are a lot of developers who already use custom AI models, like Adobe, Zoom, OBS (in OBS Studio, for streamers) and Microsoft. But there\'s a multitude of APIs for handling the on-device model and interaction with the operating system -- WindowsML, Intel OpenVINO, Nvidia\'s integration into its own software (like DLSS in the graphics driver and Broadcast) and more. It\'s still all shaking out.']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '14a6075d-377d-9629-9ab6-4a3ca2a3c35b', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA_7', 'Esports Giant TSM Forges Ahead With Web3 Gaming on Avalanche', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'MSFT_8']","['Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', 'Your Web3 Gaming Power-Up Enjoy exclusive benefits with the GG Membership Pass\n\nDecrypt’s Art, Fashion, and Entertainment Hub. Discover SCENE\n\nDespite the collapse of FTX and a scrapped $210 million naming rights deal, Team SoloMid’s affinity for crypto hasn’t soured. In fact, the esports org also known as TSM is now building its own crypto sub-network on Avalanche to facilitate esports transactions and tournaments, TSM parent company Swift announced Tuesday.\n\nSwift, which also owns the Blitz Esports platform, is building the blockchain sub-network—or “Subnet”—on Avalanche for TSM events. Swift has also chosen crypto payments firm Core for TSM and Blitz, allowing players and fans to “store, sell, and purchase digital assets,” according to a statement. When asked if those assets might be NFTs, Ava Labs’ Head of Gaming Ed Chang explained to Decrypt via email that such details have not yet been finalized.\n\nThe Blitz Subnet will use Avalanche’s AVAX token for network transaction fees, also known as gas fees. Swift plans to convert its Avalanche Subnet into an “Elastic Subnet” in the future, meaning that users will be able to become validators for the network by locking up or “staking” crypto tokens and will earn financial rewards in exchange under the “proof of stake” validation mechanism.\n\nAD\n\nAD\n\n“Web3 gaming is still quite early,” TSM and Swift CEO Andy Dinh told Decrypt via email. “It’s very exciting, but it will take time to materialize.”\n\nAs one of the largest esports orgs, TSM is known for its “League of Legends” (LoL) professional team, while Blitz offers in-game overlays for LoL as well as for AAA games like “Apex Legends,” “Valorant,” and “Teamfight Tactics” and currently boasts over 30 million users.\n\n“Partnering with TSM brings truly innovative gaming experiences to players around the world,” said John Wu, president of Ava Labs, the developers behind Avalanche. “Avalanche’s fully customizable subnets were created to help organizations push the boundaries of what is possible for gaming with sub-second transaction speed, scalability, and security for millions of users.”\n\nWhen asked why TSM chose Avalanche over other blockchain networks, Dinh explained that Ava Labs was the most collaborative.\n\n“We think a big part of finding success is finding teams that are easy to work with,” Dinh said.\n\nAD\n\nAD\n\nTSM’s approach to Web3 involves building products over time that are “authentic to the space and add value,” Dinh added.']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'b7b86963-f371-4628-52cf-58dc3dc7d28f', 'c778838f-5a8e-29d9-7945-b1804ff1cc42', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'How to Invest in Microsoft Stock (MSFT)', 'MSFT_8', 'New Tools to Support Independent Research', 'NVDA_7']","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on February 15, 2024 at 7:00AM PT:\n\nWe want to make more data from our platforms available to academic researchers so they can pursue public interest research, while doing so in a way that respects both people’s privacy and our compliance obligations.\n\nIn the months since we rolled out our Meta Content Library tool we’ve been gathering feedback from researchers to ensure the sort of publicly-accessible data they need is available to them in a way that’s effective for their research. Based on that feedback, we are adding some new data and features.\n\nOne of the biggest requests was to make content from public figures more accessible to researchers so it is easier to study the impact their activity on Facebook and Instagram has on politics, society and culture. So, in the coming weeks, we’re making it possible for researchers to download certain publicly-accessible content posted by public figures and widely-known figures and entities. This data will be accessible in a downloadable CSV format through the Meta Content Library user interface and won’t require access through a virtual clean room.\n\nIn the next few months, we’ll also be adding ‘comments’ as a new data type within the Meta Content Library. This will help researchers study how people around the world receive, discuss and reinterpret content across publicly-accessible pages and posts. We’ll be starting with comments from public forums on Facebook, which researchers will be able to analyze within ICPSR’s virtual clean room.\n\nOur Third Party Fact-Checking partners will also have access to Meta Content Library to help them investigate and debunk misinformation. We hope these powerful search capabilities will help them do this more efficiently, particularly during key moments such as elections.\n\nOriginally published on November 21, 2023 at 3:00AM PT:\n\nTo understand the impact social media apps like Facebook and Instagram have on the world, it’s important to support rigorous, independent research. That’s why Meta has been committed to an open and privacy-protective approach to research for many years, including making tools available to support public interest research, such as the US 2020 studies.\n\nOver the past few months we gave Beta access to our new Meta Content Library and API tools. After multiple rounds of feedback with researchers and other stakeholders, we are now in a position to roll these tools out more broadly.\n\nMeta Content Library & API\n\nOur Meta Content Library and API tools provide access to near real-time public content from Pages, Posts, Groups and Events on Facebook, as well as from creator and business accounts on Instagram. Details about the content, such as the number of reactions, shares, comments and, for the first time, post view counts are also available. Researchers can search, explore and filter that content on both a graphical User Interface (UI) or through a programmatic API.\n\nTogether, these tools provide the most comprehensive access to publicly-available content across Facebook and Instagram of any research tool we have built to date. They also help us meet new regulatory requirements, data-sharing and transparency compliance obligations. Introducing these tools to researchers early in the development process gave us the opportunity to improve them before making them more widely available. We will continue to make improvements as we collect more feedback from researchers.\n\nIndividuals from qualified institutions pursuing scientific or public interest research topics will be able to apply for access to these tools through partners with deep expertise in secure data sharing for research, starting with the University of Michigan’s Inter-university Consortium for Political and Social Research. This is a first-of-its-kind partnership that will enable researchers to analyze data from the API in ICPSR’s Social Media Archive’s (SOMAR) Virtual Data Enclave.\n\nSocial Capital Research\n\nLast year, in collaboration with Raj Chetty and Harvard’s Opportunity Insights Program, we released a landmark study to measure the drivers of economic mobility in the US using information from 21 billion friendships on Facebook, which found that social connections play an important role in helping communities rise out of poverty.\n\nWe’re now expanding this research program with Harvard to better understand the drivers of economic mobility around the world by using insights from our platform on the dynamics of social networks, as well as publicly available data on socioeconomics and schools. We plan to examine cross-class friendships across the United Kingdom in collaboration with experts at the Behavioural Insights Team, Royal Society of Arts, Stripe Partners and Neighbourly Lab.\n\nAs well as expanding to more countries, we also plan to do more research into the role social connections play in economic opportunity including business creation, attending college, and getting a job. Building on our work looking at how social connections benefit people, we will continue to study how social networks help communities recover from crises and help displaced populations and migrants.', 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', '3 Most Important Financial Statements\n\nEmotions in Investing: How to Manage Stock Market Anxiety & Stress\n\nFutures Trading: Everything You Need to Know\n\nFor Investors: Business Valuation 101\n\n11 Up-and-Coming Stocks to Invest In\n\nWhen to Sell Stocks — for Profit or Loss\n\nAccounts That Earn Compounding Interest\n\nHow Many Shares Should I Buy of a Stock?\n\nSelling Stock: How Capital Gains Are Taxed\n\nMarket Order vs. Limit Order\n\nHow Are Stock Prices Determined?\n\nWhat Is a Good Return on Investment?\n\nDay Trading Definition: Why It Differs From Investing\n\nThe Definitive Guide: How to Value a Stock\n\nWhat Happens When a Stock Is Delisted?\n\nGAAP vs. Non-GAAP: Everything You Need to Know\n\nShould I Buy Stock Now or Wait?\n\nA Beginner\'s Guide to Understanding Financial News\n\nTechnical Analysis for the Long-Term Investor\n\nHow to Calculate Cost Basis for Inherited Stock\n\nWhat Are Share Repurchases?\n\nHow to Research Stocks\n\nAverage Stock Market Return\n\nHow to Short a Stock\n\nStock vs. Share: What\'s the Difference?\n\nHow to Find Investment Ideas\n\nInvestment Strategies for the Long Term\n\nWhat is the Difference Between Simple & Compound Interest?\n\nWhy Is It Important to Invest in Stocks?\n\nWhat Makes a Stock Price Go Up?\n\nHow to Pick a Stock for the First Time\n\nCan You Owe Money on Stocks?\n\nOptions vs. Stocks: What\'s the Difference?\n\nTaxes on Investments: Understanding the Basics\n\nHow Many Stocks Should You Own?\n\nSocially Responsible Investing\n\nHow to Gift Stock\n\nHow to Invest in Stocks: A Step-by-Step Guide\n\nHow to Calculate Volatility of a Stock\n\nHow to Calculate Total Stock Returns\n\nHow to Calculate Take-Home Pay\n\nTax Loss Harvesting\n\nHow to Invest in Amazon Stock\n\nHow to Invest in Tesla Stock\n\nHow to Buy Nvidia Stock (NVDA)\n\nHow to Invest in Disney Stock\n\nHow to Invest in Google Stock\n\nHow to Invest in Berkshire Hathaway Stock\n\nHow to Invest in Johnson & Johnson Stock\n\nHow to Invest in Exxon Stock\n\nHow to Invest in Facebook Stock\n\nHow to Invest in Stripe\n\nHow to Invest in Apple Stock\n\nHow to Invest in Databricks\n\nHow to Invest in Epic Games\n\nHow to Invest in Ford Stock\n\nHow to Invest in PayPal Stock\n\nHow to Invest in Etsy Stock\n\nHow to Buy Pinterest Stock in 2024\n\nHow to Invest in Block Stock\n\nHow to Invest in OpenAI\n\nHow to Invest in SpaceX in 2024\n\nHow to Invest in Mistral AI in 2024\n\nHow to Invest in C3.ai\n\nHow to Invest in Shopify in 2024\n\nHow to Invest in Costco in 2024\n\nHow to Invest in Netflix in 2024\n\nHow to Invest in Aldi in 2024\n\nHere\'s How to Calculate Future Expected Stock Price\n\nConverting Daily Returns to Annual Returns: Formula, Process, and Example\n\nHow to Calculate Average Stock Price: A Step-By-Step Guide\n\nMillion-Dollar Portfolio: How to Get There\n\nBest Master Limited Partnership Stocks to Buy in 2024\n\nUpcoming Stock Splits to Pay Attention to\n\nApple\'s Stock Split History\n\nCall vs. Put Options\n\nHow to Trade Options\n\nFutures vs. Options: What\'s the Difference?\n\nUnderstanding the Differences Between GAAP and IFRS\n\nHow to Invest in Reddit Stock\n\nHow to Invest in Coca-Cola Stock (NYSE:KO)\n\nHow to Invest in Discord\n\nHow to Invest in Twilio Stock\n\nHow to Invest in Upstart\n\nHow to Invest in Intuitive Surgical\n\nHow to Invest in Carnival Cruise Lines\n\nHow to Invest in Rivian\n\nHow to Invest in SoFi Stock\n\nHow to Invest in Plug\n\nHow to Invest in CRISPR Therapeutics Stock\n\nHow to Invest in Cava\n\nHow to Invest in Nio\n\nHow to Invest in Advanced Micro Devices\n\nHow to Invest in Nu Holdings\n\nHow to Invest in Palantir Technologies Stock\n\nHow to Invest in Coinbase Stock\n\nHow to Invest in AT&T Stock\n\nHow to Invest in Pepsi Stock\n\nHow to Invest in Walmart (NYSE:WMT)\n\nHow to Invest in Palo Alto Networks Stock\n\nHow to Invest in Arm Stock\n\nHow to Invest in Instacart\n\nHow to Invest in Klarna Stock\n\nHow to Invest in The Boring Company\n\nHow to Invest in Rippling Stock Pre-IPO\n\nHow to Invest in Blue Origin\n\nHow to Invest in Upside Foods\n\nHow to Invest in Zipline\n\nNeuralink Stock: How to Invest Before the IPO\n\nInvesting in Ripple Stock\n\nHow to Invest in Canva\n\nHow to Invest in Fanatics Stock\n\nHow to Invest in Revolut\n\nHow to Invest in Chime Stock\n\nHow to Invest in Impossible Foods\n\nHow to Invest in Forge Global\n\nHow to Invest in Tilray Stock\n\nHow to Invest in AMC\n\nHow to Invest in General Electric (GE)\n\nHow to Invest in Northrop Grumman (NOC)\n\nHow to Invest in Boeing\n\nHow to Invest in Kenvue\n\nHow to Invest in Bank of America\n\nHow to Invest in Comcast\n\nHow to Invest in Snap\n\nHow to Invest in QuantumScape\n\nHow to Invest in Lockheed Martin\n\nHow to Invest in Birkenstock\n\nHow to Invest in Snowflake\n\nHow to Invest in Taiwan Semiconductor\n\nYour Guide to Investing: ""Magnificent Seven"" Stocks\n\nHow to Invest in Intel\n\nHow to Invest in IBM\n\nHow to Invest in Liquid Death\n\nHow to Invest in Northvolt\n\nHow to Invest in Flexport in 2024\n\nHow to Invest in Nikola\n\nHow to Invest in Verizon in 2024\n\nHow to Invest in Skims in 2024\n\nHow to Invest in Waystar Technologies\n\nHow to Invest in BMC Software\n\nHow to Invest in Unity Software\n\nHow to Invest in Canopy Growth\n\nSHEIN IPO: Investing in SHEIN\n\nHow to Invest in Panera Bread\n\nHow to Invest in Starlink in 2024\n\nHow to Invest in Publix\n\nHow to Invest in Ikea\n\nHow to Invest in Marvel\n\nHow to Invest in Deloitte\n\nHow to Invest in Cargill\n\nHow to Invest in Lyft\n\nHow to Invest in Uber\n\nHow to Invest in Mars Stock\n\nHow to Invest in H-E-B Grocery\n\nWhat Does Disney Own?\n\nWhat Does Coca-Cola Own?\n\nWhat Does Pepsi Own?\n\nWhat Does Procter & Gamble Own?\n\nWhat Does Altria Own?\n\nBuying Trader Joe\'s Stock: Is It Public?\n\nHow to Invest in the Lego Company\n\nHow to Invest in the NFL\n\nHow to Invest in Hulu Stock\n\nHow to Invest in Arctic Wolf\n\nHow to Invest in Rubrik Pre-IPO\n\nHow to Invest in ServiceTitan Pre-IPO\n\nHow to Invest in Checkout.com Pre-IPO\n\nHow to Invest in Plaid Pre-IPO\n\nHow to Invest in Redwood Materials Stock\n\nWhat Happens to the Ownership of Stocks After a Person Dies?']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '847c11a8-0c3d-b013-2aaf-2bd2fa429037', 'b62cc0aa-1de6-c896-1788-a3a15c52d0a3', 'b78da971-cede-623b-d604-234e42dda7f8', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA_7', 'META_1A', 'NVDA vs. TSM: Which Chipmaker Stock is Better?', 'MSFT_8']","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', ""In addition, we have implemented, and may continue to implement, product changes that give users the ability to limit our use of such data signals to improve ads and other experiences on our products and services, including changes implemented in connection with the GDPR, ePrivacy Directive, DMA, and other regulatory frameworks. These developments have limited our ability to target and measure the effectiveness of ads on our platform and negatively impacted our advertising revenue. For example, our advertising revenue has been negatively impacted by marketer reaction to targeting and measurement challenges associated with iOS changes beginning in 2021. If we are unable to mitigate these developments as they take further effect in the future, our targeting and measurement capabilities will be materially and adversely affected, which would in turn significantly impact our advertising revenue. Table of Contents Our user growth, engagement, and monetization on mobile devices depend upon effective operation with mobile operating systems, networks, technologies, products, and standards that we do not control. The substantial majority of our revenue is generated from advertising on mobile devices. There is no guarantee that popular mobile devices will continue to feature our products, or that mobile device users will continue to use our products rather than competing products. We are dependent on the interoperability of our products with popular mobile operating systems, networks, technologies, products, and standards that we do not control, such as the Android and iOS operating systems and mobile browsers. Changes, bugs, or technical issues in such systems, or changes in our relationships with mobile operating system partners, handset manufacturers, browser developers, or mobile carriers, or in the content or application of their terms of service or policies (which they have made in the past and continue to seek to implement) that degrade our products' functionality, reduce or eliminate our ability to update or distribute our products, give preferential treatment to competitive products, limit our ability to deliver, target, or measure the effectiveness of ads, or charge fees related to the distribution of our products or our delivery of ads have adversely affected, and could in the future adversely affect, the usage of our products and monetization on mobile devices. For example, Apple previously released an update to its Safari browser that limits the use of third-party cookies, which reduces our ability to provide the most relevant ads to our users and impacts monetization, and also released changes to iOS that limit our ability to target and measure ads effectively, while expanding their own advertising business. In addition, in January 2024, Google began the process of phasing out third-party cookies in its Chrome browser. We expect that any similar changes to Apple's, Google's, or other browser or mobile platforms will further limit our ability to target and measure the effectiveness of ads and impact monetization. Additionally, in order to deliver high quality mobile products, it is important that our products work well with a range of mobile technologies, products, systems, networks, and standards that we do not control, and that we have good relationships with handset manufacturers, mobile carriers, and browser developers. We may not be successful in maintaining or developing relationships with key participants in the mobile ecosystem or in developing products that operate effectively with these technologies, products, systems, networks, or standards. In the event that it is more difficult for our users to access and use our products on their mobile devices, or if our users choose not to access or use our products on their mobile devices or use mobile products that do not offer access to our products, our user growth and user engagement could be harmed. From time to time, we may also take actions regarding the distribution of our products or the operation of our business based on what we believe to be in our long-term best interests. Such actions may adversely affect our users and our relationships with the operators of mobile operating systems, handset manufacturers, mobile carriers, browser developers, other business partners, or advertisers, and there is no assurance that these actions will result in the anticipated long-term benefits. In the event that our users are adversely affected by these actions or if our relationships with such third parties deteriorate, our user growth, engagement, and monetization could be adversely affected and our business could be harmed. We have experienced challenges in operating with mobile operating systems, networks, technologies, products, and standards that we do not control, and any such occurrences in the future may negatively impact our user growth, engagement, and monetization on mobile devices, which may in turn materially and adversely affect our business and financial results. Our new products and changes to existing products could fail to attract or retain users or generate revenue and profits, or otherwise adversely affect our business. Our ability to retain, increase, and engage our user base and to increase our revenue depends heavily on our ability to continue to evolve our existing products and to create successful new products, both independently and in conjunction with developers or other third parties. We may introduce significant changes to our existing products or acquire or introduce new and unproven products, including using technologies with which we have little or no prior development or operating experience. For example, we have relatively limited experience with consumer hardware products and virtual and augmented reality technology, which may adversely affect our ability to successfully develop and market these evolving products and technologies. We are also making significant investments in artificial intelligence (AI) initiatives across our business. For example, we recently launched new AI features on our products, including conversational AIs, stickers, and editing tools. We continue to incur substantial costs, and we may not be successful in generating profits, in connection with these efforts. In addition, we have invested, and expect to continue to invest, significant resources in growing our messaging products to support increasing usage of such products. We have historically monetized messaging in only a limited fashion, and we may not be successful in our efforts to generate meaningful revenue or profits from messaging over the long term. "", 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Maintaining and enhancing our brands will require us to make substantial investments and these investments may not be successful. Certain of our actions, such as the foregoing matter regarding developer misuse of data and concerns around our handling of political speech and advertising, hate speech, and other content, as well as user well-being issues, have eroded confidence in our brands and may continue to do so in the future. If we fail to successfully promote and maintain our brands or if we incur excessive expenses in this effort, our business and financial results may be adversely affected. We may not be able to continue to successfully maintain or grow usage of and engagement with applications that integrate with our products. We have made and are continuing to make investments to enable developers to build, grow, and monetize applications that integrate with our products. Such existing and prospective developers may not be successful in building, growing, or monetizing applications that create and maintain user engagement. Additionally, developers may choose to build on other platforms, including platforms controlled by third parties, rather than building products that integrate with our products. We are continuously seeking to balance the distribution objectives of our developers with our desire to provide an optimal user experience, and we may not be successful in achieving a balance that continues to attract and retain such developers. For example, from time to time, we have taken actions to reduce the volume of communications from these developers to users on our products with the objective of enhancing the user experience, and such actions have reduced distribution from, user engagement with, and our monetization opportunities from, applications integrated with our products. In addition, as part of our efforts related to privacy, safety, and security, we conduct investigations and audits of platform applications from time to time, and we also have announced several product changes that restrict developer access to certain user data. In some instances, these actions, as well as other actions to enforce our policies applicable to developers, have adversely affected, or will adversely affect, our relationships with developers. If we are not successful in our efforts to maintain or grow the number of developers that choose to build products that integrate with our products or if we are unable to continue to build and maintain good relations with such developers, our user growth and user engagement and our financial results may be adversely affected. Table of Contents Risks Related to Our Business Operations and Financial Results Our business is highly competitive. Competition presents an ongoing threat to the success of our business. We compete with companies providing connection, sharing, discovery, and communication products and services to users online, as well as companies that sell advertising to businesses looking to reach consumers and/or develop tools and systems for managing and optimizing advertising campaigns. We face significant competition in every aspect of our business, including, but not limited to, companies that facilitate the ability of users to create, share, communicate, and discover content and information online or enable marketers to reach their existing or prospective audiences. We compete to attract, engage, and retain people who use our products, to attract and retain businesses that use our free or paid business and advertising services, and to attract and retain developers who build compelling applications that integrate with our products. We also compete with companies that develop and deliver consumer hardware and virtual and augmented reality products and services. We also expect to face additional competition as we introduce or acquire new products, as our existing products evolve, or as other companies introduce new products and services, including as part of efforts to develop the metaverse or innovate through the development and application of new technologies such as AI. Some of our current and potential competitors may have greater resources, experience, or stronger competitive positions in certain product segments, geographic regions, or user demographics than we do. For example, some of our competitors may be domiciled in different countries and subject to political, legal, and regulatory regimes that enable them to compete more effectively than us. These factors may allow our competitors to respond more effectively than us to new or emerging technologies and changes in market conditions. We believe that some users, particularly younger users, are aware of and actively engaging with other products and services similar to, or as a substitute for, our products and services, and we believe that some users have reduced their use of and engagement with our products and services in favor of these other products and services. In addition, from time to time we make updates to our products and services to improve the user experience (including to help provide users with safe, positive, age-appropriate experiences), and these changes have had, and may in the future have, the effect of reducing time spent and some measures of user engagement with our products and services. In the event that users increasingly engage with other products and services, we may experience a decline in use and engagement in key user demographics or more broadly, in which case our business would likely be harmed. Our competitors may develop products, features, or services that are similar to ours or that achieve greater acceptance, may undertake more far-reaching and successful product development efforts or marketing campaigns, or may adopt more aggressive pricing policies. Some competitors may gain a competitive advantage against us in areas where we operate, including: by making acquisitions; by limiting our ability to deliver, target, or measure the effectiveness of ads; by imposing fees or other charges related to our applications or our delivery of ads; by making access to our products more difficult or impossible; by making it more difficult to communicate with our users; or by integrating competing platforms, applications, or features into products they control such as mobile device operating systems, search engines, browsers, or e-commerce platforms. For example, each of Apple and Google have integrated competitive products with iOS and Android, respectively. In addition, Apple has released changes to iOS that limit our ability, and the ability of others in the digital advertising industry, to target and measure ads effectively. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['2c481b68-b535-cf82-584b-b1cbdff1d1db', '3e619c5b-8801-886f-1153-21429e404e1b', '4ebba5df-5943-d59e-0f3d-e716f0014ca8', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', ""How Weak Demand Is Putting A Damper On Taiwan Semi's Outlook — And Those Of Others"", ""Here's Why Microsoft (MSFT) is a Strong Growth Stock""]","[""Taking full advantage of the stock market and investing with confidence are common goals for new and old investors alike.\n\nWhile you may have an investing style you rely on, finding great stocks is made easier with the Zacks Style Scores. These are complementary indicators that rate stocks based on value, growth, and/or momentum characteristics.\n\nWhy This 1 Growth Stock Should Be On Your Watchlist\n\nDifferent than value or momentum investors, growth-oriented investors are concerned with a stock's future prospects, and the overall financial health and strength of a company. Thus, they'll want to focus on the Growth Style Score, which analyzes characteristics like projected and historical earnings, sales, and cash flow to find stocks that will see sustainable growth over time.\n\nMicrosoft (MSFT)\n\nMicrosoft Corporation is one of the largest broad-based technology providers in the world. The company dominates the PC software market with more than 73% of the market share for desktop operating systems.\n\nMSFT boasts a Growth Style Score of A and VGM Score of B, and holds a Zacks Rank #3 (Hold) rating. Its bottom-line is projected to rise 13.5% year-over-year for 2024, while Wall Street anticipates its top line to improve by 14.3%.\n\n17 analysts revised their earnings estimate upwards in the last 60 days, and the Zacks Consensus Estimate has increased $0.23 to $11.13 per share for 2024. MSFT boasts an average earnings surprise of 7.8%.\n\nLooking at cash flow, Microsoft is expected to report cash flow growth of 3.9% this year; MSFT has generated cash flow growth of 16.6% over the past three to five years.\n\nWith solid fundamentals, a good Zacks Rank, and top-tier Growth and VGM Style Scores, MSFT should be on investors' short lists.\n\nWant the latest recommendations from Zacks Investment Research? Today, you can download 7 Best Stocks for the Next 30 Days. Click to get this free report\n\nMicrosoft Corporation (MSFT) : Free Stock Analysis Report\n\nTo read this article on Zacks.com click here.\n\nZacks Investment Research"", 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure', 'Shares of Taiwan Semiconductor Manufacturing (TSM) took a beating Thursday as the world\'s largest contract chipmaker topped analyst estimates for the second quarter but disappointed with its outlook. TSM stock fell more than 5% and dragged other chip players down with it.\n\nX\n\nTaiwan Semiconductor, better known as TSMC, earned $1.14 per U.S. share on sales of $15.68 billion in the June quarter. Analysts polled by FactSet had expected earnings of $1.07 a share on sales of $15.44 billion. However, TSMC earnings fell 25% year over year while sales dropped 12%. In local currency, earnings decreased 23% while sales declined 10%.\n\nTSMC\'s results marked its second straight quarter of declining sales and earnings as its customers navigate a downturn in chip demand.\n\nFor the current quarter, TSMC predicted revenue of $16.7 billion to $17.5 billion. The midpoint of $17.1 billion is below Wall Street\'s target of $17.4 billion. In the year-earlier period, TSMC generated $19.2 billion in sales.\n\nTSM Stock Falls After Report\n\nTaiwan Semiconductor also cut its revenue forecast for the full year to a 10% decline from a mid-single-digit decline.\n\n""This is the third cut to its revenue outlook that TSMC has made this cycle,"" Needham analyst Charles Shi said in a note to clients. Shi had expected TSMC to reduce its 2023 sales outlook to a high-single-digit decline.\n\n""TSMC\'s second-quarter earnings call may go down as one of the more pessimistic calls in recent history,"" Shi said.\n\nOn the stock market today, TSM stock tumbled 5.1% to close at 97.86.\n\nTSMC\'s earnings report pulled down a host of semiconductor stocks. The Philadelphia semiconductor index, known as SOX, sank 3.6% on Thursday. The SOX includes the 30 largest semiconductor stocks traded in the U.S.\n\nAmong major TSMC customers, Advanced Micro Devices (AMD) fell 5.3% and Nvidia (NVDA) retreated 3.3%.\n\nTSM stock is in a flat base with a buy point of 110.69, according to IBD MarketSmith charts.\n\nFactors Behind Soft Demand\n\n""Our second-quarter business was impacted by the overall global economic conditions, which dampened the end-market demand, and led to customers\' ongoing inventory adjustment,"" Chief Financial Officer Wendell Huang said in a news release.\n\nHe added, ""Moving into third quarter 2023, we expect our business to be supported by the strong ramp of our 3-nanomenter technologies, partially offset by customers\' continued inventory adjustment.""\n\nCircuit widths on chips are measured in nanometers, which are one-billionth of a meter.\n\nThe slower-than-expected economic recovery in China also is a factor in TSMC\'s reduced outlook, Evercore ISI analyst C.J. Muse said in a report.\n\nIn addition, the chip inventory correction now is likely to last through the fourth quarter, rather than the third quarter as previously expected, Muse said.\n\nTaiwan Semi Getting AI Boost\n\nTaiwan Semiconductor produces chips for fabless semiconductor firms such as AMD, Apple (AAPL), Broadcom (AVGO), Nvidia and Qualcomm (QCOM).\n\nCyclical headwinds overshadowed strength in AI chip production at TSMC in the second quarter, Needham\'s Shi said.\n\nTSMC management expects chips for artificial intelligence to grow to a low-teens percent of sales by 2028 from 6% today.\n\n""Management still sees Q3 as the end of an inventory correction but believes customers may not build inventory back as fast as previously expected,"" Shi said.\n\nTSM Stock On Tech Leaders List\n\nWedbush Securities analyst Matt Bryson kept his outperform rating on TSM stock despite the company\'s disappointing outlook.\n\n""While we believe this deterioration in outlook wasn\'t unexpected, the magnitude of the downtick was more significant than we had anticipated heading into earnings,"" Bryson said in a note to clients.\n\nTSM stock ranks sixth out of 30 stocks in IBD\'s semiconductor manufacturing industry group, according to IBD Stock Checkup. Taiwan Semiconductor has an IBD Composite Rating of 92 out of 99. IBD\'s Composite Rating is a blend of key fundamental and technical metrics to help investors gauge a stock\'s strengths. The best growth stocks have a Composite Rating of 90 or better.\n\nFurther, TSM stock is on the IBD Tech Leaders list.\n\nFollow Patrick Seitz on Twitter at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nChip Gear Maker ASML Beats Second-Quarter Targets, Guides Higher\n\nNetflix Crushes Subscriber Goal As It Turns Freeloaders Into Paying Customers\n\nApple Stock Rises As India Seen Driving Growth For iPhone Maker\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens']",,
"['3e619c5b-8801-886f-1153-21429e404e1b', '6dfdcb26-c454-0d98-c37c-324dd95f3039', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'ff8c03e9-bef1-87c8-227f-25e8d8367361']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'AMD Powers Hitachi Astemo Next-Generation Forward Camera System for Enhanced Vehicle Safety Through AI Object Detection', 'NVDA_7', 'AMD Radeon RX 7800 XT Review', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones']","['AMD Powers Hitachi Astemo Next-Generation Forward Camera System for Enhanced Vehicle Safety Through AI Object Detection\n\nAMD Automotive XA Zynq UltraScale+ MPSoC in Hitachi Astemo stereo camera platform provides a 3X wider detection area than prior generation cameras\n\nSANTA CLARA, Calif., Sept. 05, 2023 (GLOBE NEWSWIRE) -- AMD (NASDAQ: AMD) today announced that leading mobility supplier Hitachi Astemo has selected AMD adaptive computing technology to power its new, stereo-format, forward-looking camera for adaptive cruise control and autonomous emergency braking, improving the vision capabilities and helping to increase the safety of next-generation vehicles. The AMD Automotive XA Zynq™ UltraScale+™ multi-processor system-on-a-chip (MPSoC) provides both stereo and monocular image processing in the camera, enabling it to detect objects over 120 degrees — a 3X wider angle than its previous-generation cameras — to enhance overall safety.\n\n\n\n“The AMD Automotive XA Zynq UltraScale+ MPSoC is incredibly versatile and allows us to add multiple safety-critical features in our forward camera system,” said Makoto Kudo, deputy head of ECU solution business unit, Powertrain and Safety Systems Business Division, Hitachi Astemo Limited. “AMD high-performance, highly scalable, programmable silicon offers distinct benefits for the extremely complex image signal processing requirements of our forward camera system. The flexibility and capabilities of the Zynq UltraScale+ MPSoC platform and its ability to meet stringent functional safety requirements led us to work with AMD.”\n\n“Hitachi Astemo has clearly demonstrated its technological leadership with the development of this stereo forward camera that utilizes AMD adaptive computing technology,” said Yousef Khalilollahi, corporate vice president, APAC Sales, AMD. “Increased safety and accident avoidance are key tenets to automotive technologies, and AMD is proud to offer the foundational technology in these camera systems.”\n\nCamera systems are a critical part of autonomous driving and advanced driver-assistance systems in vehicles. Forward cameras play a key role in these systems, enabling vehicles to reliably detect objects and people. The Hitachi Astemo system powered by AMD combines stereo camera image-processing algorithms with artificial intelligence to provide object detection that will also enable video-based driver-assistance systems.\n\nAMD in Automotive\n\nAs the pace of innovation continues to accelerate in the automotive industry, the need for high-performance compute, compute acceleration and graphics technologies is increasing. AMD is a leader at this inflection point, with a broad line of high-performance CPUs, GPUs, FPGAs and Adaptive SoCs. From powering in-vehicle infotainment systems to advanced driver-assistance systems, autonomous driving and networking applications where functional safety is of paramount importance, AMD provides carmakers with a one-stop shop for silicon and software solutions. For more information, visit the AMD Automotive website.\n\nSupporting Resources:\n\nLearn more about the Zynq UltraScale+ MPSoC product family\n\nFollow AMD on LinkedIn\n\nFollow AMD on Twitter\n\n\n\nAbout AMD\n\nFor more than 50 years AMD has driven innovation in high-performance computing, graphics and visualization technologies. Billions of people, leading Fortune 500 businesses and cutting-edge scientific research institutions around the world rely on AMD technology daily to improve how they live, work and play. AMD employees are focused on building leadership high-performance and adaptive products that push the boundaries of what is possible. For more information about how AMD is enabling today and inspiring tomorrow, visit the AMD (NASDAQ: AMD) website, blog, LinkedIn and Twitter pages.\n\n©2023 Advanced Micro Devices, Inc. All rights reserved. AMD, the AMD Arrow logo, Zynq, UltraScale+, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Other names are for informational purposes only and may be trademarks of their respective owners.\n\nContact:\n\nDavid Szabados\n\nAMD Communications\n\n(408) 472-2439\n\ndavid.szabados@amd.com\n\n\n\nSuresh Bhaskaran\n\nAMD Investor Relations\n\n(408) 749-2845\n\nSuresh.bhaskaran@amd.com\n\n', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure', 'AMD\'s Radeon RX 7000-series graphics cards released to date have brought fierce competition to Nvidia and its GeForce RTX 40-series GPUs. You\'ve likely noticed, though, a massive hole in AMD’s product lineup, with nothing between the $269 AMD Radeon RX 7600 and the $899 AMD Radeon RX 7900 XT. That this state of affairs has gone on for as long as it has is astonishing. But it was likely worth the wait, as the AMD Radeon RX 7700 XT and Radeon RX 7800 XT are both exceptional new GPUs. In this review, we’ll focus on the $499 Radeon RX 7800 XT, and it\'s a winner. Its price and currently unmatched performance give it a dominant position in its slice of the graphics card market, earning it an Editors\' Choice award for 1440p GPUs.\n\nArchitecture: With Navi 32, the Chiplets Are Back\n\nWhen AMD introduced its line of Radeon RX 7000-series graphics cards, it called out three technologies as core components of the new design. First was its new microarchitecture, known as ""RDNA 3,"" and second was a new manufacturing process. Both of these were expected, as such changes happen almost every generation. I covered them in my launch review of the AMD Radeon RX 7900 XTX.\n\n(Credit: Michael Justin Allen Sexton)\n\nThe third technology is the fresh chiplet design, which debuted in the first AMD Radeon RX 7000-series graphics cards. Chiplets don\'t underpin every Radeon RTX 7000-series card, though. After releasing the chiplet-based Radeon RX 7900 XTX and the similar Radeon RX 7900 XT, AMD next released the Radeon RX 7600 with a monolithic chip design. That raised the question of what future cards in the line would look like. Now, we have our answer.\n\nThe Radeon RX 7800 XT is built on a chiplet design akin to the one used in the RX 7900 XTX and the RX 7900 XT. It\'s based around one large chip that is referred to as the Graphics Chip Die (GCD). It measures 200mm2 and contains 60 compute units, giving it 62.5% as many resources as the GCD in the 7900 XTX.\n\n(Credit: Michael Justin Allen Sexton)\n\nAs for cache, the RX 7800 XT also comes with four Memory Cache Dies (MCDs) that measure roughly 37mm2 each, for a total combined area of about 150mm2. Each of these MCDs supports a 64-bit memory interface and 16MB of L2 cache, giving the RX 7800 XT an aggregate 256-bit memory interface and 64MB of L2 cache. AMD fitted the card out with 16GB of GDDR6 memory that operates at 19.5Gbps, enabling 624GBps of total bandwidth. All of this is about two-thirds of what’s available on the Radeon RX 7900 XTX.\n\nFor a more detailed breakdown of the number of ray accelerators, AI accelerators, TMUs, ROPs, and shaders, please see the chart above. Often when we see a drop in the amount of resources, we see a slight increase in clock speed to partially make up for the disparity in shaders. We do not see this with the Radeon RX 7800 XT and instead see a slight drop in clock speed. It tops out at a boost clock of 2,430MHz, compared with the Radeon RX 7900 XTX’s boost of 2,500MHz.\n\n(Credit: Michael Justin Allen Sexton)\n\nWhile all of these reductions make the RX 7800 XT look slower than the 7900 XTX—on paper, and in benchmarks—this is only half of the story. If we take price into consideration, the RX 7800 XT is the most alluring product in AMD’s Radeon RX 7000 series.\n\n(Credit: Michael Justin Allen Sexton)\n\nPut simply, at $499, the AMD Radeon RX 7800 XT costs half as much as the RX 7900 XTX, while packing roughly two-thirds of its resources. This equates to better overall value-per-dollar, and it places the RX 7800 XT in a competitive position in the graphics card market.\n\nAMD\'s Reference Design and FSR 3\n\nFor review, AMD sent us a Radeon RX 7800 XT based on its internally developed reference design. This card is equipped with two internal eight-pin PCIe power connections, and it has three DisplayPort connectors and an HDMI port on its rear I/O panel. The reference card employs a dual-fan thermal solution that\'s just a bit wider than a standard dual-slot card.\n\n(Credit: Michael Justin Allen Sexton)\n\nBefore I move on to testing, I have one last key detail to address: FSR 3. AMD developed FSR 3 in response to Nvidia’s DLSS 3 technology, and it works in a similar way: by generating artificial frames between existing frames to boost overall frame rates.\n\n(Credit: Michael Justin Allen Sexton)\n\nThis feature was introduced alongside the RX 7800 XT, but I have little to say about it at this time. AMD hasn’t shared explicit details (yet) about how this technology works, though it is an open technology and can work with a wide range of graphics cards—from AMD, or otherwise.\n\n(Credit: Michael Justin Allen Sexton)\n\nThough FSR 3 will be available to everyone soon, AMD was not able to provide us with early access to the game files required to test FSR 3 for this review. We’ll need to investigate this feature at a later date.\n\nAMD Radeon RX 7800 XT: Our Test Setup\n\nOur test system for graphics cards is built on an Asus ROG Maximus Z690 Hero motherboard with a stock-clocked Intel Core i9-12900K processor actively cooled by a Corsair Hydro Series H100X water cooler. This lot is paired with 32GB of Corsair Vengeance DDR5 RAM clocked at 5,600MHz, and a 1TB Corsair MP600 Pro NVMe 4.0 SSD for storage. Power is provided by a Corsair HX1500i power supply that is rated 80 Plus Platinum efficient and can supply up to 1,500 watts of power to the system at any given time. All tests were performed inside of Windows 11 Pro with the latest updates installed.\n\nThe pricing dynamics of the graphics card market have been turbulent in recent years, which makes it difficult to describe the Radeon RX 7800 XT\'s exact position at launch. It has the characteristics of a midrange graphics card, which better fits the likes of the RX 7600 and the Nvidia GeForce RTX 4060. It\'s also not a flagship card and is vastly different from the ""high end"" graphics cards we were introduced to at the initial launch of the Radeon RX 7000 and GeForce RTX 40 families. Calling the RX 7800 XT a high-end card still fits best, though high-end has never quite felt so close to the middle.\n\nIn its position as a high-end but not top-end graphics card, the RX 7800 XT comes into closest competition with the Nvidia GeForce RTX 4070, which occupies a similar tier in the graphics card market. However, this too feels like an awkward comparison: Nvidia\'s GeForce RTX 4070 cards start at $599, making that GPU line clearly more expensive than the $499 RX 7800 XT.\n\nAs for pricing, the $499 Nvidia GeForce RTX 4060 Ti 16GB is a better match, but that card and the lesser 8GB RTX 4060 Ti have some notable shortcomings that weaken their position against the RX 7800 XT. (Nvidia points out that a few specific base-model versions of the 16GB RTX 4060 Ti are selling for under MSRP, at $449—which was true at this writing, but most of the 16GB cards were still $500 or more.) All told, the RX 7800 XT undercuts the RTX 4060 Ti line, and with resources that are on a closer level to the RTX 4070\'s.\n\nDetermining exactly how these cards compare is what we have benchmark testing for, of course. But the specs and pricing suggest that the Radeon RX 7800 XT represents one of the best values we\'ve seen in quite some time in the graphics card world. Let\'s see if that bears out.\n\nSynthetic Tests\n\nSynthetic tests allow us to gauge a graphics processor’s raw performance, but they can never tell the full story. Both 3DMark and Furmark show about what we would expect to see, with the RX 7800 XT results coming in fairly close to the RTX 4070, which was still a clear step ahead in all but a few subtests.\n\nLuxMark tests the compute performance of graphics cards, and that test showed an even greater advantage for the RTX 4070. It’s only in Unigine\'s Superposition trial that we saw the RX 7800 XT pull back a bit, coming to a near dead-even tie with the RTX 4070 in the DirectX 11 test and slightly surpassing it when OpenGL is used.\n\nRay Tracing, FSR, and DLSS Game Testing\n\nAMD’s graphics cards are at their deepest disadvantage when it comes to games that support ray tracing. Nvidia has placed a greater emphasis on boosting ray-tracing performance than AMD has up to this point, but even with that advantage, it’s still not an open-and-shut case for Nvidia in ray-tracing games.\n\nIn our first ray-tracing game test (using F1 22), the Radeon RX 7800 XT was able to beat out the GeForce RTX 4060 Ti by roughly 13% at 1080p and about 31% at 4K. It didn’t fare quite as well against the RTX 4070, which surpassed the Radeon RX 7800 XT by as much as 12%. That changed with FSR 1.0 and DLSS 2.0 enabled, handing the advantage back to the RX 7800 XT. DLSS 3 enables the RTX 4070 to pull ahead again, but only at 1440p.\n\nIn Cyberpunk 2077, we saw much the same results as in F1 22, with the Radeon RX 7800 XT outperforming the GeForce RTX 4060 Ti and slightly behind the GeForce RTX 4070 with FSR and DLSS off. We didn’t test this game with DLSS 2, but with DLSS 3 even the significantly slower GeForce RTX 4060 was able to pull ahead of the Radeon RX 7800 XT.\n\nGuardians of the Galaxy has shown a preference for Nvidia-based graphics cards, and we typically see Nvidia cards perform significantly better in this test. Despite this inherent disadvantage, the Radeon RX 7800 XT performed quite well in this test. It was only slightly behind the RTX 4060 Ti in this test at 1080p. The two cards then tied at 1440p, and the RX 7800 XT pulled ahead for a slim 2fps advantage at 4K. The RX 7800 XT had no chance of touching the RTX 4070 this time, however.\n\nWhen Driver Issues Get in the Way\n\nOut of all of the tests I ran, the most disappointing result is one that’s not shown here. I’ve been testing graphics cards with Returnal as I slowly weave it into the standard array of graphics cards tests I use. I’ve never had an issue with this test or game, even while using Intel’s Arc graphics cards—until now.\n\nIn what can only be a driver issue, AMD’s Radeon RX 7800 XT crashed every time I attempted to run Returnal. This was unique to the RX 7800 XT and did not affect any other Radeon cards I put through this test, including the RX 7700 XT, the RX 7600, and the RX 7900 XTX.\n\nThough this gives a poor first impression, it’s necessary to temper any reaction to this issue. The volume of games on the market, even if you just count the ones considered modern AAA titles, is enormous. We expect all of these games to run flawlessly on new hardware, but realistically glitches slip through, which is why we have driver updates. I’m sure that AMD will fix this issue at some point before long, but it is nevertheless disappointing to see from an otherwise class-leading product.\n\nAAA Game Testing\n\nIn games that don’t support ray tracing, the GeForce RTX 40-series cards lose one of their greatest advantages, giving AMD\'s Radeon RX 7800 XT an ever greater chance to shine.\n\nWithout ray tracing, the RX 7800 XT was predictably able to run circles around the RTX 4060 Ti in Total War: Three Kingdoms, Shadow of the Tomb Raider, and Far Cry 5. The one exception to this was in Far Cry 5 at 1080p, which has shown irregular results likely due to some sort of bottleneck on the processor or game engine. At 1440p and 4K, however, the RX 7800 XT was far faster than the RTX 4060 Ti in Far Cry 5, too.\n\nNvidia’s GeForce RTX 4070 didn\'t score a clean win here. Instead it traded places, with the RX 7800 XT performing better in Total War: Three Kingdoms and the RTX 4070 retorting with wins in the other two games.\n\nLegacy Games Testing\n\nOlder games are often challenging for newer graphics cards—not because they lack the performance to run the games, but because these games receive less modern driver support, which can result in reduced performance or even cause games to fail to run.\n\nWe can’t raise any criticism on AMD in this area, however, as all tests ran without issue and performance was overall impressive. The Radeon RX 7800 XT performed well in Bioshock Infinite, trading places with the RTX 4070 once again. In Hitman Absolution, the RX 7800 XT maintained a healthy lead over the RTX 4070 across all three test resolutions. And in Sleeping Dogs, the two cards once again traded places back and forth.\n\nPower and Thermals\n\nWe test the power consumption of our graphics card test bed using a Kill-A-Watt wall meter to gauge the power draw of each card. Only the graphics card and applicable drivers are changed between tests, giving us a decent idea of the power consumption of each card, if not an exact measurement.\n\nPower consumption is one area in which AMD has room to improve relative to its Nvidia competition. The GeForce RTX 4070 performed on a competitive footing with the Radeon RX 7800 XT, but the RTX 4070 had notably lower power consumption numbers in all areas except the idle power draw. The RTX 4060 Ti’s power consumption numbers were even lower.\n\nThermal readings were also higher for the Radeon RX 7800 XT card, which was somewhat disappointing as the RX 7900 XT fared significantly better in this area. This suggests the cooler was responsible for the lackluster temp readings on the RX 7800 XT, as it has a less robust thermal solution than the RX 7900 XT\'s. This situation could be significantly better on some cards made by AMD’s board partners, with some cards perhaps outfitted with more-robust cooling schemes. But for now, all we can do is speculate on that front.\n\nWe should be clear, however, that the thermal readings on the RX 7800 XT weren’t terrible. The 69 degrees C thermal reading is well within the safe operating range for the card and acceptable for continuous use.\n\nVerdict: AMD\'s Best Effort of the 7000s\n\nThough the AMD Radeon RX 7800 XT ran a little warm and used a bit more power than we may have liked, it’s hard for us to fault the card for this or on any other front. Price and performance are always the most important factors for desktop components, and the Radeon RX 7800 XT excels at both.\n\n(Credit: Michael Justin Allen Sexton)\n\nWhen discussing components, it’s necessary to take a broader look to understand a product\'s place in the market. Sometimes, we can let the numbers speak for themselves: The Radeon RX 7800 XT best compares with Nvidia’s GeForce RTX 4070 in terms of performance, but the RX 7800 XT costs $100 less. When the performance is so frequently on a near-even footing or possibly even better on the cheaper card, what reason do you have to buy the more expensive one? Sure, the RTX 4070 is occasionally faster, but neither consistently nor overwhelmingly, and even in those cases the speed spread still isn’t enough to justify the added expense.\n\nThe second-closest competing Nvidia graphics card to the Radeon RX 7800 XT is the Nvidia GeForce RTX 4060 Ti, but if anything, that comparison looks much worse for Nvidia here. The RTX 4060 Ti has an MSRP of $399 for cards that ship with 8GB of GDDR6 RAM, and cards with 16GB of RAM are $499-plus (with the exception of the few basic $449 models). Even pitted against the 16GB GeForce RTX 4060 Ti, the RX 7800 XT remains the more attractive deal.\n\nIndeed, AMD\'s Radeon RX 7800 XT is significantly faster than the 8GB RTX 4060 Ti in almost every test, and in this case the performance difference is more than sufficient to justify the $100 premium. This situation only worsens if you look closely at tests running at 1440p and 4K, as the 8GB RTX 4060 Ti is held back by a limited memory interface that cramps its performance above 1080p. This is why Nvidia markets the 8GB card for 1080p play...but $399 is rather much for that level of play.\n\nDue to this limitation, the performance advantage held by the Radeon RX 7800 XT over the RTX 4060 Ti only increases as the resolution goes up. The RX 7800 XT does not suffer from any such handicap, and if you needed any more reason to opt for the RX 7800 XT over the RTX 4060 Ti, this should be it.\n\nWhat about AMD\'s competition from within its own house? With two-thirds the resources at half the price of the AMD Radeon RX 7900 XTX, the RX 7800 XT is clearly a better value than AMD’s flagship on a per-dollar basis. It even edges out the Radeon RX 7600 with a slightly lower price per compute unit, and that’s not even considering the improved memory system on the RX 7800 XT.\n\nTo sweeten the deal further, AMD now (at the time of writing) includes a copy of Starfield: Premium Edition with all Radeon RX 7800 XT graphics cards at launch. This version of the game, which includes an expansion to the base game along with a skin pack and access to digital art and original soundtracks, retails for $99.99 — not a bad deal at all.\n\nEverything you see here suggests that the Radeon RX 7800 XT will be AMD\'s best graphics card of this generation, earning it our Editors\' Choice award for 1440p gaming. Until Nvidia adjusts its prices, or releases a new card to combat it, the Radeon RX 7800 XT stands as the only graphics card worth recommending between the $299 Nvidia GeForce RTX 4060 and the $899 AMD Radeon RX 7900 XT for the foreseeable future.\n\nAMD Radeon RX 7800 XT 4.5 Editors\' Choice See It $489.99 at Amazon MSRP $499.99 Pros Exceptional performance for price\n\nCompetitive price undercuts GeForce competition\n\nPlenty of memory bandwidth\n\n16GB GDDR6 memory View More Cons Slightly high power draw\n\nLaunch driver crashed with AAA title Returnal The Bottom Line Rivaling the Nvidia GeForce RTX 4070 for a lot less cash, the AMD Radeon RX 7800 XT is an exceptional value and the first graphics card you should consider between $300 and $900.']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', 'b451c4ec-73a0-5a0d-e2bf-49d2e1a1859a', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'eba8dc9d-1ab8-8485-21c5-6e3054f5545d']","['AMD Issues Second Statement on Ryzen 7000 Burnout Issues: Caps SoC Voltages', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'META_7', 'New – Amazon EC2 Hpc7a Instances Powered by 4th Gen AMD EPYC Processors Optimized for High Performance Computing', 'NVDA_7']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Yesterday, AMD issued a statement surrounding the burnout issues some users have been experiencing with their Ryzen 7000X3D processors. The problem, reported in multiple Reddit subforums, includes some Ryzen 7000X3D CPUs burning out part of the chip, and damaging the AM5 socket in the process. This morning, AMD has released a second statement regarding the issue, including what it is doing to rectify the problem and put Ryzen 7000 processor owners at ease.\n\nThe official statement from AMD is as follows:\n\n""We have root caused the issue and have already distributed a new AGESA that puts measures in place on certain power rails on AM5 motherboards to prevent the CPU from operating beyond its specification limits, including a cap on SOC voltage at 1.3V. None of these changes affect the ability of our Ryzen 7000 Series processors to overclock memory using EXPO or XMP kits or boost performance using PBO technology. We expect all of our ODM partners to release new BIOS for their AM5 boards over the next few days. We recommend all users to check their motherboard manufacturers website and update their BIOS to ensure their system has the most up to date software for their processor. Anyone whose CPU may have been impacted by this issue should contact AMD customer support. Our customer service team is aware of the situation and prioritizing these cases.""\n\nTo counteract the problem, AMD has apparently identified an issue with specific chip voltages going too high when users enable AMD\'s EXPO memory profiles. A new cap on SoC voltages looks to be the primary change in the AGESA firmware rollout.\n\nHowever, AMD\'s broad statement mentions that the update will address multiple power rails, which implies to some degree that the issue may be more than just the SoC power rail – or at least, that AMD isn\'t taking any chances. So what this entirely means is still a bit up in the air, as AMD hasn\'t specified in detail what it\'s doing outside of SoC power limits to prevent Ryzen CPUs from exceeding their specification limits.\n\nTechnically speaking, enabling EXPO memory profiles is a form of overclocking – i.e. operating the processor outside of specifications – as AMD\'s Ryzen 7000 family only officially supports DDR5 memory up to DDR5-5200 speeds. So going past this is putting additional stress on the memory controller in terms of clockspeeds; but the greater concern is how the various voltages on the chip are being adjusted to keep up with the demands of higher memory speeds.\n\nOne interesting point about AMD\'s statement is that it doesn\'t allude to whether or not the issue is just on its Ryzen 7000X3D processors, or whether it affects all of its Ryzen 7000 processors entirely. Regardless of the Zen 4 chip that users may have, AMD is ambiguous in its language, and it seems to be that AMD is recommended that all users with a Ryzen 7000 series processor should update to the latest firmware.\n\nIn practice, enabling EXPO memory profiles on compatible DRAM does seem to push SoC voltages beyond AMD\'s safe spot on the Ryzen 7000 processors, which AMD is treating as part of the cause of the burnout issue. AMD does, however, state that the changes it has made to their AGESA firmware, once flashed, shouldn\'t affect the user\'s ability to apply EXPO memory profiles on compatible kits of DDR5 memory. Which does raise the question of why motherboards were increasing SoC voltages in the first place, as presumably this shouldn\'t be needed if AMD\'s new caps won\'t limit EXPO memory overclocking.\n\nIn any case, AMD is actively working with its motherboard partners to release a new AGESA firmware with the new voltage limits, which they say has already been distributed. AMD claims that all AM5 motherboard vendors and models should have a new BIOS version available to them within the next few days, and is recommending all users to update their BIOS at their earliest convenience.\n\nImage source: Speedrookie/Reddit', 'In January 2022, we launched Amazon EC2 Hpc6a instances for customers to efficiently run their compute-bound high performance computing (HPC) workloads on AWS with up to 65 percent better price performance over comparable x86-based compute-optimized instances.\n\nAs their jobs grow more complex, customers have asked for more cores with more compute performance and more memory and network performance to reduce the time to complete jobs. Additionally, as customers look to bring more of their HPC workloads to EC2, they have asked how we can make it easier to distribute processes to make the best use of memory and network bandwidth, to align with their workload requirements.\n\nToday, we are announcing the general availability of Amazon EC2 Hpc7a instances, the next generation of instance types that are purpose-built for tightly coupled HPC workloads. Hpc7a instances powered by the 4th Gen AMD EPYC processors (Genoa) deliver up to 2.5 times better performance compared to Hpc6a instances. These instances offer 300 Gbps Elastic Fabric Adapter (EFA) bandwidth powered by the AWS Nitro System, for fast and low-latency internode communications.\n\nHpc7a instances feature Double Data Rate 5 (DDR5) memory, which provides 50 percent higher memory bandwidth compared to DDR4 memory to enable high-speed access to data in memory. These instances are ideal for compute-intensive, latency-sensitive workloads such as computational fluid dynamics (CFD) and numerical weather prediction (NWP).\n\nIf you are running on Hpc6a, you can use Hpc7a instances and take advantage of the 2 times higher core density, 2.1 times higher effective memory bandwidth, and 3 times higher network bandwidth to lower the time needed to complete jobs compared to Hpc6a instances.\n\nHere’s a quick infographic that shows you how the Hpc7a instances and the 4th Gen AMD EPYC processor (Genoa) compare to the previous instances and processor:\n\nHpc7a instances feature sizes of up to 192 cores of the AMD EPYC processors CPUs with 768 GiB RAM. Here are the detailed specs:\n\nInstance Name CPUs RAM (Gib)\n\nEFA Network Bandwidth (Gbps)\n\nAttached Storage Hpc7a.12xlarge 24 768 Up to 300 EBS Only Hpc7a.24xlarge 48 768 Up to 300 EBS Only Hpc7a.48xlarge 96 768 Up to 300 EBS Only Hpc7a.96xlarge 192 768 Up to 300 EBS Only\n\nThese instances provide higher compute, memory, and network performance to run the most compute-intensive workloads, such as CFD, weather forecasting, molecular dynamics, and computational chemistry on AWS.\n\nSimilar to EC2 Hpc7g instances released a month earlier, we are offering smaller instance sizes that makes it easier for customers to pick a smaller number of CPU cores to activate while keeping all other resources constant based on their workload requirements. For HPC workloads, common scenarios include providing more memory bandwidth per core for CFD workloads, allocating fewer cores in license-bound scenarios, and supporting more memory per core. To learn more, see Instance sizes in the Amazon EC2 Hpc7 family – a different experience in the AWS HPC Blog.\n\nAs with Hpc6a instances, you can use the Hpc7a instance to run your largest and most complex HPC simulations on EC2 and optimize for cost and performance. You can also use the new Hpc7a instances with AWS Batch and AWS ParallelCluster to simplify workload submission and cluster creation. You can also use Amazon FSx for Lustre for submillisecond latencies and up to hundreds of gigabytes per second of throughput for storage.\n\nTo achieve the best performance for HPC workloads, these instances have Simultaneous Multithreading (SMT) disabled, they’re available in a single Availability Zone, and they have limited external network and EBS bandwidth.\n\nNow Available\n\nAmazon EC2 Hpc7a instances are available today in three AWS Regions: US East (Ohio), EU (Ireland), and US GovCloud for purchase in On-Demand, Reserved Instances, and Savings Plans. For more information, see the Amazon EC2 pricing page.\n\nTo learn more, visit our Hpc7a instances page and get in touch with our HPC team, AWS re:Post for EC2, or through your usual AWS Support contacts.\n\n— Channy', 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '98bbf6ab-43a5-bbd3-0b3e-b06c74380463', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'ce697c3b-c8d1-f695-d9f0-a370d118583c', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['AMD_1', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'META_7', 'NVDA_7', 'MSFT_1']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', 'Organizations purchase perpetual licenses or subscribe to licenses. SA is optional for customers that purchase perpetual licenses. PART I Item 1 &#160; Open Value Open Value agreements are a simple, cost-effective way to acquire the latest Microsoft technology. These agreements are designed for small and medium organizations that want to license cloud services and on-premises software over a three-year period. Under Open Value agreements, organizations can elect to purchase perpetual licenses or subscribe to licenses and SA is included. Select Plus A Select Plus agreement is designed for government and academic organizations to acquire on-premises licenses at any affiliate or department level, while realizing advantages as one organization. Organizations purchase perpetual licenses and SA is optional. Partner Programs The Microsoft Cloud Solution Provider Program offers customers an easy way to license the cloud services they need in combination with the value-added services offered by their systems integrator, managed services provider, or cloud reseller partner. Partners in this program can easily package their own products and services to directly provision, manage, and support their customer subscriptions. The Microsoft Services Provider License Agreement allows hosting service providers and independent software vendors who want to license eligible Microsoft software products to provide software services and hosted applications to their end customers. Partners license software over a three-year period and are billed monthly based on consumption. The Independent Software Vendor Royalty Program enables partners to integrate Microsoft products into other applications and then license the unified business solution to their end users. CUSTOMERS Our customers include individual consumers, small and medium organizations, large global enterprises, public-sector institutions, Internet service providers, application developers, and OEMs. Our practice is to ship our products promptly upon receipt of purchase orders from customers; consequently, backlog is not significant. INFORMATION ABOUT OUR EXECUTIV E OFFICERS Our executive officers as of July 27, 2023 were as follows: &#160; ##TABLE_START Name Age Position with the Company &#160; &#160; &#160; Satya Nadella Chairman and Chief Executive Officer Judson B. Althoff &#160; &#160; Executive Vice President and Chief Commercial Officer Christopher C. Capossela Executive Vice President and Chief Marketing Officer Kathleen T. Hogan Executive Vice President and Chief Human Resources Officer Amy E. Hood Executive Vice President and Chief Financial Officer Bradford L. Smith Vice Chair and President Christopher D. Young &#160; &#160; Executive Vice President, Business Development, Strategy, and Ventures ##TABLE_END Mr. Nadella was appointed Chairman of the Board in June 2021 and Chief Executive Officer in February 2014. He served as Executive Vice President, Cloud and Enterprise from July 2013 until that time. From 2011 to 2013, Mr. Nadella served as President, Server and Tools. From 2009 to 2011, he was Senior Vice President, Online Services Division. From 2008 to 2009, he was Senior Vice President, Search, Portal, and Advertising. Since joining Microsoft in 1992, Mr. Nadella&#8217;s roles also included Vice President of the Business Division. Mr. Nadella also serves on the Board of Directors of Starbucks Corporation. Mr. Althoff was appointed Executive Vice President and Chief Commercial Officer in July 2021. He served as Executive Vice President, Worldwide Commercial Business from July 2017 until that time. Prior to that, Mr. Althoff served as the President of Microsoft North America. Mr. Althoff joined Microsoft in March 2013 as President of Microsoft North America. PART I Item 1 &#160; Mr. Capossela was appointed Executive Vice President, Marketing and Consumer Business, and Chief Marketing Officer in July 2016. He had served as Executive Vice President, Chief Marketing Officer since March 2014.Since joining Microsoft in 1991, Mr. Capossela has held a variety of marketing leadership roles in the Consumer Channels Group, and in the Microsoft Office Division where he was responsible for marketing productivity solutions including Microsoft Office, Office 365, SharePoint, Exchange, Skype for Business, Project, and Visio. Ms. Hogan was appointed Executive Vice President, Human Resources in November 2014. Prior to that Ms. Hogan was Corporate Vice President of Microsoft Services. She also served as Corporate Vice President of Customer Service and Support. Ms. Hogan joined Microsoft in 2003. Ms. Hogan also serves on the Board of Directors of Alaska Air Group, Inc. Ms. Hood was appointed Executive Vice President and Chief Financial Officer in July 2013, subsequent to her appointment as Chief Financial Officer in May 2013. From 2010 to 2013, Ms. Hood was Chief Financial Officer of the Microsoft Business Division. Since joining Microsoft in 2002, Ms. Hood has also held finance-related positions in the Server and Tools Business and the corporate finance organization. Ms. Hood also serves on the Board of Directors of 3M Corporation. Mr. Smith was appointed Vice Chair and President in September 2021. Prior to that, he served as President and Chief Legal Officer since September 2015. He served as Executive Vice President, General Counsel, and Secretary from 2011 to 2015, and served as Senior Vice President, General Counsel, and Secretary from 2001 to 2011. Mr. Smith was also named Chief Compliance Officer in 2002. Since joining Microsoft in 1993, he was Deputy General Counsel for Worldwide Sales and previously was responsible for managing the European Law and Corporate Affairs Group, based in Paris. Mr. Smith also serves on the Board of Directors of Netflix, Inc. Mr. Young has served as Executive Vice President, Business Development, Strategy, and Ventures since joining Microsoft in November 2020. Prior to Microsoft, he served as the Chief Executive Officer of McAfee, LLC from 2017 to 2020, and served as a Senior Vice President and General Manager of Intel Security Group from 2014 until 2017, when he led the initiative to spin out McAfee into a standalone company. Mr. Young also serves on the Board of Directors of American Express Company. PART I Item 1 &#160; AVAILABLE INFORMATION Our Internet address is www.microsoft.com. At our Investor Relations website, www.microsoft.com/investor, we make available free of charge a variety of information for investors. Our goal is to maintain the Investor Relations website as a portal through which investors can easily find or navigate to pertinent information about us, including: &#8226; Our annual report on Form 10-K, quarterly reports on Form 10-Q, current reports on Form 8-K, and any amendments to those reports, as soon as reasonably practicable after we electronically file that material with or furnish it to the Securities and Exchange Commission (&#8220;SEC&#8221;) at www.sec.gov. ', 'Our AMD Ryzen Z1 Series processors bring high-performance to handheld Windows-based PC gaming platforms. These processors feature &#8220;Zen 4&#8221; processor technology combined with RDNA 3 graphics to deliver fast PC gaming, incredible battery life, and immersive experiences in handheld systems. Commercial CPUs. We offer enterprise-class desktop and mobile PC solutions sold as AMD PRO Mobile and AMD PRO desktop processors with Radeon&#8482; graphics for the commercial market. AMD Ryzen PRO, AMD Threadripper PRO and AMD Athlon PRO processors solutions are designed to provide enterprise customers with the performance, security capabilities and business features such as enhanced security and manageability, platform longevity and extended image stability. Our AMD Ryzen Threadripper PRO 7000 WX-Series processors with &#8220;Zen 4&#8221; core architecture and 5000 WX-Series processors with &#8220;Zen 3&#8221; core architecture provide full-spectrum performance across multiple workstation workloads due to the performance and efficiency of the Zen CPU core with core count scaling up to 96 cores in the 7000 WX-Series. Our Ryzen PRO 7040 Series Mobile processors are built on &#8220;Zen 4&#8221; architecture, AMD RDNA 3 integrated graphics, AMD PRO technologies and Ryzen AI, on select models. Our AMD Ryzen Threadripper PRO 7000 WX-Series processors are built on 5 nm &#8220;Zen 4&#8221; architecture. Chipsets. We offer a full suite of chipset products to support our AMD Ryzen and Threadripper platforms, including chipsets for the AM5 socket like the X670 chipsets which support PCIe &#174; 5.0 (fifth generation Peripheral Component Interconnect Express motherboard interface) designed for enthusiast desktop platforms. In the AM5 platform we also offer B650 chipsets to enable a broader range of solutions in the market. In the AM4 ecosystem for 5000-series processors and prior, we offer the X570, B550 and A520 chipsets. In addition, we continue to offer the B450 chipsets that are combined with AMD Ryzen processors for the AM4 desktop platform for the performance and affordable mainstream platforms segments. In HEDT and Workstation segments, we offer the WRX90 and TRX50 chipsets to support 7000-series Threadripper and Threadripper PRO platforms, as well as the WRX80 chipsets to support the 5000-series Threadripper PRO platforms. Gaming Segment Gaming Market Graphics processing is a fundamental component across many of our products and can be found in APU, GPU, SoC or a combination of a discrete GPU with another product working in tandem. Our customers generally use our graphics solutions to enable or increase the speed of rendering images, to help improve image resolution and color definition and/or to process AI/ML based workloads. We develop our graphics products for use in various computing devices and entertainment platforms, including desktop PCs, notebook PCs, handheld PCs, All-in-Ones (AIOs), professional workstations, and the data center. With each of our graphics products, we have available drivers and supporting software packages that enable the effective use of these products under a variety of operating systems and applications. We have developed AMD RDNA&#8482; 3, a high performing and power efficient graphics architecture, featuring a chiplet design, AI accelerators and the Radiance Display&#8482; Engine. This generation continues to support advanced graphics features introduced with RDNA 2, such as ray tracing, AMD Infinity Cache&#8482; and variable rate shading. The Sony PlayStation &#174; 5 and Microsoft &#174; Xbox Series S&#8482; and X&#8482; game consoles also feature our RDNA graphics architecture. Our APUs deliver visual processing functionality for value and mainstream PCs by integrating a CPU and a GPU on a single chip, while discrete GPUs (which are also known as dGPUs) offer high-performance graphics processing across all platforms. We leverage our core IP, including our graphics and processing technologies to develop semi-custom solutions. Here, semiconductor suppliers work alongside system designers and manufacturers to enhance the performance and overall user experience for semi-custom customers. We have used this collaborative co-development approach with many of today&#8217;s leading game console and handheld PC gaming manufacturers and can also address customer needs in many other markets. We leverage our existing IP to create a variety of products tailored to a specific customer&#8217;s needs, including complex fully-customized SoCs to more modest adaptations and integrations of existing CPU, APU or GPU products. Gaming Products Semi-Custom Products. Our semi-custom products are tailored, high-performance, customer-specific solutions based on our CPU, GPU and multi-media technologies. We work closely with our customers to define solutions to precisely match the requirements of the device or application. We developed the semi-custom SoC products that power both the Sony PlayStation 5 as well as the Microsoft Xbox Series S and X game consoles. We partnered with Valve to create a semi-custom APU optimized for handheld gaming to power the Steam Deck&#8482;. Discrete Desktop and Notebook GPUs . Our AMD Radeon series discrete GPU processors for desktop and notebook PCs support current generation application program interfaces (APIs) like DirectX&#174; 12 Ultimate and Vulkan &#174; , support high-refresh rate displays using AMD FreeSync&#8482;, AMD FreeSync Premium, and AMD FreeSync Premium Pro technologies, and are designed to support VR in PC platforms. Our AMD Radeon Software offers performance enhancing tools and enables new features and customization capabilities to customers and end-users. In addition, we also offer tools for game developers such as our AMD FidelityFX&#8482; open-source image quality software toolkit that helps deliver improved visual quality with minimal performance overhead. FidelityFX Super Resolution (FSR) uses upscaling technologies to help boost frame rates in games. Our FSR 2.0 technology uses temporal data and optimized anti-aliasing to boost frame rates in supported games while delivering similar or better image quality than native resolution without the requirement of dedicated machine learning hardware. Our FSR 3.0 technology combines the upscaling features of prior versions while introducing our AMD Fluid Motion Frames Technology which generates interpolated frames between native frames to increase the frame rate of games for a smoother gaming experience. Varying versions of FSR are supported in over 250 games and multiple products including Radeon GPUs, Ryzen APUs, and many of our Semi-custom solutions. Being an open-source technology FSR works across competing hardware solutions as well. Our AMD Radeon RX 7000 series are built on the high-performance, energy-efficient AMD RDNA3 architecture which provides up to 96 compute units, second generation high-bandwidth, low-latency AMD Infinity Cache technology as well as dedicated AI and ray tracing hardware. ']",,
"['25c2084b-d2c7-2c1d-2bdf-5ac4b97e8d7e', '386fd3d7-310a-a488-bbdd-a0f50bd371e7', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","[""TSM and Jersey Mike's cook up multi-year esports partnership"", 'NVDA_7', 'NVDA_1']","['TSM, the premier championship esports organization, and Jersey Mike’s, known for its fresh sliced/fresh grilled subs, have set a three-year, North American partnership, making Jersey Mike\'s the official Sub Sandwich of TSM.\n\nWhile the key ingredients of branding and content production are baked in to the partnership, this made-to-order deal brings TSM and Jersey Mike\'s fans alike loads of meaty offerings, including:\n\n● A freshly-made fan sweepstakes offering the chance to win epic prizes\n\n● The tasty “Subs for Subs” initiative where Jersey Mike\'s will gift thousands of subscriptions and free subs to up-and-coming Twitch streamers to grow their audiences and support their dreams of becoming full time content creators.\n\n● A custom crafted Jersey Mike\'s Blitz Arena on TSM\'s esports coaching app Blitz\n\nAnd in keeping with both organizations’ desires to give back to their community, this collaboration also funds a unique, first-of-its-kind internship program. Students from TSM partner campuses, Jersey Mike\'s university partners and HBCUs will have the opportunity for hands-on experience in the gaming business including working at an esports-focused event.\n\n“This partnership stands for everything our fans crave- and it will leave them hungry for more!” said TSM CRO Stephan Cieplik. “Jersey Mike\'s commitment to quality and excellence aligns with our own values at TSM, and we look forward to bringing this partnership to life with authentic activations to engage with our fans, gamers and streamers.”\n\n“TSM is a leader in the esports industry and we are honored to partner with them,"" said Rich Hope, Chief Marketing Officer, Jersey Mike’s Franchise Systems, Inc. “We are excited to bring our delicious subs to the TSM community and support the next generation of esports stars through our internship program.”\n\nAbout TSM\n\nTSM is an elite, holistic gaming brand composed of championship esports teams, world-class influencers, and gaming strategy platforms that level up the casual player all the way to the professional. A platform of champions, TSM seeks to provide maximum value through the competitive excellence of its teams and the creation of exciting, educational, and entertaining content that deliver the ultimate esports and gaming fan experience. For more: tsm.gg.\n\nAbout Jersey Mike’s Subs\n\nJersey Mike’s Subs, with nearly 2,500 locations nationwide, serves authentic fresh sliced/fresh grilled subs on in-store freshly baked bread — the same recipe it started with in 1956. Passion for giving in Jersey Mike’s local communities is reflected in its mission statement “Giving…making a difference in someone’s life.” For more information, please visit jerseymikes.com or follow us on Facebook, Instagram, and Twitter.', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Mr. Puri previously held marketing, management consulting, and product development positions at Hewlett-Packard, an information technology company, Booz Allen Hamilton Inc., a management and technology consulting company, and Texas Instruments Incorporated. Mr. Puri holds a B.S.E.E. degree from the University of Minnesota, an M.S.E.E. degree from the California Institute of Technology and an M.B.A. degree from Harvard Business School. Debora Shoquist joined NVIDIA in 2007 as Senior Vice President of Operations and in 2009 became Executive Vice President of Operations. Prior to NVIDIA, Ms. Shoquist served from 2004 to 2007 as Executive Vice President of Operations at JDS Uniphase Corp., a provider of communications test and measurement solutions and optical products for the telecommunications industry. She served from 2002 to 2004 as Senior Vice President and General Manager of the Electro-Optics business at Coherent, Inc., a manufacturer of commercial and scientific laser equipment. Previously, she worked at Quantum Corp., a data protection company, as President of the Personal Computer Hard Disk Drive Division, and at Hewlett-Packard. Ms. Shoquist holds a B.S. degree in Electrical Engineering from Kansas State University and a B.S. degree in Biology from Santa Clara University. Timothy S. Teter joined NVIDIA in 2017 as Senior Vice President, General Counsel and Secretary and became Executive Vice President, General Counsel and Secretary in February 2018. Prior to NVIDIA, Mr. Teter spent more than two decades at the law firm of Cooley LLP, where he focused on litigating patent and technology related matters. Prior to attending law school, he worked as an engineer at Lockheed Missiles and Space Company, an aerospace company. Mr. Teter holds a B.S. degree in Mechanical Engineering from the University of California at Davis and a J.D. degree from Stanford Law School. Available Information Our annual reports on Form 10-K, quarterly reports on Form 10-Q, current reports on Form 8-K and, if applicable, amendments to those reports filed or furnished pursuant to Section 13(a) or 15(d) of the Securities Exchange Act of 1934, as amended, or the Exchange Act, are available free of charge on or through our website, http://www.nvidia.com , as soon as reasonably practicable after we electronically file such material with, or furnish it to, the Securities and Exchange Commission, or the SEC. The SEC&#8217;s website, http://www.sec.gov , contains reports, proxy and information statements, and other information regarding issuers that file electronically with the SEC. Our web site and the information on it or connected to it are not a part of this Annual Report on Form 10-K. ']",,
"['0870abb5-2ad8-0efc-2b2c-cac74fa92b6f', '2113a3c7-6535-c732-d98c-787721cb9f55', 'b37b3a8a-5802-0bfe-fc98-64ec70a185da', 'b78da971-cede-623b-d604-234e42dda7f8', 'ca5f358e-4ab4-12da-ae89-99040cbc1fce']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'Mark Zuckerberg announces new team at Meta working on A.I. products for Instagram, WhatsApp', 'After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees', 'META_1A', 'META_7']","['Mark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work force and struggled to gain mainstream traction with its ambitious plans for virtual reality.\n\nOn Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, Mr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta’s work in artificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\n\nMr. Zuckerberg’s talk was an attempt to rally staff after the most tumultuous period in his company’s 19-year history. The chief executive said he made “tough decisions” about layoffs with the goal of “building a better technology company” that shipped better products, faster — something he believed Meta wasn’t doing well as it swelled to more than 80,000 employees at the peak of the pandemic.\n\n“I want us to use this period that’s going to be a bit more stable in order to evolve and rebuild our culture,” he said, according to two people who attended the meeting and shared remarks and a recording with The New York Times.', 'Founder and CEO of US online social media and social networking service Facebook Mark Zuckerberg reacts upon his arrival for a meeting with European Commission vice-president in charge for Values and Transparency, in Brussels, on February 17, 2020.\n\nMeta will create a new product group inside the company focused on generative AI, a new set of machine learning techniques that allow computers to generate text, draw pictures, and create other media that resemble human output.\n\nThe move comes as big tech companies and well-capitalized startups alike race to tout advances in machine learning techniques and incorporate artificial intelligence models into their products.\n\nThe unit will combine several teams across Meta, CEO Mark Zuckerberg said in a Facebook post. The new group will be organized under current Chief Product Officer Chris Cox.\n\nZuckerberg said that the team would build ""creative and expressive"" tools to be used inside Meta\'s products.\n\n""We\'re exploring experiences with text (like chat in WhatsApp and Messenger), with images (like creative Instagram filters and ad formats), and with video and multi-modal experiences,"" Zuckerberg said. ""We have a lot of foundational work to do before getting to the really futuristic experiences, but I\'m excited about all of the new things we\'ll build along the way.""\n\nFor example, large language models created by OpenAI have been integrated into a Microsoft Bing chatbot as well as a separate chatbot called ChatGPT. Google is also working on a chatbot named Bard.\n\nOn Monday, Snap announced that it would integrate a ChatGPT bot into its Snapchat app.\n\nLast week, Meta announced its own new large language model called LLaMA. Meta said at the time that its models are distinguished because they are available to researchers and that they are smaller and less expensive to use than larger models.\n\nBut the announcement was also a sign that Meta, which does a significant amount of research into artificial intelligence, was not going to let competitors pass it by in the AI race.', 'For example, as a result of limited visibility into encrypted products, we have fewer data signals from WhatsApp user accounts and primarily rely on phone numbers and device information to match WhatsApp user accounts with accounts on our other products. Any loss of access to data signals we use in our process for calculating Family metrics, whether as a result of our own product decisions, actions by third-party browser or mobile platforms, regulatory or legislative requirements, or other factors, also may impact the stability or accuracy of our reported Family metrics, as well as our ability to report these metrics at all. Our estimates of Family metrics also may change as our methodologies evolve, including through the application of new data signals or technologies, product changes, or other improvements in our user surveys, algorithms, or machine learning that may improve our ability to match accounts within and across our products or otherwise evaluate the broad population of our users. In addition, such evolution may allow us to identify previously undetected violating accounts (as defined below). We regularly evaluate our Family metrics to estimate the percentage of our MAP consisting solely of ""violating"" accounts. We define ""violating"" accounts as accounts which we believe are intended to be used for purposes that violate our terms of service, including bots and spam. In the fourth quarter of 2023, we estimated that approximately 3% of our worldwide MAP consisted solely of violating accounts. Such estimation is based on an internal review of a limited sample of accounts, and we apply significant judgment in making this determination. For example, we look for account information and behaviors associated with Facebook and Instagram accounts that appear to be inauthentic to the reviewers, but we have Table of Contents limited visibility into WhatsApp user activity due to encryption. In addition, if we believe an individual person has one or more violating accounts, we do not include such person in our violating accounts estimation as long as we believe they have one account that does not constitute a violating account. From time to time, we disable certain user accounts, make product changes, or take other actions to reduce the number of violating accounts among our users, which may also reduce our DAP and MAP estimates in a particular period. Violating accounts are very difficult to measure at our scale, and it is possible that the actual number of violating accounts may vary significantly from our estimates. We also regularly evaluate our Facebook metrics to estimate the number of ""duplicate"" and ""false"" accounts among our MAUs. A duplicate account is one that a user maintains in addition to his or her principal account. We divide ""false"" accounts into two categories: (1) user-misclassified accounts, where users have created personal profiles for a business, organization, or non-human entity such as a pet (such entities are permitted on Facebook using a Page rather than a personal profile under our terms of service); and (2) violating accounts, which represent user profiles that we believe are intended to be used for purposes that violate our terms of service, such as bots and spam. The estimates of duplicate and false accounts are based on an internal review of a limited sample of accounts, and we apply significant judgment in making this determination. For example, to identify duplicate accounts we use data signals such as identical IP addresses and similar user names, and to identify false accounts we look for names that appear to be fake or other behavior that appears inauthentic to the reviewers. Any loss of access to data signals we use in this process, whether as a result of our own product decisions, actions by third-party browser or mobile platforms, regulatory or legislative requirements, or other factors, also may impact the stability or accuracy of our estimates of duplicate and false accounts. Our estimates also may change as our methodologies evolve, including through the application of new data signals or technologies or product changes that may allow us to identify previously undetected duplicate or false accounts and may improve our ability to evaluate a broader population of our users. Duplicate and false accounts are very difficult to measure at our scale, and it is possible that the actual number of duplicate and false accounts may vary significantly from our estimates. In the fourth quarter of 2023, we estimated that duplicate accounts may have represented approximately 10% of our worldwide MAUs. We believe the percentage of duplicate accounts is meaningfully higher in developing markets such as the Philippines and Vietnam, as compared to more developed markets. In the fourth quarter of 2023, we estimated that false accounts may have represented approximately 4% of our worldwide MAUs. Our estimation of false accounts can vary as a result of episodic spikes in the creation of such accounts, which we have seen originate more frequently in specific countries such as Indonesia, Vietnam, and Nigeria. From time to time, we disable certain user accounts, make product changes, or take other actions to reduce the number of duplicate or false accounts among our users, which may also reduce our DAU and MAU estimates in a particular period. Other data limitations also may affect our understanding of certain details of our business. For example, while user-provided data indicates a decline in usage among younger users, this age data may be unreliable because a disproportionate number of our younger users register with an inaccurate age. Accordingly, our understanding of usage by age group may not be complete. In addition, our data regarding the geographic location of our users is estimated based on a number of factors, such as the user\'s IP address and self-disclosed location. These factors may not always accurately reflect the user\'s actual location. For example, a user may appear to be accessing Facebook from the location of the proxy server that the user connects to rather than from the user\'s actual location. The methodologies used to measure our metrics are also susceptible to algorithm or other technical errors, and our estimates for revenue by user location and revenue by user device are also affected by these factors. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure', 'See Note 3 &#8212; Restructuring in the notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K for additional information regarding restructuring charges. Family of Apps Metrics &#8226; Family daily active people (DAP) was 3.19 billion on average for December 2023, an increase of 8% year-over-year. &#8226; Family monthly active people (MAP) was 3.98 billion as of December 31, 2023, an increase of 6% year-over-year. &#8226; Facebook daily active users (DAUs) were 2.11 billion on average for December 2023, an increase of 6% year-over-year. &#8226; Facebook monthly active users (MAUs) were 3.07 billion as of December 31, 2023, an increase of 3% year-over-year. &#8226; Ad impressions delivered across our Family of Apps increased by 28% year-over-year in 2023, and the average price per ad decreased by 9% year-over-year in 2023. Beginning with our Quarterly Report on Form 10-Q to be filed for the first quarter of 2024, we will no longer report DAUs, MAUs, ARPU, and MAP in our periodic reports filed with the Securities and Exchange Commission. We intend to begin reporting year-over-year percentage changes in ad impressions delivered and the average price per ad by geographic region, while continuing to report DAP and ARPP (calculated based on DAP), beginning with our Quarterly Report on Form 10-Q to be filed for the first quarter of 2024. For additional information, see the section entitled ""Limitations of Key Metrics and Other Data"" in this Annual Report on Form 10-K. Developments in Advertising Substantially all of our revenue is currently generated from advertising on Facebook and Instagram. We rely on targeting and measurement tools that incorporate data signals from user activity on websites and services that we do not control in order to deliver relevant and effective ads to our users. Our advertising revenue has been, and we expect will continue to be, adversely affected by reduced marketer spending as a result of limitations on our ad targeting and measurement tools arising from changes to the regulatory environment and third-party mobile operating systems and browsers. In particular, legislative and regulatory developments such as the General Data Protection Regulation, including its evolving interpretation through decisions of the Court of Justice of the European Union, ePrivacy Directive, the European Digital Services Act, and U.S. state privacy laws including the California Consumer Privacy Act, as amended by the California Privacy Rights Act, have impacted our ability to use data signals in our ad products, and we expect these and other Table of Contents developments such as the Digital Markets Act will have further impact in the future. As a result, we have implemented, and we will continue to implement, whether voluntarily or otherwise, changes to our products and user data practices, which reduce our ability to effectively target and measure ads. For example, in response to regulatory developments in Europe, we announced our plans to change the legal basis for behavioral advertising on Facebook and Instagram in the EU, European Economic Area, and Switzerland from ""legitimate interests"" to ""consent,"" and began offering users in the region a ""subscription for no ads"" alternative. We are continuing to engage with regulators on our new consent model. In addition, mobile operating system and browser providers, such as Apple and Google, have implemented product changes and/or announced future plans to limit the ability of websites and application developers to collect and use these signals to target and measure advertising. For example, in 2021, Apple made certain changes to its products and data use policies in connection with changes to its iOS operating system that reduce our and other iOS developers\' ability to target and measure advertising, which has negatively impacted, and we expect will continue to negatively impact, the size of the budgets marketers are willing to commit to us and other advertising platforms. To mitigate these developments, we are continually working to evolve our advertising systems to improve the performance of our ad products. We are developing privacy enhancing technologies to deliver relevant ads and measurement capabilities while reducing the amount of personal information we process, including by relying more on anonymized or aggregated third-party data. In addition, we are developing tools that enable marketers to share their data into our systems, as well as ad products that generate more valuable signals within our apps. More broadly, we also continue to innovate our advertising tools to help marketers prepare campaigns and connect with consumers, including developing growing formats such as Reels ads and our business messaging ad products. Across all of these efforts, we are making significant investments in artificial intelligence (AI), including generative AI, to improve our delivery, targeting, and measurement capabilities. Further, we are focused on driving onsite conversions in our business messaging ad products by developing new features and scaling existing features. We are also engaging with others across our industry to explore the possibility of new open standards for the private and secure processing of data for advertising purposes. We believe our ongoing improvements to ad targeting and measurement are continuing to drive improved results for advertisers. However, we expect that some of these efforts will be long-term initiatives, and that the legislative, regulatory and platform developments described above will continue to adversely impact our advertising revenue for the foreseeable future. Other Business and Macroeconomic Conditions Other global and regional business, macroeconomic, and geopolitical conditions also have had, and we believe will continue to have, an impact on our user growth and engagement and advertising revenue. In particular, we believe advertising budgets have been pressured from time to time by factors such as inflation, rising interest rates, and related market uncertainty, which has led to reduced marketer spending. While we saw improvement in business and macroeconomic conditions in 2023, continued business, macroeconomic, and geopolitical uncertainty remains, which could impact our financial results in future periods. In addition, competitive products and services have reduced some users\' engagement with our products and services. We are investing in Reels and in AI initiatives across our products, including our AI-powered discovery engine to recommend relevant content, which we have already seen results in improved user engagement and monetization of our products. ']",,
"['2113a3c7-6535-c732-d98c-787721cb9f55', '3e619c5b-8801-886f-1153-21429e404e1b', '77899e50-1aae-2b16-f8d4-65c30e9717d0', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', 'MSFT_1']","['Mark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work force and struggled to gain mainstream traction with its ambitious plans for virtual reality.\n\nOn Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, Mr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta’s work in artificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\n\nMr. Zuckerberg’s talk was an attempt to rally staff after the most tumultuous period in his company’s 19-year history. The chief executive said he made “tough decisions” about layoffs with the goal of “building a better technology company” that shipped better products, faster — something he believed Meta wasn’t doing well as it swelled to more than 80,000 employees at the peak of the pandemic.\n\n“I want us to use this period that’s going to be a bit more stable in order to evolve and rebuild our culture,” he said, according to two people who attended the meeting and shared remarks and a recording with The New York Times.', 'PART I Item 1 &#160; OPERATING SEGMENTS We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal Computing. Our segments provide management with a comprehensive financial view of our key businesses. The segments enable the alignment of strategies and objectives across the development, sales, marketing, and services organizations, and they provide a framework for timely and rational allocation of resources within businesses. Additional information on our operating segments and geographic and product information is contained in Note 19 &#8211; Segment Information and Geographic Data of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K). Our reportable segments are described below. Productivity and Business Processes Our Productivity and Business Processes segment consists of products and services in our portfolio of productivity, communication, and information services, spanning a variety of devices and platforms. This segment primarily comprises: &#8226; Office Commercial (Office 365 subscriptions, the Office 365 portion of Microsoft 365 Commercial subscriptions, and Office licensed on-premises), comprising Office, Exchange, SharePoint, Microsoft Teams, Office 365 Security and Compliance, Microsoft Viva, and Microsoft 365 Copilot. &#8226; Office Consumer, including Microsoft 365 Consumer subscriptions, Office licensed on-premises, and other Office services. &#8226; LinkedIn, including Talent Solutions, Marketing Solutions, Premium Subscriptions, and Sales Solutions. &#8226; Dynamics business solutions, including Dynamics 365, comprising a set of intelligent, cloud-based applications across ERP, CRM (including Customer Insights), Power Apps, and Power Automate; and on-premises ERP and CRM applications. Office Commercial Office Commercial is designed to increase personal, team, and organizational productivity through a range of products and services. Growth depends on our ability to reach new users in new markets such as frontline workers, small and medium businesses, and growth markets, as well as add value to our core product and service offerings to span productivity categories such as communication, collaboration, analytics, security, and compliance. Office Commercial revenue is mainly affected by a combination of continued installed base growth and average revenue per user expansion, as well as the continued shift from Office licensed on-premises to Office 365. Office Consumer Office Consumer is designed to increase personal productivity and creativity through a range of products and services. Growth depends on our ability to reach new users, add value to our core product set, and continue to expand our product and service offerings into new markets. Office Consumer revenue is mainly affected by the percentage of customers that buy Office with their new devices and the continued shift from Office licensed on-premises to Microsoft 365 Consumer subscriptions. Office Consumer Services revenue is mainly affected by the demand for communication and storage through Skype, Outlook.com, and OneDrive, which is largely driven by subscriptions, advertising, and the sale of minutes. PART I Item 1 &#160; LinkedIn LinkedIn connects the world&#8217;s professionals to make them more productive and successful and transforms the way companies hire, market, sell, and learn. Our vision is to create economic opportunity for every member of the global workforce through the ongoing development of the world&#8217;s first Economic Graph, a digital representation of the global economy. In addition to LinkedIn&#8217;s free services, LinkedIn offers monetized solutions: Talent Solutions, Marketing Solutions, Premium Subscriptions, and Sales Solutions. Talent Solutions provide insights for workforce planning and tools to hire, nurture, and develop talent. Talent Solutions also includes Learning Solutions, which help businesses close critical skills gaps in times where companies are having to do more with existing talent. Marketing Solutions help companies reach, engage, and convert their audiences at scale. Premium Subscriptions enable professionals to manage their professional identity, grow their network, find jobs, and connect with talent through additional services like premium search. Sales Solutions help companies strengthen customer relationships, empower teams with digital selling tools, and acquire new opportunities. LinkedIn has over 950 million members and has offices around the globe. Growth will depend on our ability to increase the number of LinkedIn members and our ability to continue offering services that provide value for our members and increase their engagement. LinkedIn revenue is mainly affected by demand from enterprises and professional organizations for subscriptions to Talent Solutions, Sales Solutions, and Premium Subscriptions offerings, as well as member engagement and the quality of the sponsored content delivered to those members to drive Marketing Solutions. Dynamics Dynamics provides cloud-based and on-premises business solutions for financial management, enterprise resource planning (&#8220;ERP&#8221;), customer relationship management (&#8220;CRM&#8221;), supply chain management, and other application development platforms for small and medium businesses, large organizations, and divisions of global enterprises. Dynamics revenue is driven by the number of users licensed and applications consumed, expansion of average revenue per user, and the continued shift to Dynamics 365, a unified set of cloud-based intelligent business applications, including Power Apps and Power Automate. Competition Competitors to Office include software and global application vendors, such as Apple, Cisco Systems, Meta, Google, Okta, Proofpoint, Slack, Symantec, Zoom, and numerous web-based and mobile application competitors as well as local application developers. Apple distributes versions of its pre-installed application software, such as email and calendar products, through its PCs, tablets, and phones. Cisco Systems is using its position in enterprise communications equipment to grow its unified communications business. Meta offers communication tools to enable productivity and engagement within organizations. Google provides a hosted messaging and productivity suite. Slack provides teamwork and collaboration software. Zoom offers videoconferencing and cloud phone solutions. Okta, Proofpoint, and Symantec provide security solutions across email security, information protection, identity, and governance. Web-based offerings competing with individual applications have also positioned themselves as alternatives to our products and services. We compete by providing powerful, flexible, secure, integrated industry-specific, and easy-to-use productivity and collaboration tools and services that create comprehensive solutions and work well with technologies our customers already have both on-premises or in the cloud. LinkedIn faces competition from online professional networks, recruiting companies, talent management companies, and larger companies that are focusing on talent management and human resource services; job boards; traditional recruiting firms; and companies that provide learning and development products and services. Marketing Solutions competes with online and offline outlets that generate revenue from advertisers and marketers, and Sales Solutions competes with online and offline outlets for companies with lead generation and customer intelligence and insights. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['31970220-d0ef-988f-147c-bc3d032af7cb', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'adfada1a-9035-2536-c50b-c83d3f18a36a', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'e9a3dc11-aef9-8334-46d8-8bffc19dda5b']","['AMD_1', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'NVDA_7', 'Testing Meta Verified to Help Creators Establish Their Presence', 'Microsoft Corporation (MSFT) Rose on Exceeding Expectations']","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on June 27, 2023 at 7:30 AM PT:\n\nWe’re excited to begin rolling out Meta Verified to most markets globally over the coming months.\n\nWe’ve heard positive feedback from creators in our initial tests and continue to gather input about what’s most valuable for subscribers. We’ll continue to evolve Meta Verified based on these learnings and explore new features and benefits that create more value for subscribers.\n\nUpdate on June 7, 2023 at 7:30 AM PT:\n\nMeta Verified is now available in India and will soon be available in Brazil.\n\nUpdate on May 31, 2023 at 9:00 AM PT:\n\nMeta Verified is now available in Canada.\n\nUpdate on May 16, 2023 at 7:40 AM PT:\n\nMeta Verified is now available in the United Kingdom.\n\nUpdate on March 17, 2023 at 11 AM PT:\n\nWe’re expanding our test of Meta Verified to the US after seeing good results from our early testing. This test in the US will reflect some initial learnings and feedback. We’re removing increased reach as a subscription feature for now, as we gather more feedback and further evolve Meta Verified. We’re exploring elements to add to the subscription as we roll out to more places and will share more when we’re ready.\n\nOriginally published on February 19, 2023 at 12 PM PT:\n\nTo help up-and-coming creators grow their presence and build community faster, today Mark Zuckerberg announced that we’ll begin testing a new offering called Meta Verified, a subscription bundle on Instagram and Facebook that includes a verified badge that authenticates your account with government ID, proactive account protection, access to account support, and increased visibility and reach. We’re starting with a gradual test in Australia and New Zealand later this week to learn what’s most valuable, and we hope to bring Meta Verified to the rest of the world soon.\n\nSome of the top requests we get from creators are for broader access to verification and account support, in addition to more features to increase visibility and reach. Since last year, we’ve been thinking about how to unlock access to these features through a paid offering.\n\nWith Meta Verified, you’ll get:\n\nA verified badge, confirming you’re the real you and that your account has been authenticated with a government ID.¹\n\nMore protection from impersonation with proactive account monitoring for impersonators who might target people with growing online audiences.\n\nHelp when you need it with access to a real person for common account issues.\n\nIncreased visibility and reach with prominence in some areas of the platform– like search, comments and recommendations.²\n\nExclusive features to express yourself in unique ways.³\n\nMeta Verified is available for direct purchase on Instagram or Facebook in Australia and New Zealand starting later this week. People can purchase a monthly subscription for (USD) $11.99 on the web and (USD) $14.99 on iOS and Android.4\n\nAs we test and learn, there will be no changes to accounts on Instagram and Facebook that are already verified based on prior requirements. Long term, we want to build a subscription offering that’s valuable to everyone, including creators, businesses and our community at large. As part of this vision, we are evolving the meaning of verified accounts on our apps so we can expand access to verification and more people can trust the accounts they interact with are authentic.\n\nBuilding Safety from the Beginning\n\nIt’s important to feel confident that your identity and accounts are safe and that the people you’re interacting with are who they say they are. That’s why we’re building a series of checks into Meta Verified before, during, and after someone applies.\n\nTo be eligible, accounts must meet minimum activity requirements, such as prior posting history, and be at least 18 years old .\n\nApplicants are then required to submit a government ID that matches the profile name and photo of the Facebook or Instagram account they’re applying for .\n\nSubscriptions will include proactive monitoring for account impersonation.\n\nWe’re also committed to continuous monitoring and review of reported violations, as well as taking swift action against those who try to evade our systems.\n\nTo learn more about Meta Verified visit Mark Zuckerberg’s Meta Channel on Instagram on your mobile device.\n\n1. Where available, some subscribers may be required to submit a selfie video as part of the authentication process.\n\n2. We’ll offer exclusive stickers on Facebook and Instagram Stories and Facebook Reels, and 100 free stars a month on Facebook so you can show your support for other creators.\n\n3. AUD 19.99 on web, AUD 24.99 on iOS and Android. NZD 23.99 on web, NZD 29.99 on iOS and Android. Subscription features are the same for both web and app purchases.\n\n4. Businesses are not eligible to apply for Meta Verified at this time.', 'Diamond Hill Capital, an investment management company, released its “Large Cap Strategy” second-quarter 2023 investor letter. A copy of the same can be downloaded here. In the second quarter, the strategy underperformed the Russell 1000 Index. With the revival of growth and technology stocks, the strategy’s underweight exposure to the sector was a headwind on the relative performance. Technology and communication services holdings of the strategy collectively performed well but did not keep pace with those in the index. It benefited from the strength of investments in the materials and consumer discretionary sectors. The strategy returned 6.04% (net) in the quarter compared to 8.58% for the index. In addition, you can check the top 5 holdings of the strategy to know its best picks in 2023.\n\nDiamond Hill Large Cap Strategy highlighted stocks like Microsoft Corporation (NASDAQ:MSFT) in the second quarter 2023 investor letter. Headquartered in Redmond, Washington, Microsoft Corporation (NASDAQ:MSFT) is a multinational software company that develops, and licenses software, services, devices, and solutions. On September 14, 2023, Microsoft Corporation (NASDAQ:MSFT) stock closed at $338.70 per share. One-month return of Microsoft Corporation (NASDAQ:MSFT) was 7.02%, and its shares gained 38.39% of their value over the last 52 weeks. Microsoft Corporation (NASDAQ:MSFT) has a market capitalization of $2.516 trillion.\n\nDiamond Hill Large Cap Strategy made the following comment about Microsoft Corporation (NASDAQ:MSFT) in its Q2 2023 investor letter:\n\n""Also among our leading contributors were software and IT services provider Microsoft Corporation (NASDAQ:MSFT) and health care facilities operator HCA Healthcare. Microsoft reported strong quarterly results and provided more favorable than expected commentary on near-term Azure (cloud platform) revenue growth. Investors had become concerned that Azure’s revenue growth could come under increased pressure in a weakening economy, but the combination of quarterly results and commentary about Azure’s future growth trajectory calmed concerns.""\n\nStory continues\n\nImage by Tawanda Razika from Pixabay\n\nMicrosoft Corporation (NASDAQ:MSFT) holds the first position on our list of 30 Most Popular Stocks Among Hedge Funds. As per our database, 300 hedge fund portfolios held Microsoft Corporation (NASDAQ:MSFT) at the end of second quarter which was 289 in the previous quarter.\n\nWe discussed Microsoft Corporation (NASDAQ:MSFT) in another article and shared the list of biggest Web3.0 companies in the world. In addition, please check out our hedge fund investor letters Q2 2023 page for more investor letters from hedge funds and other leading investors.\n\nSuggested Articles:\n\nDisclosure: None. This article is originally published at Insider Monkey.', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', 'ITEM 1. &#160; BUSINESS Cautionary Statement Regarding Forward-Looking Statements The statements in this report include forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. These forward-looking statements are based on current expectations and beliefs and involve numerous risks and uncertainties that could cause actual results to differ materially from expectations. These forward-looking statements speak only as of the date hereof or as of the dates indicated in the statements and should not be relied upon as predictions of future events, as we cannot assure you that the events or circumstances reflected in these statements will be achieved or will occur. You can identify forward-looking statements by the use of forward-looking terminology including &#8220;believes,&#8221; &#8220;expects,&#8221; &#8220;may,&#8221; &#8220;will,&#8221; &#8220;should,&#8221; &#8220;seeks,&#8221; &#8220;intends,&#8221; &#8220;plans,&#8221; &#8220;pro forma,&#8221; &#8220;estimates,&#8221; &#8220;anticipates,&#8221; or the negative of these words and phrases, other variations of these words and phrases or comparable terminology. The forward-looking statements relate to, among other things: possible impact of future accounting rules on AMD&#8217;s consolidated financial statements; demand for AMD&#8217;s products; AMD&#8217;s strategy and expected benefits; the growth, change and competitive landscape of the markets in which AMD participates; international sales will continue to be a significant portion of total sales in the foreseeable future; that AMD&#8217;s cash, cash equivalents and short-term investment balances together with the availability under that certain revolving credit facility (the Revolving Credit Agreement) made available to AMD and certain of its subsidiaries, our commercial paper program, and our cash flows from operations will be sufficient to fund AMD&#8217;s operations including capital expenditures and purchase commitments over the next 12 months and beyond; AMD&#8217;s ability to obtain sufficient external financing on favorable terms, or at all; AMD&#8217;s expectation that based on management&#8217;s current knowledge, the potential liability related to AMD&#8217;s current litigation will not have a material adverse effect on its financial position, results of operation or cash flows; anticipated ongoing and increased costs related to enhancing and implementing information security controls; all unbilled accounts receivables are expected to be billed and collected within 12 months; revenue allocated to remaining performance obligations that are unsatisfied which will be recognized in the next 12 months; a small number of customers will continue to account for a substantial part of AMD&#8217;s revenue in the future; the expected implications from the development of the legal and regulatory environment relating to emerging technologies such as AI; AMD&#8217;s expectation that it will not pay dividends in the near future; AMD&#8217;s ability to achieve its corporate responsibility initiatives; expected future AI technology trends and developments. For a discussion of the factors that could cause actual results to differ materially from the forward-looking statements, see &#8220;Part I, Item 1A-Risk Factors&#8221; and the &#8220;Financial Condition&#8221; section set forth in &#8220;Part II, Item 7-Management&#8217;s Discussion and Analysis of Financial Condition and Results of Operations,&#8221; or MD&#38;A, and such other risks and uncertainties as set forth below in this report or detailed in our other Securities and Exchange Commission (SEC) reports and filings. We assume no obligation to update forward-looking statements. Additionally, we make certain voluntary disclosures in this report and on our website, which are informed by various standards and frameworks (including standards for the measurement of underlying data), and the interests of various stakeholders. As such, these voluntary disclosures may not necessarily be &#8220;material&#8221; under the federal securities laws for SEC reporting purposes. Furthermore, much of this information is subject to methodological considerations or information, including from third-parties, that is still evolving and subject to change, and which AMD does not independently verify. For example, our disclosures based on any standards may change due to revisions in framework requirements, availability of information, changes in our business or applicable government policies, or other factors, some of which may be beyond our control. References in this Annual Report on Form 10-K to &#8220;AMD,&#8221; &#8220;we,&#8221; &#8220;us,&#8221; &#8220;management,&#8221; &#8220;our&#8221; or the &#8220;Company&#8221; mean Advanced Micro Devices, Inc. and our consolidated subsidiaries. Overview We are a global semiconductor company primarily offering: &#8226; server microprocessors (CPUs), graphics processing units (GPUs), accelerated processing units (APUs), data processing units (DPUs), Field Programmable Gate Arrays (FPGAs), Smart Network Interface Cards (SmartNICs), Artificial Intelligence (AI) accelerators and Adaptive System-on-Chip (SoC) products for data centers; &#8226; CPUs, APUs and chipsets for desktop, notebook, and handheld personal computers; &#8226; discrete GPUs, and semi-custom SoC products and development services; and &#8226; embedded CPUs, GPUs, APUs, FPGAs, System on Modules (SOMs), and Adaptive SoC products. From time to time, we may also sell or license portions of our intellectual property (IP) portfolio. Additional Information AMD was incorporated under the laws of Delaware on May 1, 1969 and became a publicly held company in 1972. Our common stock is currently listed on The NASDAQ Global Select Market (NASDAQ) under the symbol &#8220;AMD&#8221;. Our mailing address and executive offices are located at 2485 Augustine Drive, Santa Clara, California 95054, and our telephone number is (408) 749-4000. For financial information about geographic areas and for segment information with respect to revenues and operating results, refer to the information set forth in Note 4 of our consolidated financial statements. We use a 52- or 53-week fiscal year ending on the last Saturday in December. References in this report to 2023, 2022 and 2021 refer to the fiscal year unless explicitly stated otherwise. AMD, the AMD Arrow logo, AMD CDNA, AMD Instinct, RDNA, Alveo, Artix, Athlon, CoolRunner, EPYC, FidelityFX, FirePro, FreeSync, Geode, Infinity Fabric, Kinex, Kria, Pensando, Radeon, ROCm, Ryzen, Spartan, Threadripper, UltraScale, UltraScale+, V-Cache, Versal, Virtex, Vitis, Vivado, Xilinx, XDNA, Zynq and combinations thereof are trademarks of Advanced Micro Devices, Inc. Microsoft, Windows, DirectX and Xbox One are either registered trademarks or trademarks of Microsoft Corporation in the United States and/or other countries. PCIe is a registered trademark of PCI-SIG Corporation. Linux is the registered trademark of Linus Torvalds in the United States and/or other countries. PlayStation is a registered trademark or trademark of Sony Interactive Entertainment, Inc. Arm is a registered trademark of ARM Limited (or its subsidiaries) in the United States and/or other countries. ']",,
"['3e619c5b-8801-886f-1153-21429e404e1b', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'ca76e309-cb8c-049d-6d6a-a628b8b74f30']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'META_1A', 'META_7', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones']","['Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'There can be no assurance that we will continue to declare cash dividends. On February 1, 2024, we announced the initiation of our first-ever quarterly cash dividend. The payment of any cash dividends in the future is subject to continued capital availability, market conditions, applicable laws and agreements, and our board of directors continuing to determine that the declaration of dividends are in the best interests of our stockholders. The declaration and payment of any dividend may be discontinued or reduced at any time, and there can be no assurance that we will declare cash dividends in the future in any particular amounts, or at all. Risks Related to Government Regulation and Enforcement Actions by governments that restrict access to Facebook or our other products in their countries, censor or moderate content on our products in their countries, or otherwise impair our ability to sell advertising in their countries, could substantially harm our business and financial results. Governments from time to time seek to censor or moderate content available on Facebook or our other products in their country, restrict access to our products from their country partially or entirely, or impose other restrictions that may affect the accessibility of our products in their country for an extended period of time or indefinitely. For example, user access to Facebook and certain of our other products has been or is currently restricted in whole or in part in China, Iran, and North Korea. In addition, government authorities in other countries may seek to restrict user access to our products if they consider us to be in violation of their laws or a threat to public safety or for other reasons, and certain of our products have been restricted by governments in other countries from time to time. For example, in 2020, Hong Kong adopted a National Security Law that provides authorities with the ability to obtain information, remove and block access to content, and suspend user services, and if we are found to be in violation of this law then the use of our products may be restricted. Hong Kong is also expected to pass additional national security legislation in 2024. In addition, if we are required to or elect to make changes to our marketing and sales or other operations in Hong Kong as a result of the National Security Law or other legislation, our revenue and business in the region will be adversely affected. In addition, in connection with the war in Ukraine in the first quarter of 2022, access to Facebook and Instagram was restricted in Russia and the services were then prohibited by the Russian government, which has adversely affected, and will likely continue to adversely affect, our revenue and business in the region. It is also possible that government authorities could take action that impairs our ability to sell advertising, including in countries where access to our consumer-facing products may be blocked or restricted. For example, we generate meaningful revenue from a small number of resellers serving advertisers based in China, and it is possible that the Chinese government could take action that reduces or eliminates our China-based advertising revenue, whether as a result of the trade dispute with the United States, in response to content issues or information requests in Hong Kong or elsewhere, or for other reasons, or take other action against us, such as imposing taxes or other penalties, which could adversely affect our financial results. Similarly, if we are found to be out of compliance with certain legal requirements for companies in Turkey, the Turkish government could take action to reduce or eliminate our Turkey-based advertising revenue or otherwise adversely impact access to our products. In the event that content shown on Facebook or our other products is subject to censorship, access to our products is restricted, in whole or in part, in one or more countries, we are required to or elect to make changes to our operations, or other restrictions are imposed on our products, or our competitors are able to successfully penetrate new geographic markets or capture a greater share of existing geographic markets that we cannot access or where we face other restrictions, our ability to retain or increase our user base, user engagement, or the level of advertising by marketers may be adversely affected, we may not be able to maintain or grow our revenue as anticipated, and our financial results could be adversely affected. Table of Contents Our business is subject to complex and evolving U.S. and foreign laws and regulations regarding privacy, data use and data protection, content, competition, safety and consumer protection, e-commerce, and other matters. Many of these laws and regulations are subject to change and uncertain interpretation, and could result in claims, changes to our products and business practices, monetary penalties, increased cost of operations, or declines in user growth or engagement, or otherwise harm our business. We are subject to a variety of laws and regulations in the United States and abroad that involve matters central to our business, including privacy, data use, data protection and personal information, the provision of our services to younger users, biometrics, encryption, rights of publicity, content, integrity, intellectual property, advertising, marketing, distribution, data security, data retention and deletion, data localization and storage, data disclosure, AI and machine learning, electronic contracts and other communications, competition, protection of minors, consumer protection, civil rights, accessibility, telecommunications, product liability, e-commerce, taxation, economic or other trade controls including sanctions, anti-corruption and political law compliance, securities law compliance, and online payment services. The introduction of new products, expansion of our activities in certain jurisdictions, or other actions that we may take may subject us to additional laws, regulations, or other government scrutiny. In addition, foreign data protection, privacy, content, competition, consumer protection, and other laws and regulations can impose different obligations or be more restrictive than those in the United States, and create the potential for significant fines to be imposed. These U.S. federal and state, EU, and other international laws and regulations, which in some cases can be enforced by private parties in addition to government entities, are constantly evolving and can be subject to significant change. ', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['31970220-d0ef-988f-147c-bc3d032af7cb', '591c2bb5-1433-43c4-3c95-43e8b4164fba', '621b9412-442f-9f87-2209-0ecbfb9beeb0', 'adfada1a-9035-2536-c50b-c83d3f18a36a', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['AMD_1', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'NVDA_7', 'Testing Meta Verified to Help Creators Establish Their Presence', ""What Does Microsoft Corporation's (NASDAQ:MSFT) Share Price Indicate?""]","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on June 27, 2023 at 7:30 AM PT:\n\nWe’re excited to begin rolling out Meta Verified to most markets globally over the coming months.\n\nWe’ve heard positive feedback from creators in our initial tests and continue to gather input about what’s most valuable for subscribers. We’ll continue to evolve Meta Verified based on these learnings and explore new features and benefits that create more value for subscribers.\n\nUpdate on June 7, 2023 at 7:30 AM PT:\n\nMeta Verified is now available in India and will soon be available in Brazil.\n\nUpdate on May 31, 2023 at 9:00 AM PT:\n\nMeta Verified is now available in Canada.\n\nUpdate on May 16, 2023 at 7:40 AM PT:\n\nMeta Verified is now available in the United Kingdom.\n\nUpdate on March 17, 2023 at 11 AM PT:\n\nWe’re expanding our test of Meta Verified to the US after seeing good results from our early testing. This test in the US will reflect some initial learnings and feedback. We’re removing increased reach as a subscription feature for now, as we gather more feedback and further evolve Meta Verified. We’re exploring elements to add to the subscription as we roll out to more places and will share more when we’re ready.\n\nOriginally published on February 19, 2023 at 12 PM PT:\n\nTo help up-and-coming creators grow their presence and build community faster, today Mark Zuckerberg announced that we’ll begin testing a new offering called Meta Verified, a subscription bundle on Instagram and Facebook that includes a verified badge that authenticates your account with government ID, proactive account protection, access to account support, and increased visibility and reach. We’re starting with a gradual test in Australia and New Zealand later this week to learn what’s most valuable, and we hope to bring Meta Verified to the rest of the world soon.\n\nSome of the top requests we get from creators are for broader access to verification and account support, in addition to more features to increase visibility and reach. Since last year, we’ve been thinking about how to unlock access to these features through a paid offering.\n\nWith Meta Verified, you’ll get:\n\nA verified badge, confirming you’re the real you and that your account has been authenticated with a government ID.¹\n\nMore protection from impersonation with proactive account monitoring for impersonators who might target people with growing online audiences.\n\nHelp when you need it with access to a real person for common account issues.\n\nIncreased visibility and reach with prominence in some areas of the platform– like search, comments and recommendations.²\n\nExclusive features to express yourself in unique ways.³\n\nMeta Verified is available for direct purchase on Instagram or Facebook in Australia and New Zealand starting later this week. People can purchase a monthly subscription for (USD) $11.99 on the web and (USD) $14.99 on iOS and Android.4\n\nAs we test and learn, there will be no changes to accounts on Instagram and Facebook that are already verified based on prior requirements. Long term, we want to build a subscription offering that’s valuable to everyone, including creators, businesses and our community at large. As part of this vision, we are evolving the meaning of verified accounts on our apps so we can expand access to verification and more people can trust the accounts they interact with are authentic.\n\nBuilding Safety from the Beginning\n\nIt’s important to feel confident that your identity and accounts are safe and that the people you’re interacting with are who they say they are. That’s why we’re building a series of checks into Meta Verified before, during, and after someone applies.\n\nTo be eligible, accounts must meet minimum activity requirements, such as prior posting history, and be at least 18 years old .\n\nApplicants are then required to submit a government ID that matches the profile name and photo of the Facebook or Instagram account they’re applying for .\n\nSubscriptions will include proactive monitoring for account impersonation.\n\nWe’re also committed to continuous monitoring and review of reported violations, as well as taking swift action against those who try to evade our systems.\n\nTo learn more about Meta Verified visit Mark Zuckerberg’s Meta Channel on Instagram on your mobile device.\n\n1. Where available, some subscribers may be required to submit a selfie video as part of the authentication process.\n\n2. We’ll offer exclusive stickers on Facebook and Instagram Stories and Facebook Reels, and 100 free stars a month on Facebook so you can show your support for other creators.\n\n3. AUD 19.99 on web, AUD 24.99 on iOS and Android. NZD 23.99 on web, NZD 29.99 on iOS and Android. Subscription features are the same for both web and app purchases.\n\n4. Businesses are not eligible to apply for Meta Verified at this time.', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', 'ITEM 1. &#160; BUSINESS Cautionary Statement Regarding Forward-Looking Statements The statements in this report include forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. These forward-looking statements are based on current expectations and beliefs and involve numerous risks and uncertainties that could cause actual results to differ materially from expectations. These forward-looking statements speak only as of the date hereof or as of the dates indicated in the statements and should not be relied upon as predictions of future events, as we cannot assure you that the events or circumstances reflected in these statements will be achieved or will occur. You can identify forward-looking statements by the use of forward-looking terminology including &#8220;believes,&#8221; &#8220;expects,&#8221; &#8220;may,&#8221; &#8220;will,&#8221; &#8220;should,&#8221; &#8220;seeks,&#8221; &#8220;intends,&#8221; &#8220;plans,&#8221; &#8220;pro forma,&#8221; &#8220;estimates,&#8221; &#8220;anticipates,&#8221; or the negative of these words and phrases, other variations of these words and phrases or comparable terminology. The forward-looking statements relate to, among other things: possible impact of future accounting rules on AMD&#8217;s consolidated financial statements; demand for AMD&#8217;s products; AMD&#8217;s strategy and expected benefits; the growth, change and competitive landscape of the markets in which AMD participates; international sales will continue to be a significant portion of total sales in the foreseeable future; that AMD&#8217;s cash, cash equivalents and short-term investment balances together with the availability under that certain revolving credit facility (the Revolving Credit Agreement) made available to AMD and certain of its subsidiaries, our commercial paper program, and our cash flows from operations will be sufficient to fund AMD&#8217;s operations including capital expenditures and purchase commitments over the next 12 months and beyond; AMD&#8217;s ability to obtain sufficient external financing on favorable terms, or at all; AMD&#8217;s expectation that based on management&#8217;s current knowledge, the potential liability related to AMD&#8217;s current litigation will not have a material adverse effect on its financial position, results of operation or cash flows; anticipated ongoing and increased costs related to enhancing and implementing information security controls; all unbilled accounts receivables are expected to be billed and collected within 12 months; revenue allocated to remaining performance obligations that are unsatisfied which will be recognized in the next 12 months; a small number of customers will continue to account for a substantial part of AMD&#8217;s revenue in the future; the expected implications from the development of the legal and regulatory environment relating to emerging technologies such as AI; AMD&#8217;s expectation that it will not pay dividends in the near future; AMD&#8217;s ability to achieve its corporate responsibility initiatives; expected future AI technology trends and developments. For a discussion of the factors that could cause actual results to differ materially from the forward-looking statements, see &#8220;Part I, Item 1A-Risk Factors&#8221; and the &#8220;Financial Condition&#8221; section set forth in &#8220;Part II, Item 7-Management&#8217;s Discussion and Analysis of Financial Condition and Results of Operations,&#8221; or MD&#38;A, and such other risks and uncertainties as set forth below in this report or detailed in our other Securities and Exchange Commission (SEC) reports and filings. We assume no obligation to update forward-looking statements. Additionally, we make certain voluntary disclosures in this report and on our website, which are informed by various standards and frameworks (including standards for the measurement of underlying data), and the interests of various stakeholders. As such, these voluntary disclosures may not necessarily be &#8220;material&#8221; under the federal securities laws for SEC reporting purposes. Furthermore, much of this information is subject to methodological considerations or information, including from third-parties, that is still evolving and subject to change, and which AMD does not independently verify. For example, our disclosures based on any standards may change due to revisions in framework requirements, availability of information, changes in our business or applicable government policies, or other factors, some of which may be beyond our control. References in this Annual Report on Form 10-K to &#8220;AMD,&#8221; &#8220;we,&#8221; &#8220;us,&#8221; &#8220;management,&#8221; &#8220;our&#8221; or the &#8220;Company&#8221; mean Advanced Micro Devices, Inc. and our consolidated subsidiaries. Overview We are a global semiconductor company primarily offering: &#8226; server microprocessors (CPUs), graphics processing units (GPUs), accelerated processing units (APUs), data processing units (DPUs), Field Programmable Gate Arrays (FPGAs), Smart Network Interface Cards (SmartNICs), Artificial Intelligence (AI) accelerators and Adaptive System-on-Chip (SoC) products for data centers; &#8226; CPUs, APUs and chipsets for desktop, notebook, and handheld personal computers; &#8226; discrete GPUs, and semi-custom SoC products and development services; and &#8226; embedded CPUs, GPUs, APUs, FPGAs, System on Modules (SOMs), and Adaptive SoC products. From time to time, we may also sell or license portions of our intellectual property (IP) portfolio. Additional Information AMD was incorporated under the laws of Delaware on May 1, 1969 and became a publicly held company in 1972. Our common stock is currently listed on The NASDAQ Global Select Market (NASDAQ) under the symbol &#8220;AMD&#8221;. Our mailing address and executive offices are located at 2485 Augustine Drive, Santa Clara, California 95054, and our telephone number is (408) 749-4000. For financial information about geographic areas and for segment information with respect to revenues and operating results, refer to the information set forth in Note 4 of our consolidated financial statements. We use a 52- or 53-week fiscal year ending on the last Saturday in December. References in this report to 2023, 2022 and 2021 refer to the fiscal year unless explicitly stated otherwise. AMD, the AMD Arrow logo, AMD CDNA, AMD Instinct, RDNA, Alveo, Artix, Athlon, CoolRunner, EPYC, FidelityFX, FirePro, FreeSync, Geode, Infinity Fabric, Kinex, Kria, Pensando, Radeon, ROCm, Ryzen, Spartan, Threadripper, UltraScale, UltraScale+, V-Cache, Versal, Virtex, Vitis, Vivado, Xilinx, XDNA, Zynq and combinations thereof are trademarks of Advanced Micro Devices, Inc. Microsoft, Windows, DirectX and Xbox One are either registered trademarks or trademarks of Microsoft Corporation in the United States and/or other countries. PCIe is a registered trademark of PCI-SIG Corporation. Linux is the registered trademark of Linus Torvalds in the United States and/or other countries. PlayStation is a registered trademark or trademark of Sony Interactive Entertainment, Inc. Arm is a registered trademark of ARM Limited (or its subsidiaries) in the United States and/or other countries. ', ""Microsoft Corporation (NASDAQ:MSFT) saw significant share price movement during recent months on the NASDAQGS, rising to highs of US$359 and falling to the lows of US$316. Some share price movements can give investors a better opportunity to enter into the stock, and potentially buy at a lower price. A question to answer is whether Microsoft's current trading price of US$321 reflective of the actual value of the large-cap? Or is it currently undervalued, providing us with the opportunity to buy? Let’s take a look at Microsoft’s outlook and value based on the most recent financial data to see if there are any catalysts for a price change.\n\nCheck out our latest analysis for Microsoft\n\nIs Microsoft Still Cheap?\n\nThe stock seems fairly valued at the moment according to my valuation model. It’s trading around 11% below my intrinsic value, which means if you buy Microsoft today, you’d be paying a fair price for it. And if you believe the company’s true value is $361.14, then there’s not much of an upside to gain from mispricing. What's more, Microsoft’s share price may be more stable over time (relative to the market), as indicated by its low beta.\n\nCan we expect growth from Microsoft?\n\nFuture outlook is an important aspect when you’re looking at buying a stock, especially if you are an investor looking for growth in your portfolio. Although value investors would argue that it’s the intrinsic value relative to the price that matter the most, a more compelling investment thesis would be high growth potential at a cheap price. Microsoft's earnings over the next few years are expected to increase by 51%, indicating a highly optimistic future ahead. This should lead to more robust cash flows, feeding into a higher share value.\n\nWhat This Means For You\n\nAre you a shareholder? It seems like the market has already priced in MSFT’s positive outlook, with shares trading around its fair value. However, there are also other important factors which we haven’t considered today, such as the financial strength of the company. Have these factors changed since the last time you looked at the stock? Will you have enough confidence to invest in the company should the price drop below its fair value?\n\nStory continues\n\nAre you a potential investor? If you’ve been keeping tabs on MSFT, now may not be the most optimal time to buy, given it is trading around its fair value. However, the optimistic prospect is encouraging for the company, which means it’s worth diving deeper into other factors such as the strength of its balance sheet, in order to take advantage of the next price drop.\n\nWith this in mind, we wouldn't consider investing in a stock unless we had a thorough understanding of the risks. For example, we've discovered 1 warning sign that you should run your eye over to get a better picture of Microsoft.\n\nIf you are no longer interested in Microsoft, you can use our free platform to see our list of over 50 other stocks with a high growth potential.\n\nHave feedback on this article? Concerned about the content? Get in touch with us directly. Alternatively, email editorial-team (at) simplywallst.com.\n\n\n\nThis article by Simply Wall St is general in nature. We provide commentary based on historical data and analyst forecasts only using an unbiased methodology and our articles are not intended to be financial advice. It does not constitute a recommendation to buy or sell any stock, and does not take account of your objectives, or your financial situation. We aim to bring you long-term focused analysis driven by fundamental data. Note that our analysis may not factor in the latest price-sensitive company announcements or qualitative material. Simply Wall St has no position in any stocks mentioned.""]",,
"['3e619c5b-8801-886f-1153-21429e404e1b', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'a4430f1b-74d2-442f-2979-38644ee0d678', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc']","['NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'AMD_8', 'NVDA vs. TSM: Which Chipmaker Stock is Better?', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones']","['Advanced Micro Devices, Inc. Consolidated Statements of Cash Flows ##TABLE_START Year Ended December 30, 2023 December 31, 2022 December 25, 2021 (In millions) Cash flows from operating activities: Net income $ 854 &#160; $ 1,320 &#160; $ 3,162 &#160; Adjustments to reconcile net income to net cash provided by operating activities: Depreciation and amortization 3,453 &#160; 4,174 &#160; 407 &#160; Stock-based compensation 1,384 &#160; 1,081 &#160; 379 &#160; Amortization of operating lease right-of-use assets 98 &#160; 88 &#160; 56 &#160; Amortization of inventory fair value adjustment 3 &#160; 189 &#160; &#8212; &#160; Loss on debt redemption, repurchase and conversion &#8212; &#160; &#8212; &#160; 7 &#160; Loss on sale or disposal of property and equipment 11 &#160; 16 &#160; 34 &#160; Deferred income taxes ( 1,019 ) ( 1,505 ) 308 &#160; (Gains) losses on equity investments, net ( 1 ) 62 &#160; ( 56 ) Other ( 67 ) ( 14 ) ( 2 ) Changes in operating assets and liabilities: Accounts receivable, net ( 1,250 ) ( 1,091 ) ( 640 ) Inventories ( 580 ) ( 1,401 ) ( 556 ) Receivables from related parties ( 7 ) ( 13 ) 8 &#160; Prepaid expenses and other assets ( 472 ) ( 1,197 ) ( 920 ) Payables to related parties ( 100 ) 379 &#160; 7 &#160; Accounts payable ( 419 ) 931 &#160; 801 &#160; Accrued and other liabilities ( 221 ) 546 &#160; 526 &#160; Net cash provided by operating activities 1,667 &#160; 3,565 &#160; 3,521 &#160; Cash flows from investing activities: Purchases of property and equipment ( 546 ) ( 450 ) ( 301 ) Purchases of short-term investments ( 3,722 ) ( 2,667 ) ( 2,056 ) Proceeds from maturity of short-term investments 2,687 &#160; 4,310 &#160; 1,678 &#160; Proceeds from sale of short-term investments 300 &#160; &#8212; &#160; &#8212; &#160; Cash received from acquisition of Xilinx &#8212; &#160; 2,366 &#160; &#8212; &#160; Acquisitions, net of cash acquired ( 131 ) ( 1,544 ) &#8212; &#160; Other ( 11 ) ( 16 ) ( 7 ) Net cash provided by (used in) investing activities ( 1,423 ) 1,999 &#160; ( 686 ) Cash flows from financing activities: Proceeds from debt, net of issuance costs &#8212; &#160; 991 &#160; &#8212; &#160; Repayment of debt &#8212; &#160; ( 312 ) &#8212; &#160; Proceeds from sales of common stock through employee equity plans 268 &#160; 167 &#160; 104 &#160; Repurchases of common stock ( 985 ) ( 3,702 ) ( 1,762 ) Common stock repurchases for tax withholding on employee equity plans ( 427 ) ( 406 ) ( 237 ) Other ( 2 ) ( 2 ) &#8212; &#160; Net cash used in financing activities ( 1,146 ) ( 3,264 ) ( 1,895 ) Net increase (decrease) in cash and cash equivalents ( 902 ) 2,300 &#160; 940 &#160; Cash and cash equivalents at beginning of year 4,835 &#160; 2,535 &#160; 1,595 &#160; Cash and cash equivalents at end of year $ 3,933 &#160; $ 4,835 &#160; $ 2,535 &#160; ##TABLE_END ##TABLE_START Advanced Micro Devices, Inc. Consolidated Statements of Cash Flows Year Ended December 30, 2023 December 31, 2022 December 25, 2021 &#160; (In millions) Supplemental cash flow information: Cash paid during the year for: Interest $ 84 &#160; $ 85 &#160; $ 25 &#160; Income taxes, net of refund $ 523 &#160; $ 685 &#160; $ 35 &#160; Non-cash investing and financing activities: Purchases of property and equipment, accrued but not paid $ 106 &#160; $ 157 &#160; $ 72 &#160; Issuance of common stock and treasury stock for the acquisition of Xilinx $ &#8212; &#160; $ 48,514 &#160; $ &#8212; &#160; Fair value of replacement share-based awards related to acquisition of Xilinx $ &#8212; &#160; $ 275 &#160; $ &#8212; &#160; Non-cash activities for leases: Operating lease right-of-use assets acquired by assuming related liabilities $ 273 &#160; $ 115 &#160; $ 227 &#160; ##TABLE_END See accompanying notes to consolidated financial statements. Advanced Micro Devices, Inc. Notes to Consolidated Financial Statements NOTE 1 &#8211; The Company Advanced Micro Devices, Inc. is a global semiconductor company. References herein to AMD or the Company mean Advanced Micro Devices, Inc. and its consolidated subsidiaries. AMD&#8217;s products include x86 microprocessors (CPUs) and graphics processing units (GPUs), as standalone devices or as incorporated into accelerated processing units (APUs), chipsets, data center and professional GPUs, embedded processors, semi-custom System-on-Chip (SoC) products, microprocessor and SoC development services and technology, data processing units (DPUs), Field Programmable Gate Arrays (FPGAs), System on Modules (SOMs), Smart Network Interface Cards (SmartNICs), AI Accelerators and Adaptive SoC products. From time to time, the Company may also sell or license portions of its intellectual property (IP) portfolio. NOTE 2 &#8211; Basis of Presentation and Significant Accounting Policies Fiscal Year . The Company uses a 52- or 53-week fiscal year ending on the last Saturday in December. Fiscal 2023, 2022 and 2021 ended on December 30, 2023, December 31, 2022 and December 25, 2021, respectively. Fiscal 2023 and 2021 each consisted of 52 weeks, while fiscal 2022 consisted of 53 weeks. Principles of Consolidation. The consolidated financial statements include the Company&#8217;s accounts and those of its wholly-owned subsidiaries. Upon consolidation, all inter-company accounts and transactions have been eliminated. Reclassification. Certain immaterial prior period amounts have been reclassified to conform to current period presentation. Use of Estimates. The preparation of consolidated financial statements in conformity with U.S. generally accepted accounting principles (U.S. GAAP) requires management to make estimates and assumptions that affect the reported amounts of assets and liabilities and disclosure of commitments and contingencies at the date of the financial statements and the reported amounts of revenues and expenses during the reporting periods. Actual results are likely to differ from those estimates, and such differences may be material to the financial statements. Areas where management uses subjective judgment include, but are not limited to, revenue allowances, inventory valuation, valuation of goodwill and long-lived and intangible assets, and income taxes. Revenue Recognition Revenue is recognized when a customer obtains control of promised goods or services and is recognized in an amount that reflects the consideration which the Company expects to receive in exchange for those goods or services. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
