chunk_id,chunk_source,chunk_text,question,answer
"['3e619c5b-8801-886f-1153-21429e404e1b', 'b78da971-cede-623b-d604-234e42dda7f8', 'bbaf48df-5e7e-adae-f1ce-b00cce67e435', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'ce2f35bb-39d8-41ba-dc7b-dcb6036352fd']","['AMD_1A', 'NVDA vs. TSM: Which Chipmaker Stock is Better?', 'Nvidia (NVDA) Reports Q3 Earnings: What Key Metrics Have to Say', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones']","['For instance, with our APU products and other competing solutions with integrated graphics, we believe that demand for additional discrete graphics chips and cards may decrease in the future due to improvements in the quality and performance of integrated graphics. If competitors introduce competitive new products into the market before us, demand for our products could be adversely impacted and our business could be adversely affected. In addition, Intel is expanding its position in integrated graphics for the PC market with high-end discrete graphics solutions for a broad range of computing markets, which may negatively impact our ability to compete in these computing markets, and Nvidia has added an ARM CPU offering which adds competition in the CPU market. Also, increased adoption of ARM-based semiconductor designs could lead to further growth and development of the ARM ecosystem. While we see significant opportunity in AI, we expect intense competition from companies such as Nvidia in the supply of GPUs and other accelerators for the AI market. In addition, we are entering markets with current and new competitors who may be able to adapt more quickly to customer requirements and emerging technologies. We cannot guarantee that we will be able to compete successfully against current or new competitors who may have stronger positions in these new markets or superior ability to anticipate customer requirements and emerging industry trends. Furthermore, we may face competition from some of our customers who internally develop the same products as us. We may face delays or disruptions in research and development efforts, or we may be required to invest significantly greater resources in research and development than anticipated. Also, the semiconductor industry has seen several mergers and acquisitions over the last number of years. Further consolidation could adversely impact our business due to there being fewer suppliers, customers and partners in the industry. From time to time, governments provide incentives or make other investments that could benefit and give a competitive advantage to our competitors. For example, the United States government enacted the Creating Helpful Incentives to Produce Semiconductors for America and Science Act (CHIPS Act) of 2022 to provide financial incentives to the U.S. semiconductor industry. Government incentives, including the CHIPS Act, may not be available to us on acceptable terms or at all. If our competitors can benefit from such government incentives and we cannot, it could strengthen our competitors&#8217; relative position and have a material adverse effect on our business. Our operating results are subject to quarterly and seasonal sales patterns. The profile of our sales may be weighted differently during the year. A large portion of our quarterly sales have historically been made in the last month of the quarter. This uneven sales pattern makes prediction of revenue for each financial period difficult and increases the risk of unanticipated variations in quarterly results and financial condition. In addition, our operating results tend to vary seasonally with the markets in which our products are sold. For example, historically, our net revenue has been generally higher in the second half of the year than in the first half of the year, although market conditions and product transitions could impact these trends. Many of the factors that create and affect quarterly and seasonal trends are beyond our control. If we cannot adequately protect our technology or other intellectual property in the United States and abroad, through patents, copyrights, trade secrets, trademarks and other measures, we may lose a competitive advantage and incur significant expenses. We rely on a combination of protections provided by contracts, including confidentiality and nondisclosure agreements, copyrights, patents, trademarks and common law rights, such as trade secrets, to protect our intellectual property. However, we cannot assure you that we will be able to adequately protect our technology or other intellectual property from third-party infringement or from misappropriation in the United States and abroad. Any patent licensed by us or issued to us could be challenged, invalidated, expire, or circumvented or rights granted thereunder may not provide a competitive advantage to us. Furthermore, patent applications that we file may not result in issuance of a patent or, if a patent is issued, the patent may not be issued in a form that is advantageous to us. Despite our efforts to protect our intellectual property rights, others may independently develop similar products, duplicate our products or design around our patents and other rights. In addition, it is difficult to monitor compliance with, and enforce, our intellectual property on a worldwide basis in a cost-effective manner. In jurisdictions where foreign laws provide less intellectual property protection than afforded in the U.S. and abroad, our technology or other intellectual property may be compromised, and our business would be materially adversely affected. Unfavorable currency exchange rate fluctuations could adversely affect us. We have costs, assets and liabilities that are denominated in foreign currencies. As a consequence, movements in exchange rates could cause our foreign currency denominated expenses to increase as a percentage of revenue, affecting our profitability and cash flows. Whenever we believe appropriate, we hedge a portion of our foreign currency exposure to protect against fluctuations in currency exchange rates. We determine our total foreign currency exposure using projections of long-term expenditures for items such as payroll. We cannot assure you that these activities will be effective in reducing foreign exchange rate exposure. Failure to do so could have an adverse effect on our business, financial condition, results of operations and cash flow. In addition, the majority of our product sales are denominated in U.S. dollars. Fluctuations in the exchange rate between the U.S. dollar and the local currency can cause increases or decreases in the cost of our products in the local currency of such customers. An appreciation of the U.S. dollar relative to the local currency could reduce sales of our products. Operational and Technology Risks We rely on third parties to manufacture our products, and if they are unable to do so on a timely basis in sufficient quantities and using competitive technologies, our business could be materially adversely affected. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', ""Nvidia (NVDA) reported $18.12 billion in revenue for the quarter ended October 2023, representing a year-over-year increase of 205.5%. EPS of $4.02 for the same period compares to $0.58 a year ago.\n\nThe reported revenue compares to the Zacks Consensus Estimate of $16.19 billion, representing a surprise of +11.90%. The company delivered an EPS surprise of +19.64%, with the consensus EPS estimate being $3.36.\n\nWhile investors scrutinize revenue and earnings changes year-over-year and how they compare with Wall Street expectations to determine their next move, some key metrics always offer a more accurate picture of a company's financial health.\n\nAs these metrics influence top- and bottom-line performance, comparing them to the year-ago numbers and what analysts estimated helps investors project a stock's price performance more accurately.\n\nHere is how Nvidia performed in the just reported quarter in terms of the metrics most widely monitored and projected by Wall Street analysts:\n\nRevenue- Gaming : $2.86 billion compared to the $2.72 billion average estimate based on seven analysts. The reported number represents a change of +81.5% year over year.\n\nRevenue- Professional Visualization : $416 million versus the seven-analyst average estimate of $405.52 million. The reported number represents a year-over-year change of +108%.\n\nRevenue- Automotive : $261 million versus $255.15 million estimated by seven analysts on average. Compared to the year-ago quarter, this number represents a +4% change.\n\nRevenue- OEM and Other : $73 million versus $73.15 million estimated by seven analysts on average. Compared to the year-ago quarter, this number represents a 0% change.\n\nRevenue- Data Center: $14.51 billion compared to the $12.66 billion average estimate based on seven analysts. The reported number represents a change of +278.7% year over year.\n\nView all Key Company Metrics for Nvidia here>>>\n\n\n\nShares of Nvidia have returned +17.3% over the past month versus the Zacks S&P 500 composite's +7.9% change. The stock currently has a Zacks Rank #1 (Strong Buy), indicating that it could outperform the broader market in the near term.\n\nStory continues\n\nWant the latest recommendations from Zacks Investment Research? Today, you can download 7 Best Stocks for the Next 30 Days. Click to get this free report\n\nNVIDIA Corporation (NVDA) : Free Stock Analysis Report\n\nTo read this article on Zacks.com click here.\n\nZacks Investment Research"", 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '591c2bb5-1433-43c4-3c95-43e8b4164fba', '7c992416-7a1a-22e1-ae46-f5c25f41d8a2', 'ffe46ef0-5a92-9ff9-8fb1-c56744912b45']","['NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'AMD_8', 'MSFT_8']","['Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', '&#8226; Enterprise Services, including Enterprise Support Services, Industry Solutions (formerly Microsoft Consulting Services), and Nuance professional services. More Personal Computing Our More Personal Computing segment consists of products and services that put customers at the center of the experience with our technology. This segment primarily comprises: &#8226; Windows, including Windows OEM licensing and other non-volume licensing of the Windows operating system; Windows Commercial, comprising volume licensing of the Windows operating system, Windows cloud services, and other Windows commercial offerings; patent licensing; and Windows Internet of Things. &#8226; Devices, including Surface, HoloLens, and PC accessories. PART II Item 8 &#160; &#8226; Gaming, including Xbox hardware and Xbox content and services, comprising first- and third-party content (including games and in-game content), Xbox Game Pass and other subscriptions, Xbox Cloud Gaming, advertising, third-party disc royalties, and other cloud services. &#8226; Search and news advertising, comprising Bing (including Bing Chat), Microsoft News, Microsoft Edge, and third-party affiliates. Revenue and costs are generally directly attributed to our segments. However, due to the integrated structure of our business, certain revenue recognized and costs incurred by one segment may benefit other segments. Revenue from certain contracts is allocated among the segments based on the relative value of the underlying products and services, which can include allocation based on actual prices charged, prices when sold separately, or estimated costs plus a profit margin. Cost of revenue is allocated in certain cases based on a relative revenue methodology. Operating expenses that are allocated primarily include those relating to marketing of products and services from which multiple segments benefit and are generally allocated based on relative gross margin. In addition, certain costs are incurred at a corporate level and allocated to our segments. These allocated costs generally include legal, including settlements and fines, information technology, human resources, finance, excise taxes, field selling, shared facilities services, customer service and support , and severance incurred as part of a corporate program. Each allocation is measured differently based on the specific facts and circumstances of the costs being allocated and is generally based on relative gross margin or relative headcount. Segment revenue and operating income were as follows during the periods presented: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Year Ended June 30, &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Revenue &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes &#160; $ 69,274 &#160; &#160; $ 63,364 &#160; &#160; $ 53,915 &#160; Intelligent Cloud &#160; &#160; 87,907 &#160; &#160; &#160; 74,965 &#160; &#160; &#160; 59,728 &#160; More Personal Computing &#160; &#160; 54,734 &#160; &#160; &#160; 59,941 &#160; &#160; &#160; 54,445 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total &#160; $ 211,915 &#160; &#160; $ 198,270 &#160; &#160; $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Operating Income &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes $ 34,189 &#160; $ 29,690 &#160; $ 24,351 &#160; Intelligent Cloud &#160; 37,884 33,203 &#160; 26,471 More Personal Computing &#160; 16,450 &#160; &#160; 20,490 &#160; &#160; 19,094 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 88,523 &#160; $ 83,383 &#160; $ 69,916 &#160; &#160; &#160; &#160; ##TABLE_END &#160; No sales to an individual customer or country other than the United States accounted for more than 10% of revenue for fiscal years 2023, 2022, or 2021. Revenue, classified by the major geographic areas in which our customers were located, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; United States (a) $ 106,744 $ 100,218 $ 83,953 Other countries 105,171 98,052 84,135 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; ##TABLE_END &#160; (a) Includes billings to OEMs and certain multinational organizations because of the nature of these businesses and the impracticability of determining the geographic source of the revenue. PART II Item 8 &#160; Revenue, classified by significant product and service offerings, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; Server products and cloud services &#160; $ 79,970 $ 67,350 $ 52,589 Office products and cloud services 48,728 &#160; 44,862 39,872 Windows 21,507 24,732 22,488 Gaming 15,466 &#160; 16,230 &#160; 15,370 LinkedIn &#160; 15,145 &#160; &#160; 13,816 &#160; 10,289 Search and news advertising 12,208 &#160; 11,591 &#160; 9,267 Enterprise Services &#160; &#160; 7,722 &#160; &#160; &#160; 7,407 &#160; &#160; &#160; 6,943 &#160; Devices &#160; &#160; 5,521 &#160; &#160; &#160; 7,306 &#160; &#160; &#160; 7,143 &#160; Dynamics 5,437 4,687 3,754 Other &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; ##TABLE_END &#160; Our Microsoft Cloud revenue, which includes Azure and other cloud services, Office 365 Commercial, the commercial portion of LinkedIn, Dynamics 365, and other commercial cloud properties, was $ 111.6 billion, $ 91.4 billion, and $ 69.1 billion in fiscal years 2023, 2022, and 2021, respectively. These amounts are primarily included in Server products and cloud services, Office products and cloud services, LinkedIn, and Dynamics in the table above. Assets are not allocated to segments for internal reporting presentations. A portion of amortization and depreciation is included with various other costs in an overhead allocation to each segment. ', '3. Customer backlog represents the fair value of non-cancellable customer contract orders using the income approach, specifically the multi-period excess earnings method. 4. Product trademarks primarily relate to the Pensando product-related trademarks, and the fair value was determined by applying the income approach, specifically the relief from royalty method. 5. The fair value of IPR&#38;D was determined using the income approach, specifically the multi-period excess earnings method. The fair value of the identified intangible assets subject to amortization are amortized over the assets&#8217; estimated useful lives based on the pattern in which the economic benefits are expected to be received to cost of sales and operating expenses. IPR&#38;D consists of projects that have not yet reached technological feasibility as of the acquisition date. Accordingly, the Company recorded an indefinite-lived intangible asset of $ 220 million for the fair value of these projects, which will initially not be amortized. Instead, these projects will be tested for impairment annually and whenever events or changes in circumstances indicate that these projects may be impaired. Once the project reaches technological feasibility, the Company will begin to amortize the intangible assets over their estimated useful lives. From the Pensando Acquisition Date to December 30, 2023, the Consolidated Statements of Operations include immaterial revenue and operating results attributable to Pensando, which are reported under the Data Center segment. In 2023 and 2022, Pensando acquisition-related costs of $ 190 million and $ 102 million was recorded under Cost of sales, Research and development, and Marketing, general and administrative expenses on the Company&#8217;s Consolidated Statements of Operations. Acquisition-related costs are primarily comprised of direct transaction costs, fair value adjustments for acquired inventory and certain compensation charges. Xilinx Acquisition On February 14, 2022 (Xilinx Acquisition Date), the Company completed the acquisition of all issued and outstanding shares of Xilinx, a leading provider of adaptive computing solutions, for a total purchase consideration of $ 48.8 billion ($ 46.4 billion, net of cash acquired of $ 2.4 billion). The acquisition of Xilinx expands the Company&#8217;s product portfolio to include adaptable hardware platforms that enable hardware acceleration and rapid innovation across a variety of technologies. With the acquisition of Xilinx, the Company now offers FPGAs, Adaptive SoC products and ACAP products. The purchase consideration consisted of $ 48.5 billion of fair value of 429 million shares of the Company&#8217;s common stock issued to Xilinx stockholders and $ 275 million of fair value of replacement equity awards attributable to services rendered pre-combination. As the transaction closed prior to the opening of markets on the Xilinx Acquisition Date, the fair value of the common stock issued to Xilinx stockholders was based on the closing price of the Company&#8217;s common stock on February 11, 2022 of $ 113.18 per share. The financial results of Xilinx are included in the Company&#8217;s consolidated financial statements from the Xilinx Acquisition Date to December 30, 2023 and are reported under the Embedded and Data Center segments. The purchase consideration was allocated as follows: ##TABLE_START (In millions) Cash and cash equivalents $ 2,366 &#160; Short-term investments 1,582 &#160; Accounts receivable 299 &#160; Inventories 539 &#160; Prepaid expenses and other current assets 61 &#160; Property and equipment 692 &#160; Operating lease right-of-use assets 61 &#160; Acquisition-related intangibles 27,308 &#160; Deferred tax assets 15 &#160; Other non-current assets 418 &#160; Total Assets 33,341 &#160; Accounts payable 116 &#160; Accrued liabilities 634 &#160; Other current liabilities 185 &#160; Long-term debt 1,474 &#160; Long-term operating lease liabilities 45 &#160; Deferred tax liabilities 4,346 &#160; Other long-term liabilities 532 &#160; Total Liabilities 7,332 &#160; Fair value of net assets acquired 26,009 &#160; Goodwill 22,784 &#160; Total purchase consideration $ 48,793 &#160; ##TABLE_END The Company allocated the purchase price to tangible and identified intangible assets acquired and liabilities assumed based on the estimates of their fair values, which were determined using generally accepted valuation techniques based on estimates and assumptions made by management. Goodwill arising from the acquisition of Xilinx was assigned to the Embedded and Data Center segments. Goodwill was primarily attributed to increased synergies expected to be achieved from the integration of Xilinx. Goodwill is not expected to be deductible for income tax purposes. Following are details of the purchase consideration allocated to acquired intangible assets: ##TABLE_START Fair Value Weighted-average estimated useful life (In millions) (In years) Developed technology (1) $ 12,295 &#160; 16 years Customer relationships (2) 12,290 &#160; 14 years Customer backlog (3) 793 &#160; 1 year Corporate trade name (4) 65 &#160; 1 year Product trademarks (4) 895 &#160; 12 years Identified intangible assets subject to amortization 26,338 &#160; In-process research and development (IPR&#38;D) not subject to amortization (5) 970 &#160; N/A Total identified intangible assets acquired $ 27,308 &#160; ##TABLE_END 1. The fair value of developed technology was determined using the income approach, specifically, the multi-period excess earnings method. 2. Customer relationships represent the fair value of existing contractual relationships and customer loyalty determined based on existing relationships using the income approach, specifically the with and without method. 3. Customer backlog represents the fair value of non-cancellable customer contract orders using the income approach, specifically the multi-period excess earnings method. 4. Corporate trade name and product trademarks primarily relate to the Xilinx brand and product-related trademarks, respectively, and the fair values were determined by applying the income approach, specifically the relief from royalty method. 5. The fair value of IPR&#38;D was determined using the income approach, specifically the multi-period excess earnings method. The fair value of the identified intangible assets subject to amortization are amortized over the assets&#8217; estimated useful lives based on the pattern in which the economic benefits are expected to be received to cost of sales and operating expenses. IPR&#38;D consists of projects that have not yet reached technological feasibility as of the acquisition date. Accordingly, the Company recorded an indefinite-lived intangible asset of $ 970 million for the fair value of these projects, which were initially not amortized. In the fourth quarter of 2023, these IPR&#38;D assets reached technological feasibility and were reclassified as developed technology, and began amortization over their estimated useful lives of 15 years. ']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '6adecac3-8cfd-87c3-bf7c-02b74f9a3d98', 'c7d4a648-4b94-a253-4158-d1cc5b9512e2', 'd87a0bff-9952-0e44-46ff-553112acdec1']","['TSM sells LCS slot to Shopify Rebellion', 'Iconic League of Legends team TSM replaced by Shopify in pro league', 'TSM pausing esports efforts in several titles, per sources', 'MSFT_8']","['Shopify is making a big investment in franchised esports, buying the slot in League of Legends’ North American circuit currently held by TSM. Canada-based Shopify launched an in-house competitive gaming team, Shopify Rebellion, in 2021, as company co-founder and CEO Tobias ""Tobi"" Lütke has long been an esports fan. Sources tell SBJ that TSM has been looking to offload its franchise slot in Riot Games’ LCS circuit since June. Terms of the deal were not available at press time. Shopify Rebellion also plays competitively in Starcraft II, Rocket League, Valorant, and others.\n\nHowever, this may not be the end of League of Legends for North American Esports organization TSM as sources tell SBJ they may be looking to acquire another League of Legends team based in Asia to participate in League of Legends Champions Korea or League of Legends Pro League (China).\n\nShopify also made another move, piggybacking off their LCS announcment, revealing that they have partnered with Moist Esports to run a Valorant team as part of a joint effort.\n\nThis is a developing story and will be updated.', 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Shopify is entering the League of Legends arena. On Wednesday, Shopify announced that its Rebellion esports brand will be acquiring TSM’s spot in the League Championship Series (LCS), the pro circuit for US League of Legends esports.\n\nThe move marks a major change of the guard in the LCS. TSM, one of the biggest esports organizations in the world, got its start as a scrappy League of Legends team; the TSM acronym stands for Team SoloMid, which references a solo League of Legends player occupying the middle lane of the game’s multi-pronged map. In the mid 2010s, TSM was one of the most successful teams in the LCS, and the organization has entered other esports, signed Twitch streamers, and even bought an esports app.\n\nBut TSM has had some struggles as of late. Its LCS team hasn’t been quite as successful in League (outside of an impressive run in 2020). TSM CEO and founder Andy Dinh was fined and placed on a two-year probation by League of Legends developer Riot Games after an investigation found that “there was a pattern and practice of disparaging and bullying behavior exhibited by Dinh” toward TSM staff and players. The organization was forced to back out of a $210 million deal with FTX after the crypto company collapsed.\n\nThen, in March, Sports Business Journal reported that TSM was considering dumping its LCS team, and in May, TSM announced that it was looking to sell its LCS spot and compete in League of Legends in another region. “I believe moving to another region will re-ignite our hunger to do whatever it takes to win a world championship,” Dinh said in a video about the change.\n\nShopify Rebellion will compete in the LCS starting in 2024. “Entering League of Legends — one of the largest esports titles, with a rich competitive history — felt like an obvious next step for us as we continue to grow our presence in esports,” Shopify Rebellion’s Dario “TLO” Wünsch said in a statement. The organization also competes in games like Dota 2, Valorant, and Rocket League.\n\nTSM hasn’t said where it may end up fielding a League of Legends team next. But the organization is already positioning itself as a global brand. “TSM is a movement, binding us all together no matter who we are or where we came from,” TSM wrote in a post on X (formerly Twitter). “From North America and Europe to South America and Asia, our hearts beat as one.”', 'L.A.-based TSM will be pausing most its esports efforts in several titles and may be putting its League of Legends Championship Series franchise on the block, sources tell SBJ. TSM is one of the more popular esports and lifestyle organizations within gaming, and also fields competitive squads in Valorant, Fortnite, Apex Legends, and others. Sources tell SBJ that TSM took a big financial hit when its 10-year, $210 million naming rights deal with FTX disappeared after the crypto brand infamously went belly up. That pact was the most lucrative in all of esports sponsorships.\n\nThe pausing of esports continues a period of significant change at TSM, which last month saw its COO depart the organization and in February saw its defending-champion Rainbow Six: Siege squad depart that esports circuit.\n\nHowever, after the downfall of FTX last year TSM put out a statement that said, “TSM is built on a solid foundation. We are stable and profitable, and we continue to forecast profitability for this year, next year, and beyond. We look forward to a great year in 2023.""\n\nSources also tell SBJ that TSM will continue to focus on its Blitz application, a tool that helps video game players develop in-game skills and strategy in titles such as League of Legends, Valorant, and more.']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '3e619c5b-8801-886f-1153-21429e404e1b', '4ebba5df-5943-d59e-0f3d-e716f0014ca8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'e7d340bf-9774-758b-ec8e-788e34558d81']","['The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'NVDA_7', 'AMD Issues Official Statement on Reported Ryzen 7000 Burnout Issues', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', ""How Weak Demand Is Putting A Damper On Taiwan Semi's Outlook — And Those Of Others""]","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'Yesterday we reported that MSI announced a wave of firmware updates designed to address and alleviate potential issues with users on AM5 using AMD\'s Ryzen 7000X3D processors with 3D V-Cache. One of the main changes with MSI\'s latest UEFI firmware for AM5 included voltage restrictions when using Ryzen 7000X3D series CPUs. Further to recent reports of users with AMD Ryzen 7000X3D processors experiencing damage to their chip and motherboard socket, we reached out to AMD this morning to seek clarification. AMD has just responded with an official statement concerning the current problem.\n\nThe statement directly from AMD is as follows:\n\n""We are aware of a limited number of reports online claiming that excess voltage while overclocking may have damaged the motherboard socket and pin pads. We are actively investigating the situation and are working with our ODM partners to ensure voltages applied to Ryzen 7000X3D CPUs via motherboard BIOS settings are within product specifications. Anyone whose CPU may have been impacted by this issue should contact AMD customer support.""\n\nAs the statement clarifies, AMD themselves are investigating the issue that users have been experiencing, which has been reported on through various channels such as social media and Reddit. This is further to MSI, which launched new firmware yesterday, and ASUS announced new firmware today for users with AMD Ryzen 7000X3D processors, such as the Ryzen 9 7950X3D and the Ryzen 7 7800X3D. The new firmware specifically limits the SoC voltages applied so that these critical limits aren\'t breached when users enable AMD EXPO memory profiles on supported DRAM.\n\nWhile AMD hasn\'t officially confirmed the problem regarding the burnt pads on the Ryzen 7000X3D series processors and the burnt pins within the motherboard socket, AMD is actively looking to resolve this issue. One theory thus far is that the issue is being triggered when users are enabling AMD EXPO memory profiles – which, much like Intel\'s XMP counterpart, is technically a form of overclocking and officially voids the product warranty. Given the rollout of new firmware, which targets SoC voltages and restricts them, all things point towards voltages and overclocking said processors, which are, by default, multiplier and CPU VCore locked.\n\nAMD is actively working with motherboard vendors such as MSI, ASUS, GIGABYTE, and ASRock to roll out the new firmware. AMD also specifies that if users have a Ryzen 7000X3D processor affected by this problem, to contact AMD customer support directly.\n\nUpdate (04/27): AMD has officially made a second statement regarding the Ryzen 7000 and 7000X3D burnout issues. It is as follows:\n\nWe have root caused the issue and have already distributed a new AGESA that puts measures in place on certain power rails on AM5 motherboards to prevent the CPU from operating beyond its specification limits, including a cap on SOC voltage at 1.3V. None of these changes affect the ability of our Ryzen 7000 Series processors to overclock memory using EXPO or XMP kits or boost performance using PBO technology. We expect all of our ODM partners to release new BIOS for their AM5 boards over the next few days. We recommend all users to check their motherboard manufacturers website and update their BIOS to ensure their system has the most up to date software for their processor. Anyone whose CPU may have been impacted by this issue should contact AMD customer support. Our customer service team is aware of the situation and prioritizing these cases.\n\nImage source: Speedrookie/Reddit', 'Shares of Taiwan Semiconductor Manufacturing (TSM) took a beating Thursday as the world\'s largest contract chipmaker topped analyst estimates for the second quarter but disappointed with its outlook. TSM stock fell more than 5% and dragged other chip players down with it.\n\nX\n\nTaiwan Semiconductor, better known as TSMC, earned $1.14 per U.S. share on sales of $15.68 billion in the June quarter. Analysts polled by FactSet had expected earnings of $1.07 a share on sales of $15.44 billion. However, TSMC earnings fell 25% year over year while sales dropped 12%. In local currency, earnings decreased 23% while sales declined 10%.\n\nTSMC\'s results marked its second straight quarter of declining sales and earnings as its customers navigate a downturn in chip demand.\n\nFor the current quarter, TSMC predicted revenue of $16.7 billion to $17.5 billion. The midpoint of $17.1 billion is below Wall Street\'s target of $17.4 billion. In the year-earlier period, TSMC generated $19.2 billion in sales.\n\nTSM Stock Falls After Report\n\nTaiwan Semiconductor also cut its revenue forecast for the full year to a 10% decline from a mid-single-digit decline.\n\n""This is the third cut to its revenue outlook that TSMC has made this cycle,"" Needham analyst Charles Shi said in a note to clients. Shi had expected TSMC to reduce its 2023 sales outlook to a high-single-digit decline.\n\n""TSMC\'s second-quarter earnings call may go down as one of the more pessimistic calls in recent history,"" Shi said.\n\nOn the stock market today, TSM stock tumbled 5.1% to close at 97.86.\n\nTSMC\'s earnings report pulled down a host of semiconductor stocks. The Philadelphia semiconductor index, known as SOX, sank 3.6% on Thursday. The SOX includes the 30 largest semiconductor stocks traded in the U.S.\n\nAmong major TSMC customers, Advanced Micro Devices (AMD) fell 5.3% and Nvidia (NVDA) retreated 3.3%.\n\nTSM stock is in a flat base with a buy point of 110.69, according to IBD MarketSmith charts.\n\nFactors Behind Soft Demand\n\n""Our second-quarter business was impacted by the overall global economic conditions, which dampened the end-market demand, and led to customers\' ongoing inventory adjustment,"" Chief Financial Officer Wendell Huang said in a news release.\n\nHe added, ""Moving into third quarter 2023, we expect our business to be supported by the strong ramp of our 3-nanomenter technologies, partially offset by customers\' continued inventory adjustment.""\n\nCircuit widths on chips are measured in nanometers, which are one-billionth of a meter.\n\nThe slower-than-expected economic recovery in China also is a factor in TSMC\'s reduced outlook, Evercore ISI analyst C.J. Muse said in a report.\n\nIn addition, the chip inventory correction now is likely to last through the fourth quarter, rather than the third quarter as previously expected, Muse said.\n\nTaiwan Semi Getting AI Boost\n\nTaiwan Semiconductor produces chips for fabless semiconductor firms such as AMD, Apple (AAPL), Broadcom (AVGO), Nvidia and Qualcomm (QCOM).\n\nCyclical headwinds overshadowed strength in AI chip production at TSMC in the second quarter, Needham\'s Shi said.\n\nTSMC management expects chips for artificial intelligence to grow to a low-teens percent of sales by 2028 from 6% today.\n\n""Management still sees Q3 as the end of an inventory correction but believes customers may not build inventory back as fast as previously expected,"" Shi said.\n\nTSM Stock On Tech Leaders List\n\nWedbush Securities analyst Matt Bryson kept his outperform rating on TSM stock despite the company\'s disappointing outlook.\n\n""While we believe this deterioration in outlook wasn\'t unexpected, the magnitude of the downtick was more significant than we had anticipated heading into earnings,"" Bryson said in a note to clients.\n\nTSM stock ranks sixth out of 30 stocks in IBD\'s semiconductor manufacturing industry group, according to IBD Stock Checkup. Taiwan Semiconductor has an IBD Composite Rating of 92 out of 99. IBD\'s Composite Rating is a blend of key fundamental and technical metrics to help investors gauge a stock\'s strengths. The best growth stocks have a Composite Rating of 90 or better.\n\nFurther, TSM stock is on the IBD Tech Leaders list.\n\nFollow Patrick Seitz on Twitter at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nChip Gear Maker ASML Beats Second-Quarter Targets, Guides Higher\n\nNetflix Crushes Subscriber Goal As It Turns Freeloaders Into Paying Customers\n\nApple Stock Rises As India Seen Driving Growth For iPhone Maker\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens']",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '351c3238-8399-938c-39a7-559ab00d880b', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'ffe46ef0-5a92-9ff9-8fb1-c56744912b45']","['Samsung Electronics and AMD Extend Strategic IP Licensing Agreement To Bring AMD Radeon™ Graphics to Future Mobile Platforms', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'MSFT_8']","['Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Companies broaden scope of mobile graphics collaboration to bring leadership\n\nAMD Radeon graphics technology to expanded portfolio of Samsung Exynos SoCs\n\nSamsung Electronics, a world leader in advanced semiconductor technology, and AMD (NASDAQ: AMD) today announced they have signed a multi-year agreement extension to bring multiple generations of high-performance, ultra-low-power AMD Radeon graphics solutions to an expanded portfolio of Samsung Exynos SoCs. Through the licensing extension, Samsung will bring console-level graphics quality and optimized power consumption to more mobile devices, offering an incredibly immersive and long-lasting gaming experience.\n\n“Together with AMD, Samsung has been revolutionizing mobile graphics, including our recent collaboration that brought ray tracing capability to mobile processors for the first time in the industry,” said Seogjun Lee, Executive Vice President of Application Processor (AP) Development at Samsung Electronics. “Drawing on our technological know-how in designing ultra-low-power solutions, we will continue to drive ongoing innovation in the mobile graphics space.”\n\n“We are excited Samsung selected multiple generations of our leadership high-performance Radeon graphics to advance the next generation of Samsung Exynos solutions,” said David Wang, Senior Vice President of the Radeon Technologies Group at AMD. “The extension of our work with Samsung is a testament to our strong technology partnership and commitment to bring the best experiences possible to mobile users.”\n\nSamsung and AMD first announced their partnership to license AMD RDNA™ graphics architecture in 2019, leading to the co-development of Samsung Xclipse, a mobile graphics processing unit (GPU) based on the AMD RDNA 2 architecture in 2022. Xclipse was the industry’s first mobile GPU with hardware-accelerated ray tracing and variable rate shading features for console-like gameplay on mobile devices.', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', '&#8226; Enterprise Services, including Enterprise Support Services, Industry Solutions (formerly Microsoft Consulting Services), and Nuance professional services. More Personal Computing Our More Personal Computing segment consists of products and services that put customers at the center of the experience with our technology. This segment primarily comprises: &#8226; Windows, including Windows OEM licensing and other non-volume licensing of the Windows operating system; Windows Commercial, comprising volume licensing of the Windows operating system, Windows cloud services, and other Windows commercial offerings; patent licensing; and Windows Internet of Things. &#8226; Devices, including Surface, HoloLens, and PC accessories. PART II Item 8 &#160; &#8226; Gaming, including Xbox hardware and Xbox content and services, comprising first- and third-party content (including games and in-game content), Xbox Game Pass and other subscriptions, Xbox Cloud Gaming, advertising, third-party disc royalties, and other cloud services. &#8226; Search and news advertising, comprising Bing (including Bing Chat), Microsoft News, Microsoft Edge, and third-party affiliates. Revenue and costs are generally directly attributed to our segments. However, due to the integrated structure of our business, certain revenue recognized and costs incurred by one segment may benefit other segments. Revenue from certain contracts is allocated among the segments based on the relative value of the underlying products and services, which can include allocation based on actual prices charged, prices when sold separately, or estimated costs plus a profit margin. Cost of revenue is allocated in certain cases based on a relative revenue methodology. Operating expenses that are allocated primarily include those relating to marketing of products and services from which multiple segments benefit and are generally allocated based on relative gross margin. In addition, certain costs are incurred at a corporate level and allocated to our segments. These allocated costs generally include legal, including settlements and fines, information technology, human resources, finance, excise taxes, field selling, shared facilities services, customer service and support , and severance incurred as part of a corporate program. Each allocation is measured differently based on the specific facts and circumstances of the costs being allocated and is generally based on relative gross margin or relative headcount. Segment revenue and operating income were as follows during the periods presented: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Year Ended June 30, &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Revenue &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes &#160; $ 69,274 &#160; &#160; $ 63,364 &#160; &#160; $ 53,915 &#160; Intelligent Cloud &#160; &#160; 87,907 &#160; &#160; &#160; 74,965 &#160; &#160; &#160; 59,728 &#160; More Personal Computing &#160; &#160; 54,734 &#160; &#160; &#160; 59,941 &#160; &#160; &#160; 54,445 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total &#160; $ 211,915 &#160; &#160; $ 198,270 &#160; &#160; $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Operating Income &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes $ 34,189 &#160; $ 29,690 &#160; $ 24,351 &#160; Intelligent Cloud &#160; 37,884 33,203 &#160; 26,471 More Personal Computing &#160; 16,450 &#160; &#160; 20,490 &#160; &#160; 19,094 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 88,523 &#160; $ 83,383 &#160; $ 69,916 &#160; &#160; &#160; &#160; ##TABLE_END &#160; No sales to an individual customer or country other than the United States accounted for more than 10% of revenue for fiscal years 2023, 2022, or 2021. Revenue, classified by the major geographic areas in which our customers were located, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; United States (a) $ 106,744 $ 100,218 $ 83,953 Other countries 105,171 98,052 84,135 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; ##TABLE_END &#160; (a) Includes billings to OEMs and certain multinational organizations because of the nature of these businesses and the impracticability of determining the geographic source of the revenue. PART II Item 8 &#160; Revenue, classified by significant product and service offerings, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; Server products and cloud services &#160; $ 79,970 $ 67,350 $ 52,589 Office products and cloud services 48,728 &#160; 44,862 39,872 Windows 21,507 24,732 22,488 Gaming 15,466 &#160; 16,230 &#160; 15,370 LinkedIn &#160; 15,145 &#160; &#160; 13,816 &#160; 10,289 Search and news advertising 12,208 &#160; 11,591 &#160; 9,267 Enterprise Services &#160; &#160; 7,722 &#160; &#160; &#160; 7,407 &#160; &#160; &#160; 6,943 &#160; Devices &#160; &#160; 5,521 &#160; &#160; &#160; 7,306 &#160; &#160; &#160; 7,143 &#160; Dynamics 5,437 4,687 3,754 Other &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; ##TABLE_END &#160; Our Microsoft Cloud revenue, which includes Azure and other cloud services, Office 365 Commercial, the commercial portion of LinkedIn, Dynamics 365, and other commercial cloud properties, was $ 111.6 billion, $ 91.4 billion, and $ 69.1 billion in fiscal years 2023, 2022, and 2021, respectively. These amounts are primarily included in Server products and cloud services, Office products and cloud services, LinkedIn, and Dynamics in the table above. Assets are not allocated to segments for internal reporting presentations. A portion of amortization and depreciation is included with various other costs in an overhead allocation to each segment. ']",,
"['77899e50-1aae-2b16-f8d4-65c30e9717d0', 'adfada1a-9035-2536-c50b-c83d3f18a36a', 'b62cc0aa-1de6-c896-1788-a3a15c52d0a3', 'b78da971-cede-623b-d604-234e42dda7f8', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'META_1A', 'NVDA_7', 'Testing Meta Verified to Help Creators Establish Their Presence', 'MSFT_1']","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on June 27, 2023 at 7:30 AM PT:\n\nWe’re excited to begin rolling out Meta Verified to most markets globally over the coming months.\n\nWe’ve heard positive feedback from creators in our initial tests and continue to gather input about what’s most valuable for subscribers. We’ll continue to evolve Meta Verified based on these learnings and explore new features and benefits that create more value for subscribers.\n\nUpdate on June 7, 2023 at 7:30 AM PT:\n\nMeta Verified is now available in India and will soon be available in Brazil.\n\nUpdate on May 31, 2023 at 9:00 AM PT:\n\nMeta Verified is now available in Canada.\n\nUpdate on May 16, 2023 at 7:40 AM PT:\n\nMeta Verified is now available in the United Kingdom.\n\nUpdate on March 17, 2023 at 11 AM PT:\n\nWe’re expanding our test of Meta Verified to the US after seeing good results from our early testing. This test in the US will reflect some initial learnings and feedback. We’re removing increased reach as a subscription feature for now, as we gather more feedback and further evolve Meta Verified. We’re exploring elements to add to the subscription as we roll out to more places and will share more when we’re ready.\n\nOriginally published on February 19, 2023 at 12 PM PT:\n\nTo help up-and-coming creators grow their presence and build community faster, today Mark Zuckerberg announced that we’ll begin testing a new offering called Meta Verified, a subscription bundle on Instagram and Facebook that includes a verified badge that authenticates your account with government ID, proactive account protection, access to account support, and increased visibility and reach. We’re starting with a gradual test in Australia and New Zealand later this week to learn what’s most valuable, and we hope to bring Meta Verified to the rest of the world soon.\n\nSome of the top requests we get from creators are for broader access to verification and account support, in addition to more features to increase visibility and reach. Since last year, we’ve been thinking about how to unlock access to these features through a paid offering.\n\nWith Meta Verified, you’ll get:\n\nA verified badge, confirming you’re the real you and that your account has been authenticated with a government ID.¹\n\nMore protection from impersonation with proactive account monitoring for impersonators who might target people with growing online audiences.\n\nHelp when you need it with access to a real person for common account issues.\n\nIncreased visibility and reach with prominence in some areas of the platform– like search, comments and recommendations.²\n\nExclusive features to express yourself in unique ways.³\n\nMeta Verified is available for direct purchase on Instagram or Facebook in Australia and New Zealand starting later this week. People can purchase a monthly subscription for (USD) $11.99 on the web and (USD) $14.99 on iOS and Android.4\n\nAs we test and learn, there will be no changes to accounts on Instagram and Facebook that are already verified based on prior requirements. Long term, we want to build a subscription offering that’s valuable to everyone, including creators, businesses and our community at large. As part of this vision, we are evolving the meaning of verified accounts on our apps so we can expand access to verification and more people can trust the accounts they interact with are authentic.\n\nBuilding Safety from the Beginning\n\nIt’s important to feel confident that your identity and accounts are safe and that the people you’re interacting with are who they say they are. That’s why we’re building a series of checks into Meta Verified before, during, and after someone applies.\n\nTo be eligible, accounts must meet minimum activity requirements, such as prior posting history, and be at least 18 years old .\n\nApplicants are then required to submit a government ID that matches the profile name and photo of the Facebook or Instagram account they’re applying for .\n\nSubscriptions will include proactive monitoring for account impersonation.\n\nWe’re also committed to continuous monitoring and review of reported violations, as well as taking swift action against those who try to evade our systems.\n\nTo learn more about Meta Verified visit Mark Zuckerberg’s Meta Channel on Instagram on your mobile device.\n\n1. Where available, some subscribers may be required to submit a selfie video as part of the authentication process.\n\n2. We’ll offer exclusive stickers on Facebook and Instagram Stories and Facebook Reels, and 100 free stars a month on Facebook so you can show your support for other creators.\n\n3. AUD 19.99 on web, AUD 24.99 on iOS and Android. NZD 23.99 on web, NZD 29.99 on iOS and Android. Subscription features are the same for both web and app purchases.\n\n4. Businesses are not eligible to apply for Meta Verified at this time.', 'PART I Item 1 &#160; OPERATING SEGMENTS We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal Computing. Our segments provide management with a comprehensive financial view of our key businesses. The segments enable the alignment of strategies and objectives across the development, sales, marketing, and services organizations, and they provide a framework for timely and rational allocation of resources within businesses. Additional information on our operating segments and geographic and product information is contained in Note 19 &#8211; Segment Information and Geographic Data of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K). Our reportable segments are described below. Productivity and Business Processes Our Productivity and Business Processes segment consists of products and services in our portfolio of productivity, communication, and information services, spanning a variety of devices and platforms. This segment primarily comprises: &#8226; Office Commercial (Office 365 subscriptions, the Office 365 portion of Microsoft 365 Commercial subscriptions, and Office licensed on-premises), comprising Office, Exchange, SharePoint, Microsoft Teams, Office 365 Security and Compliance, Microsoft Viva, and Microsoft 365 Copilot. &#8226; Office Consumer, including Microsoft 365 Consumer subscriptions, Office licensed on-premises, and other Office services. &#8226; LinkedIn, including Talent Solutions, Marketing Solutions, Premium Subscriptions, and Sales Solutions. &#8226; Dynamics business solutions, including Dynamics 365, comprising a set of intelligent, cloud-based applications across ERP, CRM (including Customer Insights), Power Apps, and Power Automate; and on-premises ERP and CRM applications. Office Commercial Office Commercial is designed to increase personal, team, and organizational productivity through a range of products and services. Growth depends on our ability to reach new users in new markets such as frontline workers, small and medium businesses, and growth markets, as well as add value to our core product and service offerings to span productivity categories such as communication, collaboration, analytics, security, and compliance. Office Commercial revenue is mainly affected by a combination of continued installed base growth and average revenue per user expansion, as well as the continued shift from Office licensed on-premises to Office 365. Office Consumer Office Consumer is designed to increase personal productivity and creativity through a range of products and services. Growth depends on our ability to reach new users, add value to our core product set, and continue to expand our product and service offerings into new markets. Office Consumer revenue is mainly affected by the percentage of customers that buy Office with their new devices and the continued shift from Office licensed on-premises to Microsoft 365 Consumer subscriptions. Office Consumer Services revenue is mainly affected by the demand for communication and storage through Skype, Outlook.com, and OneDrive, which is largely driven by subscriptions, advertising, and the sale of minutes. PART I Item 1 &#160; LinkedIn LinkedIn connects the world&#8217;s professionals to make them more productive and successful and transforms the way companies hire, market, sell, and learn. Our vision is to create economic opportunity for every member of the global workforce through the ongoing development of the world&#8217;s first Economic Graph, a digital representation of the global economy. In addition to LinkedIn&#8217;s free services, LinkedIn offers monetized solutions: Talent Solutions, Marketing Solutions, Premium Subscriptions, and Sales Solutions. Talent Solutions provide insights for workforce planning and tools to hire, nurture, and develop talent. Talent Solutions also includes Learning Solutions, which help businesses close critical skills gaps in times where companies are having to do more with existing talent. Marketing Solutions help companies reach, engage, and convert their audiences at scale. Premium Subscriptions enable professionals to manage their professional identity, grow their network, find jobs, and connect with talent through additional services like premium search. Sales Solutions help companies strengthen customer relationships, empower teams with digital selling tools, and acquire new opportunities. LinkedIn has over 950 million members and has offices around the globe. Growth will depend on our ability to increase the number of LinkedIn members and our ability to continue offering services that provide value for our members and increase their engagement. LinkedIn revenue is mainly affected by demand from enterprises and professional organizations for subscriptions to Talent Solutions, Sales Solutions, and Premium Subscriptions offerings, as well as member engagement and the quality of the sponsored content delivered to those members to drive Marketing Solutions. Dynamics Dynamics provides cloud-based and on-premises business solutions for financial management, enterprise resource planning (&#8220;ERP&#8221;), customer relationship management (&#8220;CRM&#8221;), supply chain management, and other application development platforms for small and medium businesses, large organizations, and divisions of global enterprises. Dynamics revenue is driven by the number of users licensed and applications consumed, expansion of average revenue per user, and the continued shift to Dynamics 365, a unified set of cloud-based intelligent business applications, including Power Apps and Power Automate. Competition Competitors to Office include software and global application vendors, such as Apple, Cisco Systems, Meta, Google, Okta, Proofpoint, Slack, Symantec, Zoom, and numerous web-based and mobile application competitors as well as local application developers. Apple distributes versions of its pre-installed application software, such as email and calendar products, through its PCs, tablets, and phones. Cisco Systems is using its position in enterprise communications equipment to grow its unified communications business. Meta offers communication tools to enable productivity and engagement within organizations. Google provides a hosted messaging and productivity suite. Slack provides teamwork and collaboration software. Zoom offers videoconferencing and cloud phone solutions. Okta, Proofpoint, and Symantec provide security solutions across email security, information protection, identity, and governance. Web-based offerings competing with individual applications have also positioned themselves as alternatives to our products and services. We compete by providing powerful, flexible, secure, integrated industry-specific, and easy-to-use productivity and collaboration tools and services that create comprehensive solutions and work well with technologies our customers already have both on-premises or in the cloud. LinkedIn faces competition from online professional networks, recruiting companies, talent management companies, and larger companies that are focusing on talent management and human resource services; job boards; traditional recruiting firms; and companies that provide learning and development products and services. Marketing Solutions competes with online and offline outlets that generate revenue from advertisers and marketers, and Sales Solutions competes with online and offline outlets for companies with lead generation and customer intelligence and insights. ', 'Maintaining and enhancing our brands will require us to make substantial investments and these investments may not be successful. Certain of our actions, such as the foregoing matter regarding developer misuse of data and concerns around our handling of political speech and advertising, hate speech, and other content, as well as user well-being issues, have eroded confidence in our brands and may continue to do so in the future. If we fail to successfully promote and maintain our brands or if we incur excessive expenses in this effort, our business and financial results may be adversely affected. We may not be able to continue to successfully maintain or grow usage of and engagement with applications that integrate with our products. We have made and are continuing to make investments to enable developers to build, grow, and monetize applications that integrate with our products. Such existing and prospective developers may not be successful in building, growing, or monetizing applications that create and maintain user engagement. Additionally, developers may choose to build on other platforms, including platforms controlled by third parties, rather than building products that integrate with our products. We are continuously seeking to balance the distribution objectives of our developers with our desire to provide an optimal user experience, and we may not be successful in achieving a balance that continues to attract and retain such developers. For example, from time to time, we have taken actions to reduce the volume of communications from these developers to users on our products with the objective of enhancing the user experience, and such actions have reduced distribution from, user engagement with, and our monetization opportunities from, applications integrated with our products. In addition, as part of our efforts related to privacy, safety, and security, we conduct investigations and audits of platform applications from time to time, and we also have announced several product changes that restrict developer access to certain user data. In some instances, these actions, as well as other actions to enforce our policies applicable to developers, have adversely affected, or will adversely affect, our relationships with developers. If we are not successful in our efforts to maintain or grow the number of developers that choose to build products that integrate with our products or if we are unable to continue to build and maintain good relations with such developers, our user growth and user engagement and our financial results may be adversely affected. Table of Contents Risks Related to Our Business Operations and Financial Results Our business is highly competitive. Competition presents an ongoing threat to the success of our business. We compete with companies providing connection, sharing, discovery, and communication products and services to users online, as well as companies that sell advertising to businesses looking to reach consumers and/or develop tools and systems for managing and optimizing advertising campaigns. We face significant competition in every aspect of our business, including, but not limited to, companies that facilitate the ability of users to create, share, communicate, and discover content and information online or enable marketers to reach their existing or prospective audiences. We compete to attract, engage, and retain people who use our products, to attract and retain businesses that use our free or paid business and advertising services, and to attract and retain developers who build compelling applications that integrate with our products. We also compete with companies that develop and deliver consumer hardware and virtual and augmented reality products and services. We also expect to face additional competition as we introduce or acquire new products, as our existing products evolve, or as other companies introduce new products and services, including as part of efforts to develop the metaverse or innovate through the development and application of new technologies such as AI. Some of our current and potential competitors may have greater resources, experience, or stronger competitive positions in certain product segments, geographic regions, or user demographics than we do. For example, some of our competitors may be domiciled in different countries and subject to political, legal, and regulatory regimes that enable them to compete more effectively than us. These factors may allow our competitors to respond more effectively than us to new or emerging technologies and changes in market conditions. We believe that some users, particularly younger users, are aware of and actively engaging with other products and services similar to, or as a substitute for, our products and services, and we believe that some users have reduced their use of and engagement with our products and services in favor of these other products and services. In addition, from time to time we make updates to our products and services to improve the user experience (including to help provide users with safe, positive, age-appropriate experiences), and these changes have had, and may in the future have, the effect of reducing time spent and some measures of user engagement with our products and services. In the event that users increasingly engage with other products and services, we may experience a decline in use and engagement in key user demographics or more broadly, in which case our business would likely be harmed. Our competitors may develop products, features, or services that are similar to ours or that achieve greater acceptance, may undertake more far-reaching and successful product development efforts or marketing campaigns, or may adopt more aggressive pricing policies. Some competitors may gain a competitive advantage against us in areas where we operate, including: by making acquisitions; by limiting our ability to deliver, target, or measure the effectiveness of ads; by imposing fees or other charges related to our applications or our delivery of ads; by making access to our products more difficult or impossible; by making it more difficult to communicate with our users; or by integrating competing platforms, applications, or features into products they control such as mobile device operating systems, search engines, browsers, or e-commerce platforms. For example, each of Apple and Google have integrated competitive products with iOS and Android, respectively. In addition, Apple has released changes to iOS that limit our ability, and the ability of others in the digital advertising industry, to target and measure ads effectively. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', 'c22d4f50-5edf-6e64-760e-55cd59c3ac0e', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['NVDA_7', ""AMD reveals new A.I. chip to challenge Nvidia's dominance"", 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'META_7']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Lisa Su displays an AMD Instinct MI300 chip as she delivers a keynote address at CES 2023 in Las Vegas, Nevada, on Jan. 4, 2023.\n\nAMD said on Tuesday its most-advanced GPU for artificial intelligence, the MI300X, will start shipping to some customers later this year.\n\nAMD\'s announcement represents the strongest challenge to Nvidia , which currently dominates the market for AI chips with over 80% market share, according to analysts.\n\nGPUs are chips used by firms like OpenAI to build cutting-edge AI programs such as ChatGPT.\n\nIf AMD\'s AI chips, which it calls ""accelerators,"" are embraced by developers and server makers as substitutes for Nvidia\'s products, it could represent a big untapped market for the chipmaker, which is best known for its traditional computer processors.\n\nAMD CEO Lisa Su told investors and analysts in San Francisco on Tuesday that AI is the company\'s ""largest and most strategic long-term growth opportunity.""\n\n""We think about the data center AI accelerator [market] growing from something like $30 billion this year, at over 50% compound annual growth rate, to over $150 billion in 2027,"" Su said.\n\nWhile AMD didn\'t disclose a price, the move could put price pressure on Nvidia\'s GPUs, such as the H100, which can cost $30,000 or more. Lower GPU prices may help drive down the high cost of serving generative AI applications.\n\nAI chips are one of the bright spots in the semiconductor industry, while PC sales, a traditional driver of semiconductor processor sales, slump.\n\nLast month, AMD CEO Lisa Su said on an earnings call that while the MI300X will be available for sampling this fall, it would start shipping in greater volumes next year. Su shared more details on the chip during her presentation on Tuesday.\n\n""I love this chip,"" Su said.', 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ']",,
"['2113a3c7-6535-c732-d98c-787721cb9f55', '3e619c5b-8801-886f-1153-21429e404e1b', '4ebba5df-5943-d59e-0f3d-e716f0014ca8', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc']","['NVDA vs. TSM: Which Chipmaker Stock is Better?', 'After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees', 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', ""How Weak Demand Is Putting A Damper On Taiwan Semi's Outlook — And Those Of Others""]","['Mark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work force and struggled to gain mainstream traction with its ambitious plans for virtual reality.\n\nOn Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, Mr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta’s work in artificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\n\nMr. Zuckerberg’s talk was an attempt to rally staff after the most tumultuous period in his company’s 19-year history. The chief executive said he made “tough decisions” about layoffs with the goal of “building a better technology company” that shipped better products, faster — something he believed Meta wasn’t doing well as it swelled to more than 80,000 employees at the peak of the pandemic.\n\n“I want us to use this period that’s going to be a bit more stable in order to evolve and rebuild our culture,” he said, according to two people who attended the meeting and shared remarks and a recording with The New York Times.', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure', 'Shares of Taiwan Semiconductor Manufacturing (TSM) took a beating Thursday as the world\'s largest contract chipmaker topped analyst estimates for the second quarter but disappointed with its outlook. TSM stock fell more than 5% and dragged other chip players down with it.\n\nX\n\nTaiwan Semiconductor, better known as TSMC, earned $1.14 per U.S. share on sales of $15.68 billion in the June quarter. Analysts polled by FactSet had expected earnings of $1.07 a share on sales of $15.44 billion. However, TSMC earnings fell 25% year over year while sales dropped 12%. In local currency, earnings decreased 23% while sales declined 10%.\n\nTSMC\'s results marked its second straight quarter of declining sales and earnings as its customers navigate a downturn in chip demand.\n\nFor the current quarter, TSMC predicted revenue of $16.7 billion to $17.5 billion. The midpoint of $17.1 billion is below Wall Street\'s target of $17.4 billion. In the year-earlier period, TSMC generated $19.2 billion in sales.\n\nTSM Stock Falls After Report\n\nTaiwan Semiconductor also cut its revenue forecast for the full year to a 10% decline from a mid-single-digit decline.\n\n""This is the third cut to its revenue outlook that TSMC has made this cycle,"" Needham analyst Charles Shi said in a note to clients. Shi had expected TSMC to reduce its 2023 sales outlook to a high-single-digit decline.\n\n""TSMC\'s second-quarter earnings call may go down as one of the more pessimistic calls in recent history,"" Shi said.\n\nOn the stock market today, TSM stock tumbled 5.1% to close at 97.86.\n\nTSMC\'s earnings report pulled down a host of semiconductor stocks. The Philadelphia semiconductor index, known as SOX, sank 3.6% on Thursday. The SOX includes the 30 largest semiconductor stocks traded in the U.S.\n\nAmong major TSMC customers, Advanced Micro Devices (AMD) fell 5.3% and Nvidia (NVDA) retreated 3.3%.\n\nTSM stock is in a flat base with a buy point of 110.69, according to IBD MarketSmith charts.\n\nFactors Behind Soft Demand\n\n""Our second-quarter business was impacted by the overall global economic conditions, which dampened the end-market demand, and led to customers\' ongoing inventory adjustment,"" Chief Financial Officer Wendell Huang said in a news release.\n\nHe added, ""Moving into third quarter 2023, we expect our business to be supported by the strong ramp of our 3-nanomenter technologies, partially offset by customers\' continued inventory adjustment.""\n\nCircuit widths on chips are measured in nanometers, which are one-billionth of a meter.\n\nThe slower-than-expected economic recovery in China also is a factor in TSMC\'s reduced outlook, Evercore ISI analyst C.J. Muse said in a report.\n\nIn addition, the chip inventory correction now is likely to last through the fourth quarter, rather than the third quarter as previously expected, Muse said.\n\nTaiwan Semi Getting AI Boost\n\nTaiwan Semiconductor produces chips for fabless semiconductor firms such as AMD, Apple (AAPL), Broadcom (AVGO), Nvidia and Qualcomm (QCOM).\n\nCyclical headwinds overshadowed strength in AI chip production at TSMC in the second quarter, Needham\'s Shi said.\n\nTSMC management expects chips for artificial intelligence to grow to a low-teens percent of sales by 2028 from 6% today.\n\n""Management still sees Q3 as the end of an inventory correction but believes customers may not build inventory back as fast as previously expected,"" Shi said.\n\nTSM Stock On Tech Leaders List\n\nWedbush Securities analyst Matt Bryson kept his outperform rating on TSM stock despite the company\'s disappointing outlook.\n\n""While we believe this deterioration in outlook wasn\'t unexpected, the magnitude of the downtick was more significant than we had anticipated heading into earnings,"" Bryson said in a note to clients.\n\nTSM stock ranks sixth out of 30 stocks in IBD\'s semiconductor manufacturing industry group, according to IBD Stock Checkup. Taiwan Semiconductor has an IBD Composite Rating of 92 out of 99. IBD\'s Composite Rating is a blend of key fundamental and technical metrics to help investors gauge a stock\'s strengths. The best growth stocks have a Composite Rating of 90 or better.\n\nFurther, TSM stock is on the IBD Tech Leaders list.\n\nFollow Patrick Seitz on Twitter at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nChip Gear Maker ASML Beats Second-Quarter Targets, Guides Higher\n\nNetflix Crushes Subscriber Goal As It Turns Freeloaders Into Paying Customers\n\nApple Stock Rises As India Seen Driving Growth For iPhone Maker\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens']",,
"['7205f821-42ac-3151-d9c5-4063ee4a72bf', 'a6816efd-0b2a-a798-f112-cf2ebc36aeb0', 'b7b86963-f371-4628-52cf-58dc3dc7d28f', 'c778838f-5a8e-29d9-7945-b1804ff1cc42', 'f322f75f-55d7-29ae-4045-d7ba8cd3153b']","['AMD_1A', 'How to Invest in Microsoft Stock (MSFT)', 'New Tools to Support Independent Research', 'AMD vs. Nvidia: How to choose the right graphics card for your PC', 'Meta Fined $1.3 Billion for Violating E.U. Data Privacy Rules']","['Update on February 15, 2024 at 7:00AM PT:\n\nWe want to make more data from our platforms available to academic researchers so they can pursue public interest research, while doing so in a way that respects both people’s privacy and our compliance obligations.\n\nIn the months since we rolled out our Meta Content Library tool we’ve been gathering feedback from researchers to ensure the sort of publicly-accessible data they need is available to them in a way that’s effective for their research. Based on that feedback, we are adding some new data and features.\n\nOne of the biggest requests was to make content from public figures more accessible to researchers so it is easier to study the impact their activity on Facebook and Instagram has on politics, society and culture. So, in the coming weeks, we’re making it possible for researchers to download certain publicly-accessible content posted by public figures and widely-known figures and entities. This data will be accessible in a downloadable CSV format through the Meta Content Library user interface and won’t require access through a virtual clean room.\n\nIn the next few months, we’ll also be adding ‘comments’ as a new data type within the Meta Content Library. This will help researchers study how people around the world receive, discuss and reinterpret content across publicly-accessible pages and posts. We’ll be starting with comments from public forums on Facebook, which researchers will be able to analyze within ICPSR’s virtual clean room.\n\nOur Third Party Fact-Checking partners will also have access to Meta Content Library to help them investigate and debunk misinformation. We hope these powerful search capabilities will help them do this more efficiently, particularly during key moments such as elections.\n\nOriginally published on November 21, 2023 at 3:00AM PT:\n\nTo understand the impact social media apps like Facebook and Instagram have on the world, it’s important to support rigorous, independent research. That’s why Meta has been committed to an open and privacy-protective approach to research for many years, including making tools available to support public interest research, such as the US 2020 studies.\n\nOver the past few months we gave Beta access to our new Meta Content Library and API tools. After multiple rounds of feedback with researchers and other stakeholders, we are now in a position to roll these tools out more broadly.\n\nMeta Content Library & API\n\nOur Meta Content Library and API tools provide access to near real-time public content from Pages, Posts, Groups and Events on Facebook, as well as from creator and business accounts on Instagram. Details about the content, such as the number of reactions, shares, comments and, for the first time, post view counts are also available. Researchers can search, explore and filter that content on both a graphical User Interface (UI) or through a programmatic API.\n\nTogether, these tools provide the most comprehensive access to publicly-available content across Facebook and Instagram of any research tool we have built to date. They also help us meet new regulatory requirements, data-sharing and transparency compliance obligations. Introducing these tools to researchers early in the development process gave us the opportunity to improve them before making them more widely available. We will continue to make improvements as we collect more feedback from researchers.\n\nIndividuals from qualified institutions pursuing scientific or public interest research topics will be able to apply for access to these tools through partners with deep expertise in secure data sharing for research, starting with the University of Michigan’s Inter-university Consortium for Political and Social Research. This is a first-of-its-kind partnership that will enable researchers to analyze data from the API in ICPSR’s Social Media Archive’s (SOMAR) Virtual Data Enclave.\n\nSocial Capital Research\n\nLast year, in collaboration with Raj Chetty and Harvard’s Opportunity Insights Program, we released a landmark study to measure the drivers of economic mobility in the US using information from 21 billion friendships on Facebook, which found that social connections play an important role in helping communities rise out of poverty.\n\nWe’re now expanding this research program with Harvard to better understand the drivers of economic mobility around the world by using insights from our platform on the dynamics of social networks, as well as publicly available data on socioeconomics and schools. We plan to examine cross-class friendships across the United Kingdom in collaboration with experts at the Behavioural Insights Team, Royal Society of Arts, Stripe Partners and Neighbourly Lab.\n\nAs well as expanding to more countries, we also plan to do more research into the role social connections play in economic opportunity including business creation, attending college, and getting a job. Building on our work looking at how social connections benefit people, we will continue to study how social networks help communities recover from crises and help displaced populations and migrants.', 'For example, our Client segment revenue decreased due to a decline in the PC market in the second half of 2022 and the first half of 2023, and our Embedded segment revenue decreased as a result of an inventory correction in several end markets in the second half of 2023. We may build inventories during periods of anticipated growth, and the cancellation or deferral of product orders or overproduction due to failure of anticipated orders to materialize could result in excess or obsolete inventory, which could result in write-downs of inventory and an adverse effect on gross margins. Our customers may also experience a shortage of, or delay in receiving certain components to build their products, which in turn may affect the demand for or the timing of our products. For instance, OEMs have and continue to experience industry-wide challenges securing matched component sets to build their products. Excess or obsolete inventory have resulted in, and may in the future result in, write-downs of the value of our inventory. For example, in the third quarter of 2022, we recorded certain charges primarily for inventory, pricing and related reserves in the Gaming and Client segments. Factors that may result in excess or obsolete inventory, a reduction in the average selling price, or a reduction in our gross margin include: a sudden or significant decrease in demand for our products; a production or design defect in our products; a higher incidence of inventory obsolescence because of rapidly changing technology and customer requirements; a failure to accurately estimate customer demand for our products, including for our older products as our new products are introduced; or our competitors introducing new products or taking aggressive pricing actions. Our ability to design and introduce new products in a timely manner includes the use of third-party intellectual property. In the design and development of new and enhanced products, we rely on third-party intellectual property such as development and testing tools for software and hardware. Furthermore, certain product features may rely on intellectual property acquired from third parties that incorporate into our software or hardware. The design requirements necessary to meet customer demand for more features and greater functionality from semiconductor products may exceed the capabilities of the third-party intellectual property or development or testing tools available to us. If the third-party intellectual property that we use becomes unavailable, is not available with required functionality or performance in the time frame, manufacturing technology, or price point needed for our new products or fails to produce designs that meet customer demands, or laws are adopted that affect our use of third party intellectual property in certain regions or products, our business could be materially adversely affected. We depend on third-party companies for the design, manufacture and supply of motherboards, software, memory and other computer platform components to support our business and products. We depend on third-party companies for the design, manufacture and supply of motherboards, graphics cards, software (e.g., BIOS, operating systems, drivers), memory and other components that we use to design, support and sell, and our customers utilize to support and/or use our product offerings. We also rely on our AIB partners to support our products. In addition, our microprocessors are not designed to function with motherboards and chipsets designed to work with Intel microprocessors. If the designers, manufacturers, AIBs and suppliers of motherboards, graphics cards, software, memory and other components cease or reduce their design, manufacture or production of current or future products that are based on, utilized in, or support our products, or laws are adopted that result in the same, our business could be materially adversely affected. If we lose Microsoft Corporation&#8217;s support for our products or other software vendors do not design and develop software to run on our products, our ability to sell our products could be materially adversely affected. Our ability to innovate beyond the x86 instruction set controlled by Intel depends partially on Microsoft designing and developing its operating systems to run on or support our x86-based microprocessor products. With respect to our graphics products, we depend in part on Microsoft to design and develop its operating system to run on or support our graphics products. Similarly, the success of our products in the market, such as our APU products, is dependent on independent software providers designing and developing software to run on our products. If Microsoft does not continue to design and develop its operating systems so that they work with our x86 instruction sets or does not continue to develop and maintain their operating systems to support our graphics products, independent software providers may forego designing their software applications to take advantage of our innovations and customers may not purchase PCs with our products. In addition, some software drivers licensed for use with our products are certified by Microsoft. If Microsoft did not certify a driver, or if we otherwise fail to retain the support of Microsoft or other software vendors, our ability to market our products would be materially adversely affected. Our reliance on third-party distributors and AIB partners subjects us to certain risks. We market and sell our products directly and through third-party distributors and AIB partners pursuant to agreements that can generally be terminated for convenience by either party upon prior notice. These agreements are non-exclusive and permit both our distributors and AIB partners to offer our competitors&#8217; products. We are dependent on our distributors and AIB partners to supplement our direct marketing and sales efforts. If any significant distributor or AIB partner or a substantial number of our distributors or AIB partners terminated their relationship with us, decided to market our competitors&#8217; products over our products or decided not to market our products at all, our ability to bring our products to market would be impacted and we would be materially adversely affected. We extend credit to certain of our distributors and AIB partners. If we are unable to collect accounts receivable from our significant distributors and/or AIB partners or incur higher allowances for credit losses, it could have a material adverse effect on our business. ', ""When you buy through our links, Business Insider may earn an affiliate commission. Learn more\n\nIn the world of PC gaming, AMD and Nvidia dominate the graphics card market. Whether it's a custom computer or a pre-built model, a graphics card is essential for rendering games in high quality, and cards from either Nvidia or AMD are what you'll find in all of the best gaming PCs and best gaming laptops.\n\nBoth brands offer a range of graphics cards with entry-level models starting at around $270 and high-end cards costing $1,500 or more. AMD and Nvidia also allow other manufacturers to sell third-party versions of their cards based on their original specs. This can create price variations among models with similar capabilities, since third-party manufacturers may add features like extra fans or lighting.\n\nWhile there are lots of graphics cards to choose from, it's still possible to compare each brand's overall performance in relation to their price. Premium Nvidia graphics cards are typically viewed as the most powerful when it comes to advanced features, while the best AMD cards have a reputation for being significantly more affordable and energy efficient.\n\nBelow, we've broken down details on all the latest graphics cards from Nvidia and AMD, and compare how they stack up.\n\nAdvertisement\n\nAMD vs. Nvidia: Price and features\n\nAMD and Nvidia both offer a range of graphics cards for different budgets and performance needs. Nvidia's current lineup is called the GeForce RTX 40 series, while AMD's lineup is called the Radeon RX 7000 series. Here's a rundown of each series.\n\nNote: The cards listed below are for desktop computers. Both brands also make mobile versions of their cards that PC manufacturers can integrate into their gaming laptops, but performance may vary.\n\nAdvertisement\n\nNvidia GeForce RTX 40 series graphics cards\n\nThe Nvidia GeForce RTX 4090 is the company's most powerful graphics card. Nvidia\n\nNvidia's RTX 40 series debuted in fall 2022 with the release of the flagship GeForce RTX 4080 ($1,199) and the premium RTX 4090 ($1,599); four more affordable RTX 40 series cards arrived in 2023.\n\nRTX 40 series cards share a wide range of features, including raytracing, an advanced lighting feature that requires a compatible graphics card, and DLSS 3.0, the latest version of Nvidia's AI-enhanced upscaling technology that makes games easier to run at high frame rates.\n\nOther Nvidia features are designed to benefit content creators; RTX cards include support for AI-based noise removal for your microphone and virtual backgrounds for your webcam, as well as face tracking and auto-focus. However, AMD reports that its graphics cards actually render video faster than the RTX 40 series with common editing programs like Adobe Premiere Pro and DaVinci Resolve Studio.\n\nAdvertisement\n\nAMD Radeon RX 7000 series graphics cards\n\nAn AMD Radeon RX 7000 series card being used with an AMD Ryzen CPU. XFX\n\nAMD launched the Radeon RX 7000 series of graphics cards in December 2022 with the RX 7900 XT ($899) and 7900 XTX ($999), followed by the release of several lower priced cards in 2023, including the 7700XT and 7800XT which are set to launch on September 6.\n\nAMD cards offer similar performance to Nvidia cards in most games, and usually for a lower price. For example, Tom's Hardware ranks the RX 7900 XT ($999) ahead of the RTX 4080 ($1,199) in terms of overall performance, despite the AMD card typically being $200 cheaper. However, Nvidia cards tend to reveal bigger advantages when you play newer games with more advanced graphical features.\n\nLike the RTX 40 series, AMD's RX 7000 cards do feature ray tracing, but ray tracing performance generally lags behind the RTX 40 series with slower frame rates. The RX 7000 series also has an AI-based rendering feature to improve frame rates, called FSR, but it's not quite as developed as Nvidia's DLSS.\n\nIf you're looking to play newer releases like Cyberpunk 2077 or Allen Wake 2, a weaker AMD card may struggle to deliver graphics at the highest possible quality. That said, AMD does partner with some developers to boost performance on AMD hardware; for example, Microsoft's Starfield was designed with support for AMD's FSR at release, but not DLSS.\n\nAMD also supports a feature called Smart Access Memory to improve performance when you pair its latest CPUs and GPUs together. This feature allows the CPU to use more of the graphics card's memory. However, some Nvidia and Intel hardware can take advantage of a similar feature, called Resizable Bar, so the underlying tech isn't AMD exclusive.\n\nAMD benchmark data that shows RX 7000 graphics cards outperforming Nvidia hardware exclusively use AMD processors during testing, so if you have an Intel processor, you may want to look at publicly sourced benchmarks before buying an AMD card.\n\n*The target resolution and refresh rates for each graphics card were determined based on benchmarks shared by Nvidia, AMD, and crowd sourced data from the public. The maximum frame rate and resolution possible with each card will vary based on the game.\n\nAdvertisement\n\nAMD vs. Nvidia: Which graphics card should you choose?\n\nUltimately, choosing between an AMD or Nvidia graphics card comes down to your personal needs, budget, and preferences. Those building their own PC with a smaller budget may prefer the affordability of AMD graphics cards, while those willing to pay more to play brand-new games with graphics that can best the PlayStation 5 or Xbox Series X will likely want an Nvidia 4080 or 4090 card to maximize performance.\n\nOf course, high-end AMD cards like the RX 7900 XT or RX 7900 XTX are still capable of playing the latest releases, but Nvidia's top models have an edge when you enable advanced features like ray tracing.\n\nFAQs\n\nAdvertisement\n\nWhat should you know before buying a graphics card?\n\nBefore you buy any graphics card, you should make sure that it's a good fit for your computer. Using an older CPU or motherboard with a brand-new graphics card can limit your overall performance and create bottlenecks that prevent you from getting the most out of your card.\n\nCheck that your motherboard supports the latest specifications, like PCIe 4.0. Newer graphics cards also demand lots of power, so make sure your power supply has enough juice to keep your computer running.\n\nFinally, always measure the inside of your case to make sure the graphics card will physically fit during installation, as different cases can position the graphics card at different angles. Different manufacturers also make different sized versions of the same graphics card to add extra fans or lighting."", 'Meta on Monday was fined a record 1.2 billion euros ($1.3 billion) and ordered to stop transferring data collected from Facebook users in Europe to the United States, in a major ruling against the social media company for violating European Union data protection rules.\n\nThe penalty, announced by Ireland’s Data Protection Commission, is potentially one of the most consequential in the five years since the European Union enacted the landmark data privacy law known as the General Data Protection Regulation. Regulators said the company failed to comply with a 2020 decision by the European Union’s highest court that Facebook data shipped across the Atlantic was not sufficiently protected from American spy agencies.\n\nBut it remains unclear if or when Meta will ever need to cordon off the data of Facebook users in Europe. Meta said it would appeal the decision, setting up a potentially lengthy legal process.\n\nAt the same time, European Union and American officials are negotiating a new data-sharing pact that would provide legal protections for Meta and scores of other companies to continue moving information between the United States and Europe — a pact that could nullify much of the European Union’s ruling on Monday. A preliminary deal was announced last year.', '3 Most Important Financial Statements\n\nEmotions in Investing: How to Manage Stock Market Anxiety & Stress\n\nFutures Trading: Everything You Need to Know\n\nFor Investors: Business Valuation 101\n\n11 Up-and-Coming Stocks to Invest In\n\nWhen to Sell Stocks — for Profit or Loss\n\nAccounts That Earn Compounding Interest\n\nHow Many Shares Should I Buy of a Stock?\n\nSelling Stock: How Capital Gains Are Taxed\n\nMarket Order vs. Limit Order\n\nHow Are Stock Prices Determined?\n\nWhat Is a Good Return on Investment?\n\nDay Trading Definition: Why It Differs From Investing\n\nThe Definitive Guide: How to Value a Stock\n\nWhat Happens When a Stock Is Delisted?\n\nGAAP vs. Non-GAAP: Everything You Need to Know\n\nShould I Buy Stock Now or Wait?\n\nA Beginner\'s Guide to Understanding Financial News\n\nTechnical Analysis for the Long-Term Investor\n\nHow to Calculate Cost Basis for Inherited Stock\n\nWhat Are Share Repurchases?\n\nHow to Research Stocks\n\nAverage Stock Market Return\n\nHow to Short a Stock\n\nStock vs. Share: What\'s the Difference?\n\nHow to Find Investment Ideas\n\nInvestment Strategies for the Long Term\n\nWhat is the Difference Between Simple & Compound Interest?\n\nWhy Is It Important to Invest in Stocks?\n\nWhat Makes a Stock Price Go Up?\n\nHow to Pick a Stock for the First Time\n\nCan You Owe Money on Stocks?\n\nOptions vs. Stocks: What\'s the Difference?\n\nTaxes on Investments: Understanding the Basics\n\nHow Many Stocks Should You Own?\n\nSocially Responsible Investing\n\nHow to Gift Stock\n\nHow to Invest in Stocks: A Step-by-Step Guide\n\nHow to Calculate Volatility of a Stock\n\nHow to Calculate Total Stock Returns\n\nHow to Calculate Take-Home Pay\n\nTax Loss Harvesting\n\nHow to Invest in Amazon Stock\n\nHow to Invest in Tesla Stock\n\nHow to Buy Nvidia Stock (NVDA)\n\nHow to Invest in Disney Stock\n\nHow to Invest in Google Stock\n\nHow to Invest in Berkshire Hathaway Stock\n\nHow to Invest in Johnson & Johnson Stock\n\nHow to Invest in Exxon Stock\n\nHow to Invest in Facebook Stock\n\nHow to Invest in Stripe\n\nHow to Invest in Apple Stock\n\nHow to Invest in Databricks\n\nHow to Invest in Epic Games\n\nHow to Invest in Ford Stock\n\nHow to Invest in PayPal Stock\n\nHow to Invest in Etsy Stock\n\nHow to Buy Pinterest Stock in 2024\n\nHow to Invest in Block Stock\n\nHow to Invest in OpenAI\n\nHow to Invest in SpaceX in 2024\n\nHow to Invest in Mistral AI in 2024\n\nHow to Invest in C3.ai\n\nHow to Invest in Shopify in 2024\n\nHow to Invest in Costco in 2024\n\nHow to Invest in Netflix in 2024\n\nHow to Invest in Aldi in 2024\n\nHere\'s How to Calculate Future Expected Stock Price\n\nConverting Daily Returns to Annual Returns: Formula, Process, and Example\n\nHow to Calculate Average Stock Price: A Step-By-Step Guide\n\nMillion-Dollar Portfolio: How to Get There\n\nBest Master Limited Partnership Stocks to Buy in 2024\n\nUpcoming Stock Splits to Pay Attention to\n\nApple\'s Stock Split History\n\nCall vs. Put Options\n\nHow to Trade Options\n\nFutures vs. Options: What\'s the Difference?\n\nUnderstanding the Differences Between GAAP and IFRS\n\nHow to Invest in Reddit Stock\n\nHow to Invest in Coca-Cola Stock (NYSE:KO)\n\nHow to Invest in Discord\n\nHow to Invest in Twilio Stock\n\nHow to Invest in Upstart\n\nHow to Invest in Intuitive Surgical\n\nHow to Invest in Carnival Cruise Lines\n\nHow to Invest in Rivian\n\nHow to Invest in SoFi Stock\n\nHow to Invest in Plug\n\nHow to Invest in CRISPR Therapeutics Stock\n\nHow to Invest in Cava\n\nHow to Invest in Nio\n\nHow to Invest in Advanced Micro Devices\n\nHow to Invest in Nu Holdings\n\nHow to Invest in Palantir Technologies Stock\n\nHow to Invest in Coinbase Stock\n\nHow to Invest in AT&T Stock\n\nHow to Invest in Pepsi Stock\n\nHow to Invest in Walmart (NYSE:WMT)\n\nHow to Invest in Palo Alto Networks Stock\n\nHow to Invest in Arm Stock\n\nHow to Invest in Instacart\n\nHow to Invest in Klarna Stock\n\nHow to Invest in The Boring Company\n\nHow to Invest in Rippling Stock Pre-IPO\n\nHow to Invest in Blue Origin\n\nHow to Invest in Upside Foods\n\nHow to Invest in Zipline\n\nNeuralink Stock: How to Invest Before the IPO\n\nInvesting in Ripple Stock\n\nHow to Invest in Canva\n\nHow to Invest in Fanatics Stock\n\nHow to Invest in Revolut\n\nHow to Invest in Chime Stock\n\nHow to Invest in Impossible Foods\n\nHow to Invest in Forge Global\n\nHow to Invest in Tilray Stock\n\nHow to Invest in AMC\n\nHow to Invest in General Electric (GE)\n\nHow to Invest in Northrop Grumman (NOC)\n\nHow to Invest in Boeing\n\nHow to Invest in Kenvue\n\nHow to Invest in Bank of America\n\nHow to Invest in Comcast\n\nHow to Invest in Snap\n\nHow to Invest in QuantumScape\n\nHow to Invest in Lockheed Martin\n\nHow to Invest in Birkenstock\n\nHow to Invest in Snowflake\n\nHow to Invest in Taiwan Semiconductor\n\nYour Guide to Investing: ""Magnificent Seven"" Stocks\n\nHow to Invest in Intel\n\nHow to Invest in IBM\n\nHow to Invest in Liquid Death\n\nHow to Invest in Northvolt\n\nHow to Invest in Flexport in 2024\n\nHow to Invest in Nikola\n\nHow to Invest in Verizon in 2024\n\nHow to Invest in Skims in 2024\n\nHow to Invest in Waystar Technologies\n\nHow to Invest in BMC Software\n\nHow to Invest in Unity Software\n\nHow to Invest in Canopy Growth\n\nSHEIN IPO: Investing in SHEIN\n\nHow to Invest in Panera Bread\n\nHow to Invest in Starlink in 2024\n\nHow to Invest in Publix\n\nHow to Invest in Ikea\n\nHow to Invest in Marvel\n\nHow to Invest in Deloitte\n\nHow to Invest in Cargill\n\nHow to Invest in Lyft\n\nHow to Invest in Uber\n\nHow to Invest in Mars Stock\n\nHow to Invest in H-E-B Grocery\n\nWhat Does Disney Own?\n\nWhat Does Coca-Cola Own?\n\nWhat Does Pepsi Own?\n\nWhat Does Procter & Gamble Own?\n\nWhat Does Altria Own?\n\nBuying Trader Joe\'s Stock: Is It Public?\n\nHow to Invest in the Lego Company\n\nHow to Invest in the NFL\n\nHow to Invest in Hulu Stock\n\nHow to Invest in Arctic Wolf\n\nHow to Invest in Rubrik Pre-IPO\n\nHow to Invest in ServiceTitan Pre-IPO\n\nHow to Invest in Checkout.com Pre-IPO\n\nHow to Invest in Plaid Pre-IPO\n\nHow to Invest in Redwood Materials Stock\n\nWhat Happens to the Ownership of Stocks After a Person Dies?']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '5ebcc885-331d-0a06-2aca-593a9491915f', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'f322f75f-55d7-29ae-4045-d7ba8cd3153b']","['The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)', 'META_7', 'NVDA_7', 'AMD vs. Nvidia: How to choose the right graphics card for your PC', 'The AI Race: Have Microsoft (MSFT) and Nvidia (NVDA) Already Won?']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', ""When you buy through our links, Business Insider may earn an affiliate commission. Learn more\n\nIn the world of PC gaming, AMD and Nvidia dominate the graphics card market. Whether it's a custom computer or a pre-built model, a graphics card is essential for rendering games in high quality, and cards from either Nvidia or AMD are what you'll find in all of the best gaming PCs and best gaming laptops.\n\nBoth brands offer a range of graphics cards with entry-level models starting at around $270 and high-end cards costing $1,500 or more. AMD and Nvidia also allow other manufacturers to sell third-party versions of their cards based on their original specs. This can create price variations among models with similar capabilities, since third-party manufacturers may add features like extra fans or lighting.\n\nWhile there are lots of graphics cards to choose from, it's still possible to compare each brand's overall performance in relation to their price. Premium Nvidia graphics cards are typically viewed as the most powerful when it comes to advanced features, while the best AMD cards have a reputation for being significantly more affordable and energy efficient.\n\nBelow, we've broken down details on all the latest graphics cards from Nvidia and AMD, and compare how they stack up.\n\nAdvertisement\n\nAMD vs. Nvidia: Price and features\n\nAMD and Nvidia both offer a range of graphics cards for different budgets and performance needs. Nvidia's current lineup is called the GeForce RTX 40 series, while AMD's lineup is called the Radeon RX 7000 series. Here's a rundown of each series.\n\nNote: The cards listed below are for desktop computers. Both brands also make mobile versions of their cards that PC manufacturers can integrate into their gaming laptops, but performance may vary.\n\nAdvertisement\n\nNvidia GeForce RTX 40 series graphics cards\n\nThe Nvidia GeForce RTX 4090 is the company's most powerful graphics card. Nvidia\n\nNvidia's RTX 40 series debuted in fall 2022 with the release of the flagship GeForce RTX 4080 ($1,199) and the premium RTX 4090 ($1,599); four more affordable RTX 40 series cards arrived in 2023.\n\nRTX 40 series cards share a wide range of features, including raytracing, an advanced lighting feature that requires a compatible graphics card, and DLSS 3.0, the latest version of Nvidia's AI-enhanced upscaling technology that makes games easier to run at high frame rates.\n\nOther Nvidia features are designed to benefit content creators; RTX cards include support for AI-based noise removal for your microphone and virtual backgrounds for your webcam, as well as face tracking and auto-focus. However, AMD reports that its graphics cards actually render video faster than the RTX 40 series with common editing programs like Adobe Premiere Pro and DaVinci Resolve Studio.\n\nAdvertisement\n\nAMD Radeon RX 7000 series graphics cards\n\nAn AMD Radeon RX 7000 series card being used with an AMD Ryzen CPU. XFX\n\nAMD launched the Radeon RX 7000 series of graphics cards in December 2022 with the RX 7900 XT ($899) and 7900 XTX ($999), followed by the release of several lower priced cards in 2023, including the 7700XT and 7800XT which are set to launch on September 6.\n\nAMD cards offer similar performance to Nvidia cards in most games, and usually for a lower price. For example, Tom's Hardware ranks the RX 7900 XT ($999) ahead of the RTX 4080 ($1,199) in terms of overall performance, despite the AMD card typically being $200 cheaper. However, Nvidia cards tend to reveal bigger advantages when you play newer games with more advanced graphical features.\n\nLike the RTX 40 series, AMD's RX 7000 cards do feature ray tracing, but ray tracing performance generally lags behind the RTX 40 series with slower frame rates. The RX 7000 series also has an AI-based rendering feature to improve frame rates, called FSR, but it's not quite as developed as Nvidia's DLSS.\n\nIf you're looking to play newer releases like Cyberpunk 2077 or Allen Wake 2, a weaker AMD card may struggle to deliver graphics at the highest possible quality. That said, AMD does partner with some developers to boost performance on AMD hardware; for example, Microsoft's Starfield was designed with support for AMD's FSR at release, but not DLSS.\n\nAMD also supports a feature called Smart Access Memory to improve performance when you pair its latest CPUs and GPUs together. This feature allows the CPU to use more of the graphics card's memory. However, some Nvidia and Intel hardware can take advantage of a similar feature, called Resizable Bar, so the underlying tech isn't AMD exclusive.\n\nAMD benchmark data that shows RX 7000 graphics cards outperforming Nvidia hardware exclusively use AMD processors during testing, so if you have an Intel processor, you may want to look at publicly sourced benchmarks before buying an AMD card.\n\n*The target resolution and refresh rates for each graphics card were determined based on benchmarks shared by Nvidia, AMD, and crowd sourced data from the public. The maximum frame rate and resolution possible with each card will vary based on the game.\n\nAdvertisement\n\nAMD vs. Nvidia: Which graphics card should you choose?\n\nUltimately, choosing between an AMD or Nvidia graphics card comes down to your personal needs, budget, and preferences. Those building their own PC with a smaller budget may prefer the affordability of AMD graphics cards, while those willing to pay more to play brand-new games with graphics that can best the PlayStation 5 or Xbox Series X will likely want an Nvidia 4080 or 4090 card to maximize performance.\n\nOf course, high-end AMD cards like the RX 7900 XT or RX 7900 XTX are still capable of playing the latest releases, but Nvidia's top models have an edge when you enable advanced features like ray tracing.\n\nFAQs\n\nAdvertisement\n\nWhat should you know before buying a graphics card?\n\nBefore you buy any graphics card, you should make sure that it's a good fit for your computer. Using an older CPU or motherboard with a brand-new graphics card can limit your overall performance and create bottlenecks that prevent you from getting the most out of your card.\n\nCheck that your motherboard supports the latest specifications, like PCIe 4.0. Newer graphics cards also demand lots of power, so make sure your power supply has enough juice to keep your computer running.\n\nFinally, always measure the inside of your case to make sure the graphics card will physically fit during installation, as different cases can position the graphics card at different angles. Different manufacturers also make different sized versions of the same graphics card to add extra fans or lighting."", 'Without question the market has developed a seemingly insatiable appetite for artificial intelligence (AI) technology and the companies that can lead this new frontier. Seen as the promising future, AI allows computers to learn and solve problems like humans by using (among other things) an advanced form of computer processing which includes machine learning and neural networks.\n\nGiven these immense capabilities, investor interest in AI stocks, namely Microsoft (MSFT) and Nvidia (NVDA), have skyrocketed over the past few months as the race to control the technology forges ahead. The money-making potential is immense. The generative AI market is currently growing at 42% and could hit $1.3 trillion by 2032, according to Bloomberg Intelligence estimates. The bulk of the revenue growth from generative AI, estimated $247 billion by 2032, will come from demand for the infrastructure needed to train AI models.\n\n“The release of consumer-focused artificial intelligence tools such as ChatGPT and Google’s Bard is set to fuel a decade-long boom,” noted Bloomberg. What\'s more, estimates suggests that the AI-assisted digital ads business could reach $192 billion in annual revenue by 2032, while revenue from AI servers could hit $134 billion. But just like other market trendy buzzwords that have captivated the investor community, not every company that puts out an “AI press release,” staking a claim of their piece of the pie, will thrive.\n\nBut if judging solely by their growth forecasts and stocks prices, there are two clear leaders at the moment: Microsoft and Nvidia. Microsoft’s AI advances became known with ChatGPT by way if its $10 billion investment in Open AI, giving Microsoft 33% ownership of the company. Many analysts referred to Microsoft’s AI bet as an ""iPhone moment.” Since then, ChatGPT has become the fastest-growing technology in history, hitting 2 billion users after only six months. Estimates suggests it can reach 3.4 billion global users by the end of 2023.\n\nMicrosoft’s AI advances with its AI integration is being regarded as the best among the cloud giants - a group that includes Amazon (AMZN) and Google-parent Alphabet (GOOG , GOOGL). Estimates are calling for Microsoft ’s AI growth prospects to get a 33% boost. The challenge for investors in terms of valuation of Microsoft stock, what’s does that AI growth prospect equate to? Currently trading near all-time highs of $342, MSFT stock has risen 43% year to date, besting the 14% rise in the S&P 500 index.\n\nMicrosoft stock is more than 20% overvalued, according to several valuation metrics, including P/E which puts its fair value closer to $265. And that’s even when factoring three years worth of growth. The biggest risk in my book would be to assume that any of these conventional valuation metrics matter today. Microsoft’s AI-driven growth could push the stock towards $550 in the next five years, yielding 60% return or 12% annually.\n\nNvidia, which has soared 198% this year, skyrocketed close to 30% after its blowout first quarter earnings results and better-than-expected Q2 guidance. The stock gained $184 billion in one day, vaulting the stock north of a trillion-dollar valuation. Nvidia’s Q2 guidance and its proclaimed leading position as an AI chip supplier got investors excited, guiding for Q2 revenue of $11 billion, crushing estimates for revenue of $8.5 billion.\n\nNvidia CEO Jensen Huang has declared that generative AI represents an “iPhone moment.” Investors have since recognized the importance of Nvidia’s GPU data center accelerators which can potentially serve as the backbone for generative AI infrastructure. On the Q1 conference call with analysts, Nvidia’s CFO Colette Kress affirmed that belief that data centers will inevitably switch to Nvidia’s products incorporating AI. “Generative AI is driving exponential growth in compute requirements and a fast transition to NVIDIA accelerated computing,” Kress said.\n\nMeanwhile, CEO Huang, in a press release, issued the sort of outlook that suggests Nvidia’s leadership in Generative AI is all but assured. “A trillion dollars of installed global data infrastructure will transition…to accelerated computing as companies race to apply AI to every product, service, and business process,” wrote Huang. The demand for Nvidia’s GPUs based on its Hopper and Ampere architecture was noticeable in its just-announced results.\n\nNvidia continues to enjoy not only tons of AI tailwinds, but also the company’s fundamentals continues to improve evidenced by its margin improvement. As such, despite the stock reaching all-time high levels, the best play here is to stay invested and add on any dips. NVDA stock is poised to reach $500 by the end of the year.\n\nAll told, this new AI frontier is getting crowded. It remains to be seen which companies ascend and which ones falter. But while AI has tons of room for growth, Microsoft and Nvidia have planted their flags and staked their leadership in this new frontier.\n\nThe views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.']",,
"['3e619c5b-8801-886f-1153-21429e404e1b', '702bac1f-ccd2-bd8d-8a98-b590e08fb070', 'b78da971-cede-623b-d604-234e42dda7f8', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'c64e4be0-0a6b-a621-a919-864efa4ae279']","['NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', 'NVDA vs. TSM: Which Chipmaker Stock is Better?', 'META_7']","['Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Beginning in the fourth quarter of 2023, our Family metrics no longer include Messenger Kids users. Worldwide DAP increased 8% to 3.19 billion on average during December 2023 from 2.96 billion during December 2022. Table of Contents &#8226; Monthly Active People (MAP). We define a monthly active person as a registered and logged-in user of one or more Family products who visited at least one of these Family products through a mobile device application or using a web or mobile browser in the last 30 days as of the date of measurement. We do not require people to use a common identifier or link their accounts to use multiple products in our Family, and therefore must seek to attribute multiple user accounts within and across products to individual people. Our calculations of MAP rely upon complex techniques, algorithms, and machine learning models that seek to estimate the underlying number of unique people using one or more of these products, including by matching user accounts within an individual product and across multiple products when we believe they are attributable to a single person, and counting such group of accounts as one person. As these techniques and models require significant judgment, are developed based on internal reviews of limited samples of user accounts, and are calibrated against user survey data, there is necessarily some margin of error in our estimates. We view MAP as a measure of the size of our global active community of people using our products. For additional information, see the section entitled ""Limitations of Key Metrics and Other Data"" in this Annual Report on Form 10-K. Note: We report the numbers of DAP and MAP as specific amounts, but these numbers are estimates of the numbers of unique people using our products and are subject to statistical variances and errors. While we expect the error margin for these estimates to vary from period to period, we estimate that such margin generally will be approximately 3% of our worldwide MAP. At our scale, it is very difficult to attribute multiple user accounts within and across products to individual people, and it is possible that the actual numbers of unique people using our products may vary significantly from our estimates, potentially beyond our estimated error margins. For additional information, see the section entitled ""Limitations of Key Metrics and Other Data"" in this Annual Report on Form 10-K. In the third quarter of 2022, we updated our Family metrics calculations to maintain calibration of our models against recent user survey data, and we estimate such update contributed an aggregate of approximately 40 million MAP to our reported worldwide MAP in September 2022. Beginning in the fourth quarter of 2023, our Family metrics no longer include Messenger Kids users. As of December 31, 2023, we had 3.98 billion MAP, an increase of 6% from 3.74 billion as of December 31, 2022. Table of Contents &#8226; Average Revenue Per Person (ARPP). We define ARPP as our total revenue during a given quarter, divided by the average of the number of MAP at the beginning and end of the quarter. While ARPP includes all sources of revenue, the number of MAP used in this calculation only includes users of our Family products as described in the definition of MAP above. We estimate that the share of revenue from users who are not also MAP was not material. ##TABLE_START ARPP: $9.39 $7.72 $7.91 $7.53 $8.63 $7.59 $8.32 $8.71 $10.10 Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Beginning with our Quarterly Report on Form 10-Q to be filed for the first quarter of 2024, we intend to report ARPP based on DAP instead of MAP. Our annual worldwide ARPP in 2023, which represents the sum of quarterly ARPP during such period, was $34.72, an increase of 9% from 2022. Table of Contents Trends in Our Facebook User Metrics The numbers for our key Facebook metrics, our DAUs, MAUs, and average revenue per user (ARPU), do not include users on Instagram, WhatsApp, or our other products, unless they would otherwise qualify as DAUs or MAUs, respectively, based on their other activities on Facebook. Trends in the number of users affect our revenue and financial results by influencing the number of ads we are able to show, the value of our ads to marketers, as well as our expenses and capital expenditures. Substantially all of our daily and monthly active users (as defined below) access Facebook on mobile devices. &#8226; Daily Active Users (DAUs). We define a daily active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), on a given day. We view DAUs, and DAUs as a percentage of MAUs, as measures of user engagement on Facebook. ---- DAU/MAU: -- 66% ------ 67% ------ 67% ------ 67% ------ 67% ------ 68% ------ 68% ----- 68% ------ 69% - - - DAU/MAU: -- 74% ----- 75% ------ 75% ------ 74% ------ 75% ----- 74% ------ 75% ------ 75% ------ 75% ---- DAU/MAU: - 72% ------ 73% ------ 74% ----- 74% ------ 75% ------ 75% ------ 75% ------ 75% ------ 75% --- - - DAU/MAU: -- 63% ----- 64% ------ 64% ------ 64% ------ 65% ----- 66% ------ 66% ------ 66% ------ 67% ---- DAU/MAU: - 65% ------ 66% ------ 66% ----- 66% ------ 66% ------ 67% ------ 66% ------ 67% ------ 67% --- Note: For purposes of reporting DAUs, MAUs, and ARPU by geographic region, Europe includes all users in Russia and Turkey and Rest of World includes all users in Africa, Latin America, and the Middle East. Table of Contents Worldwide DAUs increased 6% to 2.11 billion on aver age during December 2023 from 2.00 billion during December 2022 . ', 'Item 7. Management\'s Discussion and Analysis of Financial Condition and Results of Operations The following discussion and analysis of our financial condition and results of operations should be read in conjunction with &#8220;Item 1A. Risk Factors&#8221;, our Consolidated Financial Statements and related Notes thereto, as well as other cautionary statements and risks described elsewhere in this Annual Report on Form 10-K, before deciding to purchase, hold or sell shares of our common stock. Overview Our Company and Our Businesses NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields. NVIDIA has leveraged its GPU architecture to create platforms for accelerated computing, AI solutions, scientific computing, data science, AV, robotics, metaverse and 3D internet applications. Our two operating segments are ""Compute &#38; Networking"" and ""Graphics."" Refer to Note 17 of the Notes to the Consolidated Financial Statements in Part IV, Item 15 of this Annual Report on Form 10-K for additional information. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Recent Developments, Future Objectives and Challenges Demand and Supply, Product Transitions, and New Products and Business Models Demand for our data center systems and products surged in fiscal year 2024. Entering fiscal year 2025, we are gathering customer demand indications across several product transitions. We have demand visibility for our new data center products ramping later in fiscal year 2025. We have increased our supply and capacity purchases with existing suppliers, added new vendors and entered into prepaid manufacturing and capacity agreements. These increased purchase volumes, the number of suppliers, and the integration of new vendors into our supply chain may create more complexity and execution risk. Our purchase commitments and obligations for inventory and manufacturing capacity at the end of fiscal year 2024 were impacted by shortening lead times for certain components. We may continue to enter into new supplier and capacity arrangements. Supply of Hopper architecture products is improving, and demand remains very strong. We expect our next-generation products to be supply-constrained based upon demand indications. We may incur inventory provisions or impairments if our inventory or supply or capacity commitments exceed demand for our products or demand declines. We build finished products and maintain inventory in advance of anticipated demand. While we have entered into long-term supply and capacity commitments, we may not be able to secure sufficient commitments for capacity to address our business needs, or our long-term demand expectations may change. These risks may increase as we shorten our product development cycles, enter new lines of business, or integrate new suppliers or components into our supply chain, creating additional supply chain complexity. Product transitions are complex as we often ship both new and prior architecture products simultaneously and we and our channel partners prepare to ship and support new products. Due to our product introduction cycles, we are almost always in various stages of transitioning the architecture of our Data Center, Professional Visualization, and Gaming products. We will have a broader and faster Data Center product launch cadence to meet a growing and diverse set of AI opportunities. The increased frequency of these transitions may magnify the challenges associated with managing our supply and demand due to manufacturing lead times. Qualification time for new products, customers anticipating product transitions and channel partners reducing channel inventory of prior architectures ahead of new product introductions can create reductions or volatility in our revenue. The increasing frequency and complexity of newly introduced products could result in quality or production issues that could increase inventory provisions, warranty or other costs or result in product delays. Deployment of new products to customers creates additional challenges due to the complexity of our technologies, which has impacted and may in the future impact the timing of customer purchases or otherwise impact our demand. While we have managed prior product transitions and have previously sold multiple product architectures at the same time, these transitions are difficult, may impair our ability to predict demand and impact our supply mix, and we may incur additional costs. We build technology and introduce products for new and innovative use cases and applications such as our NVIDIA DGX Cloud services, Omniverse platform, LLMs, and generative AI models. Our demand estimates for new use cases, applications, and services can be incorrect and create volatility in our revenue or supply levels, and we may not be able to generate significant revenue from these use cases, applications, and services. Recent technologies, such as generative AI models, have emerged, and while they have driven increased demand for Data Center, the long-term trajectory is unknown. Global Trade During the third quarter of fiscal year 2023, the USG, announced licensing requirements that, with certain exceptions, impact exports to China (including Hong Kong and Macau) and Russia of our A100 and H100 integrated circuits, DGX or any other systems or boards which incorporate A100 or H100 integrated circuits. In July 2023, the USG informed us of an additional licensing requirement for a subset of A100 and H100 products destined to certain customers and other regions, including some countries in the Middle East. In October 2023, the USG announced new and updated licensing requirements that became effective in our fourth quarter of fiscal year 2024 for exports to China and Country Groups D1, D4, and D5 (including but not limited to Saudi Arabia, the United Arab Emirates, and Vietnam, but excluding Israel) of our products exceeding certain performance thresholds, including A100, A800, H100, H800, L4, L40, L40S and RTX 4090. The licensing requirements also apply to the export of products exceeding certain performance thresholds to a party headquartered in, or with an ultimate parent headquartered in, Country Group D5, including China. On October 23, 2023, the USG informed us the licensing requirements were effective immediately for shipments of our A100, A800, H100, H800, and L40S products. Our sales to China decreased as a percentage of total Data Center revenue from 19% in fiscal year 2023 to 14% in fiscal year 2024. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Taiwan Semiconductor (NYSE:TSM), using TipRanks’ comparison tool to determine which is better. Both have skyrocketed this year, although NVIDIA is outperforming most, if not all, other stocks on U.S. exchanges, gaining 180% year-to-date. Meanwhile, Taiwan Semiconductor is up a mere 38% year-to-date.\n\nWith such massive gains, a closer look is needed to determine whether there could be any more upside left. For comparison, the U.S. semiconductor industry is trading at a price-to-earnings (P/E) multiple of 40.6 versus its three-year average of 27.1. The industry is trading at a price-to-sales (P/S) ratio of 6.7 versus the three-year average of 5.6.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of 208.5 and a P/S of 38.3, NVIDIA initially looks massively overvalued versus its industry. However, the chipmaker’s five-year mean P/E is about 66.7, while its five-year mean P/S is about 17.7, showing that it typically trades far above its industry. Nonetheless, it seems clear from the headlines about NVIDIA that it’s in a bubble, suggesting a bearish view might be appropriate for now.\n\nThis year’s massive rally in NVIDIA shares has made the company into the next $1 trillion company, joining the few blockbuster Big Tech names like Apple and Microsoft in the over-$1 trillion-market-capitalization club. However, that rally also suggests NVIDIA could be a bubble stock, and if there’s one thing all investors know about asset bubbles, it’s that they pop — eventually.\n\nNVIDIA skyrocketed nearly 30% just in the last five days to hit a new record high of about $419 after reporting a 21% year-over-year increase in net income for the first quarter. Management also used a key phrase in their earnings commentary that helped drive that massive rally: “generative AI.”\n\nThe hype over artificial intelligence this year — likely stemming from the release of ChatGPT — has boosted the shares of virtually every company that has anything to do with AI. In his earnings commentary, NVIDIA CEO Jensen Huang predicted that $1 trillion worth of installed global data infrastructure “will transition from general-purpose to accelerated computing as companies race to apply generative AI into every product, service, and business process.”\n\nNotably, NVIDIA’s data-center revenue surged to a record $4.28 billion in the first quarter. While the chipmaker is and will continue to be a winner in the AI race, euphoria doesn’t last forever, and the shares have flattened out after their initial earnings-related surge.\n\nIn fact, insiders have unloaded almost $8 million worth of NVIDIA shares over the last three months, and the rally over the last five days suggests more sales could be reported soon.\n\nIs Nvidia a Buy, Sell, or Hold?\n\nNVIDIA has a Strong Buy consensus rating based on 33 Buys, four Holds, and zero Sell ratings assigned over the last three months. At $441.84, the average NVIDIA stock price target implies an upside potential of 15.47%.\n\nTaiwan Semiconductor (NYSE:TSM)\n\nAt a P/E of 15.5 and a P/S of 6.4, Taiwan Semiconductor trades at a discount to its industry P/E and in line with its industry P/S. Thus, it looks much more reasonably valued than NVIDIA, especially considering its five-year mean P/S of eight. However, a neutral view might be appropriate in the near term due to the geopolitical overhang for Taiwanese stocks.\n\nTaiwan Semiconductor Manufacturing has enjoyed a nice 11% lift over the last five days due to NVIDIA’s good news, enjoying their best week in almost a year. TSM is likely to see some sales increase from the AI transition because it manufactures NVIDIA’s chips, but any impact is likely to be modest.\n\nUnfortunately, the company could face issues amid the growing tensions between Taiwan and China, which convinced Warren Buffett to dump most of his $4.1 billion stake after less than a year. Given Buffett’s long-term focus, it’s highly unusual that he would sell the position after holding it for such a short time.\n\nThus, while Taiwan Semiconductor could end up being an excellent long-term investment at current prices, the recent rally paired with the geopolitical tensions suggests a neutral view for now.\n\nIs Taiwan Semiconductor a Buy, Sell, or Hold?\n\nTaiwan Semiconductor has a Strong Buy consensus rating based on four Buys, zero Holds, and zero Sells assigned over the last three months. At $118.67, the average Taiwan Semiconductor stock price target implies upside potential of 19.93%.\n\nConclusion: Bearish on NVDA, Neutral on TSM\n\nNVIDIA and TSM clearly have excellent long-term prospects, given their AI exposure. However, it seems like buying NVIDIA shares at current prices could be playing with fire, given its bubble-like aspects that could bring a better entry price.\n\nTSM’s valuation is more attractive and could be a good play on AI, but the geopolitical overhang adds significant risk to owning the shares.\n\nDisclosure']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '25c2084b-d2c7-2c1d-2bdf-5ac4b97e8d7e', 'bf715864-7c6d-03f2-2587-13ce20a99fcc', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","[""TSM and Jersey Mike's cook up multi-year esports partnership"", 'NVDA_7', 'Chipmaker TSMC Gets Sales Lift From AI, Apple iPhones', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'TSM, the premier championship esports organization, and Jersey Mike’s, known for its fresh sliced/fresh grilled subs, have set a three-year, North American partnership, making Jersey Mike\'s the official Sub Sandwich of TSM.\n\nWhile the key ingredients of branding and content production are baked in to the partnership, this made-to-order deal brings TSM and Jersey Mike\'s fans alike loads of meaty offerings, including:\n\n● A freshly-made fan sweepstakes offering the chance to win epic prizes\n\n● The tasty “Subs for Subs” initiative where Jersey Mike\'s will gift thousands of subscriptions and free subs to up-and-coming Twitch streamers to grow their audiences and support their dreams of becoming full time content creators.\n\n● A custom crafted Jersey Mike\'s Blitz Arena on TSM\'s esports coaching app Blitz\n\nAnd in keeping with both organizations’ desires to give back to their community, this collaboration also funds a unique, first-of-its-kind internship program. Students from TSM partner campuses, Jersey Mike\'s university partners and HBCUs will have the opportunity for hands-on experience in the gaming business including working at an esports-focused event.\n\n“This partnership stands for everything our fans crave- and it will leave them hungry for more!” said TSM CRO Stephan Cieplik. “Jersey Mike\'s commitment to quality and excellence aligns with our own values at TSM, and we look forward to bringing this partnership to life with authentic activations to engage with our fans, gamers and streamers.”\n\n“TSM is a leader in the esports industry and we are honored to partner with them,"" said Rich Hope, Chief Marketing Officer, Jersey Mike’s Franchise Systems, Inc. “We are excited to bring our delicious subs to the TSM community and support the next generation of esports stars through our internship program.”\n\nAbout TSM\n\nTSM is an elite, holistic gaming brand composed of championship esports teams, world-class influencers, and gaming strategy platforms that level up the casual player all the way to the professional. A platform of champions, TSM seeks to provide maximum value through the competitive excellence of its teams and the creation of exciting, educational, and entertaining content that deliver the ultimate esports and gaming fan experience. For more: tsm.gg.\n\nAbout Jersey Mike’s Subs\n\nJersey Mike’s Subs, with nearly 2,500 locations nationwide, serves authentic fresh sliced/fresh grilled subs on in-store freshly baked bread — the same recipe it started with in 1956. Passion for giving in Jersey Mike’s local communities is reflected in its mission statement “Giving…making a difference in someone’s life.” For more information, please visit jerseymikes.com or follow us on Facebook, Instagram, and Twitter.', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Taiwan Semiconductor Manufacturing (TSM), better known as TSMC, reported better-than-expected sales for October, thanks to demand for chips for artificial intelligence and Apple\'s (AAPL) iPhone 15. TSM stock jumped on the news Friday.\n\nX\n\nOn the stock market today, TSM stock surged 6.4% higher to close at 97.44. Other semiconductor stocks followed suit.\n\nEarly Friday, TSMC released its monthly sales data, which showed a 34.8% increase in revenue in October from September. On a year-over-year basis, TSMC\'s October sales rose 15.7%.\n\nThe October report sets a positive tone for the company\'s fourth quarter, Wedbush Securities analyst Matt Bryson said in a client note. Bryson reiterated his outperform rating on TSM stock after the sales report.\n\n""We expect a strong Q4 from TSMC,"" he said. ""In particular, we expect that Apple seasonality and continued growth in demand for AI solutions will boost TSMC into year end, with some potential benefit from recently better handset dynamics.""\n\nTSM Stock Lifts Semiconductor Stocks\n\nTaiwan Semiconductor is the world\'s largest contract chipmaker. It makes chips for top fabless chip firms such as Apple, AMD (AMD), Nvidia (NVDA), Qualcomm (QCOM) and many more.\n\n""Looking beyond this quarter, we continue to expect an eventual recovery in macro conditions/end markets that will be boosted by technology trends requiring an increase in semiconductor content, driving future demand growth and returning utilization rates to more optimal levels,"" Bryson said.\n\nThose tech trends include AI, Internet of Things, electric vehicles, self-driving automobiles, augmented reality and virtual reality, he said.\n\nTSM stock is one of 30 semiconductor stocks on the Philadelphia semiconductor index, known as SOX. In afternoon trading on Friday, the SOX rose 4%.\n\nFollow Patrick Seitz on X, formerly Twitter, at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nNvidia Stock Hits Buy Point On New AI Chips For Chinese Market\n\nChip Designer Arm Disappoints With Soft Outlook After Earnings Beat\n\nChipmaker GlobalFoundries Beats Earnings Goal On In-Line Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens']",,
"['25c2084b-d2c7-2c1d-2bdf-5ac4b97e8d7e', '8196a9d0-bc8d-89ac-473c-eab41a572a25', '911edbf3-396c-c1f4-e97f-18c212dee4c4', 'abcc1e96-6637-b573-e425-a668f873dfa6', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['An Update on Facebook News in Europe', 'META_1A', 'NVDA_7', ""TSM and Jersey Mike's cook up multi-year esports partnership"", 'NVDA_1']","['The software and hardware on which we rely has contained, and will in the future contain, errors, bugs, or vulnerabilities, and our systems are subject to certain technical limitations that may compromise our ability to meet our objectives. Some errors, bugs, or vulnerabilities inherently may be difficult to detect and may only be discovered after the code has been released for external or internal use. For example, in September 2018, we announced our discovery of a third-party cyber-attack that exploited a vulnerability in Facebook\'s code to steal user access tokens and access certain profile information from user accounts on Facebook. Errors, bugs, vulnerabilities, design defects, or technical limitations within the software and hardware on which we rely, or human error in using such systems, have led to, and may in the future lead to, outcomes including a negative experience or other adverse effects for users and marketers who use our products, compromised ability of our products to perform in a manner consistent with our terms, contracts, or policies, delayed product introductions or enhancements, targeting, measurement, or billing errors, compromised ability to protect the data of our users and/or our intellectual property or other data, or reductions in our ability to provide some or all of our services. For example, we make commitments to our users as to how their data will be collected, used, shared, and retained within and across our products, and our systems are subject to errors, bugs and technical limitations that may prevent us from fulfilling these commitments reliably. In addition, any errors, bugs, vulnerabilities, or defects in our systems or the software and hardware on which we rely, failures to properly address or mitigate the technical limitations in our systems, or associated degradations or interruptions of service or failures to fulfill our commitments to our users, have led to, and may in the future lead to, outcomes including damage to our reputation, loss of users, loss of marketers, loss of revenue, regulatory inquiries, litigation, or liability for fines, damages, or other remedies, any of which could adversely affect our business and financial results. If we are unable to protect our intellectual property, the value of our brands and other intangible assets may be diminished, and our business may be adversely affected. We rely and expect to continue to rely on a combination of confidentiality, assignment, and license agreements with our employees, consultants, and third parties with whom we have relationships, as well as trademark, copyright, patent, trade secret, and domain name protection laws, to protect our proprietary rights. In the United States and internationally, we have filed various applications for protection of certain aspects of our intellectual property, and we currently hold a significant number of registered trademarks and issued patents in multiple jurisdictions and have acquired patents and patent applications from third parties. Third parties may knowingly or unknowingly infringe our proprietary rights, third parties may challenge proprietary rights held by us, and pending and future trademark and patent applications may not be approved. In addition, effective intellectual property protection may not be available in every country in which we operate or intend to operate our business. In any or all of these cases, we may be required to expend significant time and expense in order to prevent infringement or to enforce our rights. Although we have generally taken measures to protect our proprietary rights, there can be no assurance that others will not offer products or concepts that are substantially similar to ours and compete with our business. In addition, we regularly contribute software source code under open source and other permissive licenses and have made other technology we developed available under such licenses, and we include open source software in our products. Additionally, our AI is trained on data sets that may include open source software and the outputs of our AI may be subject to open source license restrictions or obligations. As a result of our open source contributions and the use of open source in our products, we may license or be required to license or disclose code and/or innovations that turn out to be material to our business and may also be exposed to increased litigation risk. If the protection of our proprietary rights is inadequate to prevent unauthorized use or appropriation by third parties, the value of our brands and other intangible assets may be diminished and competitors may be able to more effectively mimic our products, services, and methods of operations. Any of these events could have an adverse effect on our business and financial results. Table of Contents We are currently, and expect to be in the future, party to patent, trademark, and copyright lawsuits and other intellectual property rights claims that are expensive and time consuming and, if resolved adversely, could have a significant impact on our business, financial condition, or results of operations. Companies in the internet, technology, and media industries own large numbers of patents, copyrights, trademarks, and trade secrets, and frequently enter into litigation based on allegations of infringement, misappropriation, or other violations of intellectual property or other rights. In addition, various ""non-practicing entities"" that own patents and other intellectual property rights often attempt to aggressively assert their rights in order to extract value from technology companies. Furthermore, from time to time we may introduce or acquire new products, including in areas where we historically have not competed, or introduce new features for existing products, which could increase our exposure to intellectual property claims from competitors, non-practicing entities, and other rights holders. From time to time, we receive notice from patent, copyright, and trademark holders and other parties alleging that certain of our products and services, trademarks, or user content, infringe their intellectual property rights. We presently are involved in a number of intellectual property lawsuits, and as we face increasing competition and develop new products and services, we expect the number of intellectual property claims against us to grow. Defending intellectual property litigation is often costly and can impose a significant burden on management and employees, and there can be no assurances that favorable final outcomes will be obtained in all cases. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Today, we are announcing that in the UK, France and Germany we will deprecate Facebook News – a dedicated tab on Facebook in the bookmarks section that spotlights news – in early December.\n\nThis is part of an ongoing effort to better align our investments to our products and services people value the most. As a company, we have to focus our time and resources on things people tell us they want to see more of on the platform, including short form video. We know that people don’t come to Facebook for news and political content – they come to connect with people and discover new opportunities, passions and interests. News makes up less than 3% of what people around the world see in their Facebook feed, so news discovery is a small part of the Facebook experience for the vast majority of people.\n\nThe changes affecting the Facebook News feature will not otherwise impact Meta’s products and services in these countries. People will still be able to view links to news articles on Facebook. European news publishers will continue to have access to their Facebook accounts and Pages, where they can post links to their stories and direct people to their websites in the way any other individual or organization can. News organizations can also still leverage products like Reels and our ads system to reach broader audiences and drive people to their website, where they keep 100% of the revenue derived from outbound links on Facebook.\n\nWhile we’ll be deprecating Facebook News in these countries, we will honour our obligations under all existing Facebook News deals with publishers in the UK, France and Germany until they expire. However, to ensure that we continue to invest in those products and services that drive user engagement, we will not enter into new commercial deals for news content on Facebook News in these countries and do not expect to offer new Facebook products specifically for news publishers in the future.\n\nOur Commitment to Connecting People to Reliable Information\n\nThis does not impact our commitment to connecting people to reliable information on our platforms. We work with independent third-party fact-checkers – certified through the non-partisan International Fact-Checking Network – who review and rate viral misinformation on our apps. We have built the largest global fact-checking network of any platform by partnering with more than 90 independent fact-checking organisations around the world who review content in more than 60 languages. We have contributed more than $100 million to programs supporting our fact-checking efforts since 2016 to combat the spread of misinformation and we will continue to invest in this area.', 'TSM, the premier championship esports organization, and Jersey Mike’s, known for its fresh sliced/fresh grilled subs, have set a three-year, North American partnership, making Jersey Mike\'s the official Sub Sandwich of TSM.\n\nWhile the key ingredients of branding and content production are baked in to the partnership, this made-to-order deal brings TSM and Jersey Mike\'s fans alike loads of meaty offerings, including:\n\n● A freshly-made fan sweepstakes offering the chance to win epic prizes\n\n● The tasty “Subs for Subs” initiative where Jersey Mike\'s will gift thousands of subscriptions and free subs to up-and-coming Twitch streamers to grow their audiences and support their dreams of becoming full time content creators.\n\n● A custom crafted Jersey Mike\'s Blitz Arena on TSM\'s esports coaching app Blitz\n\nAnd in keeping with both organizations’ desires to give back to their community, this collaboration also funds a unique, first-of-its-kind internship program. Students from TSM partner campuses, Jersey Mike\'s university partners and HBCUs will have the opportunity for hands-on experience in the gaming business including working at an esports-focused event.\n\n“This partnership stands for everything our fans crave- and it will leave them hungry for more!” said TSM CRO Stephan Cieplik. “Jersey Mike\'s commitment to quality and excellence aligns with our own values at TSM, and we look forward to bringing this partnership to life with authentic activations to engage with our fans, gamers and streamers.”\n\n“TSM is a leader in the esports industry and we are honored to partner with them,"" said Rich Hope, Chief Marketing Officer, Jersey Mike’s Franchise Systems, Inc. “We are excited to bring our delicious subs to the TSM community and support the next generation of esports stars through our internship program.”\n\nAbout TSM\n\nTSM is an elite, holistic gaming brand composed of championship esports teams, world-class influencers, and gaming strategy platforms that level up the casual player all the way to the professional. A platform of champions, TSM seeks to provide maximum value through the competitive excellence of its teams and the creation of exciting, educational, and entertaining content that deliver the ultimate esports and gaming fan experience. For more: tsm.gg.\n\nAbout Jersey Mike’s Subs\n\nJersey Mike’s Subs, with nearly 2,500 locations nationwide, serves authentic fresh sliced/fresh grilled subs on in-store freshly baked bread — the same recipe it started with in 1956. Passion for giving in Jersey Mike’s local communities is reflected in its mission statement “Giving…making a difference in someone’s life.” For more information, please visit jerseymikes.com or follow us on Facebook, Instagram, and Twitter.', ""We offer tuition reimbursement programs to subsidize educational programs and advanced certifications. We implemented a career coaching service to provide one-on-one guidance to employees, and encourage internal job mobility. We have implemented specifically designed mentoring and development programs for women and employees from traditionally underrepresented groups to ensure widespread readiness for future advancement. To evaluate employee sentiment and engagement, we use pulse surveys, a suggestion box, and an anonymous third-party platform. Pulse surveys help us gain insight into employee experience and provides employee-generated ideas so that we can take targeted action. The suggestion box is an always-on, interactive tool where employees share their thoughts about making our company a better place to work. The anonymous third-party platform is designed to protect the identity of the reporter and provide a mechanism for reporters to follow an investigation and receive responses. We want NVIDIA to be a place where people can build their careers over their lifetime. Our employees tend to come and stay. In fiscal year 2024, our overall turnover rate was 2.7%. Compensation, Benefits, and Well-Being Our compensation program rewards performance and is structured to encourage employees to invest in the Company&#8217;s future. Employees receive equity, except where unavailable due to local regulations, that is tied to the value of our stock price and vests over time to retain employees while simultaneously aligning their interests with those of our shareholders. We offer comprehensive benefits to support our employees&#8217; and their families&#8217; physical health, well-being, and financial health. Programs include 401(k) programs in the U.S., statutory and supplemental pension programs outside the U.S., our employee stock purchase program, flexible work hours, and time off policies to address mental health, stress, and time-management challenges. We evaluate our benefit offerings globally and aim to provide comparable support across the regions where we operate. We are committed to providing tailored benefits based on the needs of our Community Resource Groups and continuing our support for parents, both new birth parents and those who wish to become parents. Our support is enhanced during times of crisis, such as war or economic volatility, to take care of our existing team of world-class talent and their families. Diversity, Inclusion, and Belonging We believe that diverse teams fuel innovation, and we are committed to creating an inclusive culture that supports all employees. When recruiting for new talent or developing our current employees, we strive to build a diverse talent pipeline that includes those underrepresented in the technology field, including women, Black/African American, and Hispanic/Latino candidates. To this end, we have been: &#8226; Partnering with institutions and professional organizations serving historically underrepresented communities; &#8226; Embedding dedicated recruiting teams to business areas to shepherd underrepresented candidates through the interview process and find internal opportunities; &#8226; Supporting the development of women employees through programs aimed at building a pipeline of future leaders; &#8226; Providing peer support and executive sponsors for our internal community resource groups; &#8226; Providing training and education to managers and peers on fostering supportive environments and recruiting for diversity; &#8226; Track equity and parity in retention, promotions, pay, and employee engagement scores; and &#8226; Measuring year over year progress and providing leadership visibility on diversity efforts. As of the end of fiscal year 2024, our global workforce was 79% male, 20% female, and 1% not declared, with 6% of our workforce in the United States composed of Black or African American and Hispanic or Latino employees. Flexible Working Environment We support a flexible work environment, understanding that many employees want the ability to work from home under certain conditions. This flexibility supports diverse hiring, retention, and employee engagement, which we believe makes NVIDIA a great place to work. During fiscal year 2025, we will continue to have a flexible work environment and maintain our company wide 2-days off a quarter for employees to rest and recharge. Information About Our Executive Officers The following sets forth certain information regarding our executive officers, their ages, and positions as of February 16, 2024: ##TABLE_START Name Age Position Jen-Hsun Huang 60 President and Chief Executive Officer Colette M. Kress 56 Executive Vice President and Chief Financial Officer Ajay K. Puri 69 Executive Vice President, Worldwide Field Operations Debora Shoquist 69 Executive Vice President, Operations Timothy S. Teter 57 Executive Vice President and General Counsel ##TABLE_END Jen-Hsun Huang co-founded NVIDIA in 1993 and has served as our President, Chief Executive Officer, and a member of the Board of Directors since our inception. From 1985 to 1993, Mr. Huang was employed at LSI Logic Corporation, a computer chip manufacturer, where he held a variety of positions including as Director of Coreware, the business unit responsible for LSI's SOC. From 1983 to 1985, Mr. Huang was a microprocessor designer for AMD, a semiconductor company. Mr. Huang holds a B.S.E.E. degree from Oregon State University and an M.S.E.E. degree from Stanford University. Colette M. Kress joined NVIDIA in 2013 as Executive Vice President and Chief Financial Officer. Prior to NVIDIA, Ms. Kress most recently served as Senior Vice President and Chief Financial Officer of the Business Technology and Operations Finance organization at Cisco Systems, Inc., a networking equipment company, since 2010. At Cisco, Ms. Kress was responsible for financial strategy, planning, reporting and business development for all business segments, engineering and operations. From 1997 to 2010 Ms. Kress held a variety of positions at Microsoft, a software company, including, beginning in 2006, Chief Financial Officer of the Server and Tools division, where Ms. Kress was responsible for financial strategy, planning, reporting and business development for the division. Prior to joining Microsoft, Ms. Kress spent eight years at Texas Instruments Incorporated, a semiconductor company, where she held a variety of finance positions. Ms. Kress holds a B.S. degree in Finance from University of Arizona and an M.B.A. degree from Southern Methodist University. Ajay K. Puri joined NVIDIA in 2005 as Senior Vice President, Worldwide Sales and became Executive Vice President, Worldwide Field Operations in 2009. Prior to NVIDIA, he held positions in sales, marketing, and general management over a 22-year career at Sun Microsystems, Inc., a computing systems company. ""]",,
"['0f064687-3f51-7c2c-9ad1-d77b09f66b36', '2113a3c7-6535-c732-d98c-787721cb9f55', '591c2bb5-1433-43c4-3c95-43e8b4164fba', 'fcdd9328-a897-86da-97cc-2dbb3b0c5e44', 'ffe46ef0-5a92-9ff9-8fb1-c56744912b45']","['After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees', 'NVDA vs. AMD: Which Chip Stock is the Better Buy?', 'MSFT_1', 'MSFT_8']","['Mark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work force and struggled to gain mainstream traction with its ambitious plans for virtual reality.\n\nOn Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, Mr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta’s work in artificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\n\nMr. Zuckerberg’s talk was an attempt to rally staff after the most tumultuous period in his company’s 19-year history. The chief executive said he made “tough decisions” about layoffs with the goal of “building a better technology company” that shipped better products, faster — something he believed Meta wasn’t doing well as it swelled to more than 80,000 employees at the peak of the pandemic.\n\n“I want us to use this period that’s going to be a bit more stable in order to evolve and rebuild our culture,” he said, according to two people who attended the meeting and shared remarks and a recording with The New York Times.', 'Customers may purchase perpetual licenses or subscribe to licenses, which provide customers with the same functionality and differ mainly in the duration over which the customer benefits from the software. Revenue from distinct on-premises licenses is recognized upfront at the point in time when the software is made available to the customer. In cases where we allocate revenue to software updates, primarily because the updates are provided at no additional charge, revenue is recognized as the updates are provided, which is generally ratably over the estimated life of the related device or license. Certain volume licensing programs, including Enterprise Agreements, include on-premises licenses combined with Software Assurance (&#8220;SA&#8221;). SA conveys rights to new software and upgrades released over the contract period and provides support, tools, and training to help customers deploy and use products more efficiently. On-premises licenses are considered distinct performance obligations when sold with SA. Revenue allocated to SA is generally recognized ratably over the contract period as customers simultaneously consume and receive benefits, given that SA comprises distinct performance obligations that are satisfied over time. Cloud services, which allow customers to use hosted software over the contract period without taking possession of the software, are provided on either a subscription or consumption basis. Revenue related to cloud services provided on a subscription basis is recognized ratably over the contract period. Revenue related to cloud services provided on a consumption basis, such as the amount of storage used in a period, is recognized based on the customer utilization of such resources. When cloud services require a significant level of integration and interdependency with software and the individual components are not considered distinct, all revenue is recognized over the period in which the cloud services are provided. Revenue from search advertising is recognized when the advertisement appears in the search results or when the action necessary to earn the revenue has been completed. Revenue from consulting services is recognized as services are provided. Our hardware is generally highly dependent on, and interrelated with, the underlying operating system and cannot function without the operating system. In these cases, the hardware and software license are accounted for as a single performance obligation and revenue is recognized at the point in time when ownership is transferred to resellers or directly to end customers through retail stores and online marketplaces. Refer to Note 19 &#8211; Segment Information and Geographic Data for further information, including revenue by significant product and service offering. Significant Judgments Our contracts with customers often include promises to transfer multiple products and services to a customer. Determining whether products and services are considered distinct performance obligations that should be accounted for separately versus together may require significant judgment. When a cloud-based service includes both on-premises software licenses and cloud services, judgment is required to determine whether the software license is considered distinct and accounted for separately, or not distinct and accounted for together with the cloud service and recognized over time. Certain cloud services, primarily Office 365, depend on a significant level of integration, interdependency, and interrelation between the desktop applications and cloud services, and are accounted for together as one performance obligation. Revenue from Office 365 is recognized ratably over the period in which the cloud services are provided. PART II Item 8 &#160; Judgment is required to determine the SSP for each distinct performance obligation. We use a single amount to estimate SSP for items that are not sold separately, including on-premises licenses sold with SA or software updates provided at no additional charge. We use a range of amounts to estimate SSP when we sell each of the products and services separately and need to determine whether there is a discount to be allocated based on the relative SSP of the various products and services. In instances where SSP is not directly observable, such as when we do not sell the product or service separately, we determine the SSP using information that may include market conditions and other observable inputs. We typically have more than one SSP for individual products and services due to the stratification of those products and services by customers and circumstances. In these instances, we may use information such as the size of the customer and geographic region in determining the SSP. Due to the various benefits from and the nature of our SA program, judgment is required to assess the pattern of delivery, including the exercise pattern of certain benefits across our portfolio of customers. Our products are generally sold with a right of return, we may provide other credits or incentives, and in certain instances we estimate customer usage of our products and services, which are accounted for as variable consideration when determining the amount of revenue to recognize. Returns and credits are estimated at contract inception and updated at the end of each reporting period if additional information becomes available. Changes to our estimated variable consideration were not material for the periods presented. Contract Balances and Other Receivables Timing of revenue recognition may differ from the timing of invoicing to customers. We record a receivable when revenue is recognized prior to invoicing, or unearned revenue when revenue is recognized subsequent to invoicing. For multi-year agreements, we generally invoice customers annually at the beginning of each annual coverage period. We record a receivable related to revenue recognized for multi-year on-premises licenses as we have an unconditional right to invoice and receive payment in the future related to those licenses. Unearned revenue comprises mainly unearned revenue related to volume licensing programs, which may include SA and cloud services. Unearned revenue is generally invoiced annually at the beginning of each contract period for multi-year agreements and recognized ratably over the coverage period. Unearned revenue also includes payments for consulting services to be performed in the future, LinkedIn subscriptions, Office 365 subscriptions, Xbox subscriptions, Windows post-delivery support, Dynamics business solutions, and other offerings for which we have been paid in advance and earn the revenue when we transfer control of the product or service. ', 'Our Search and news advertising business competes with Google and a wide array of websites, social platforms like Meta, and portals that provide content and online offerings to end users. OPERATIONS We have regional operations service centers that support our operations, including customer contract and order processing, billing, credit and collections, information processing, and vendor management and logistics. The center in Ireland supports the African, Asia-Pacific, European, and Middle East regions; and the centers in Arlington, Virginia, Atlanta, Georgia, Charlotte, North Carolina, Fargo, North Dakota, Fort Lauderdale, Florida, Redmond, Washington, Reno, Nevada, and Puerto Rico support the American regions. In addition to our operations centers, we also operate datacenters throughout each of these regions. We continue to identify and evaluate opportunities to expand our datacenter locations and increase our server capacity to meet the evolving needs of our customers, particularly given the growing demand for AI services. Our datacenters depend on the availability of permitted and buildable land, predictable energy, networking supplies, and servers, including graphics processing units (&#8220;GPUs&#8221;) and other components. Our devices are primarily manufactured by third-party contract manufacturers. For the majority of our products, we have the ability to use other manufacturers if a current vendor becomes unavailable or unable to meet our requirements. However, some of our products contain certain components for which there are very few qualified suppliers. Extended disruptions at these suppliers could impact our ability to manufacture devices on time to meet consumer demand. PART I Item 1 &#160; RESEARCH AND DEVELOPMENT Product and Service Development, and Intellectual Property We develop most of our products and services internally through the following engineering groups. &#8226; Cloud and AI &#8211; focuses on making IT professionals, developers, partners, independent software vendors, and their systems more productive and efficient through development of Azure AI platform and cloud infrastructure, server, database, CRM, ERP, software development tools and services (including GitHub), AI cognitive services, and other business process applications and services for enterprises. &#8226; Strategic Missions and Technologies &#8211; focuses on incubating technical products and support solutions with transformative potential for the future of cloud computing and continued company growth across quantum computing, Azure Space &#38; Missions Engineering, telecommunications, and Microsoft Federal Sales and Delivery. &#8226; Experiences and Devices &#8211; focuses on delivering high value end-user experiences across our products, services, and devices, including Microsoft 365, Windows, Microsoft Teams, Search (including Microsoft Edge and Bing Chat) and other advertising-based services, and the Surface line of devices. &#8226; Microsoft Security &#8211; focuses on delivering a comprehensive portfolio of services that protect our customers&#8217; digital infrastructure through cloud platform and application security, data protection and governance, identity and network access, and device management. &#8226; Technology and Research &#8211; focuses on fundamental research, product and business incubations, and forward-looking AI innovations that span infrastructure, services, and applications. &#8226; LinkedIn &#8211; focuses on our services that transform the way professionals grow their network and find jobs and the way businesses hire, market, sell, and learn. &#8226; Gaming &#8211; focuses on developing hardware, content, and services across a large range of platforms to help grow our user base through game experiences and social interaction. Internal development allows us to maintain competitive advantages that come from product differentiation and closer technical control over our products and services. It also gives us the freedom to decide which modifications and enhancements are most important and when they should be implemented. We strive to obtain information as early as possible about changing usage patterns and hardware advances that may affect software and hardware design. Before releasing new software platforms, and as we make significant modifications to existing platforms, we provide application vendors with a range of resources and guidelines for development, training, and testing. Generally, we also create product documentation internally. We protect our intellectual property investments in a variety of ways. We work actively in the U.S. and internationally to ensure the enforcement of copyright, trademark, trade secret, and other protections that apply to our software and hardware products, services, business plans, and branding. We are a leader among technology companies in pursuing patents and currently have a portfolio of over 70,000 U.S. and international patents issued and over 19,000 pending worldwide. While we employ much of our internally-developed intellectual property in our products and services, we also engage in outbound licensing of specific patented technologies that are incorporated into licensees&#8217; products. From time to time, we enter into broader cross-license agreements with other technology companies covering entire groups of patents. We may also purchase or license technology that we incorporate into our products and services. At times, we make select intellectual property broadly available at no or low cost to achieve a strategic objective, such as promoting industry standards, advancing interoperability, supporting societal and/or environmental efforts, or attracting and enabling our external development community. Our increasing engagement with open source software will also cause us to license our intellectual property rights broadly in certain situations. While it may be necessary in the future to seek or renew licenses relating to various aspects of our products and services, we believe, based upon past experience and industry practice, such licenses generally can be obtained on commercially reasonable terms. We believe our continuing research and product development are not materially dependent on any single license or other agreement with a third party relating to the development of our products. PART I Item 1 &#160; Investing in the Future Our success is based on our ability to create new and compelling products, services, and experiences for our users, to initiate and embrace disruptive technology trends, to enter new geographic and product markets, and to drive broad adoption of our products and services. We invest in a range of emerging technology trends and breakthroughs that we believe offer significant opportunities to deliver value to our customers and growth for the company. Based on our assessment of key technology trends, we maintain our long-term commitment to research and development across a wide spectrum of technologies, tools, and platforms spanning digital work and life experiences, cloud computing, AI, devices, and operating systems. ', 'In this piece, I evaluated two chipmaker stocks, NVIDIA (NASDAQ:NVDA) and Advanced Micro Devices (NASDAQ:AMD), using TipRanks’ comparison tool to determine which is better. A deeper analysis suggests a bullish view for NVIDIA and a bearish view for AMD.\n\nNVIDIA develops graphics processing units (GPUs) semiconductors for artificial intelligence (AI), gaming, creative design, robotics, and autonomous vehicles. Meanwhile, AMD designs processors and related technologies for AI, data centers, gaming, and business-computing applications.\n\nShares of NVDA are up 240% year-to-date. Meanwhile, AMD stock has gained 93% year-to-date, including a 20% return over the last three months.\n\nDespite NVIDIA’s much higher gains this year, it’s trading at a much lower valuation than AMD. We’ll look at their price-to-earnings (P/E) ratios to gauge their valuations against each other and that of their industry. For comparison, the U.S. semiconductor industry is currently trading at a P/E of 46.4 versus its three-year average P/E of 29.9.\n\nNVIDIA (NASDAQ:NVDA)\n\nAt a P/E of around 64.3, NVIDIA is trading at a relatively small premium to its industry (compared to AMD’s premium anyway). In fact, the stock hasn’t been this cheap in a year, and its long-term gains also suggest a bullish view might be appropriate despite the tremendous year-to-date gain.\n\nOn a P/E basis, NVIDIA hasn’t been this cheap since December 2022. In fact, NVIDIA was trading at a P/E of over 100 just days ago — before the last earnings report. Of course, significantly higher earnings send a company’s P/E much lower if its stock price doesn’t change dramatically.\n\nIn NVIDIA’s case, its earnings exploded so much higher year-over-year that its P/E was cut nearly in half after just a small pullback from around $500 a share on November 22 to $489 on November 24. For its third quarter, the company reported adjusted earnings of $4.02 per share on $18.1 billion in revenue versus the consensus estimates of $3.37 per share on $16.2 billion in revenue.\n\nStory continues\n\nOn a comparative basis, NVIDIA’s revenue jumped 206% year-over-year and 34% quarter-over-quarter, while its adjusted earnings rose nearly sevenfold year-over-year and 49% quarter-over-quarter. The chipmaker’s GAAP (generally accepted accounting principles) earnings rose more than 13 times from a year ago to $3.71 per share, also demonstrating exploding growth.\n\nBefore that earnings report, NVIDIA shares had soared to a record high of around $505 with a P/E of about 120 in November. Normally, I wouldn’t suggest a bullish view of a stock that has risen so much, so fast.\n\nHowever, once the market recognizes its lower valuation — and recovers from management’s warning about significantly lower sales to China and other countries due to export restrictions — NVIDIA shares will likely continue their tear. Despite that warning, the chipmaker still guided for almost 231% revenue growth to $20 billion in the fourth quarter, so it clearly isn’t all that worried.\n\nEven if the stock doesn’t recover dramatically in the near term, NVIDIA’s long-term stock-price gains of 267% over the last three years, 1,184% over the last five, and 13,066% over the last 10 provide some level of safety over the long term. In fact, I would use any near-term pullbacks to add to the position.\n\nWhat is the Price Target for NVDA Stock?\n\nNVIDIA has a Strong Buy consensus rating based on 30 Buys, three Holds, and zero Sell ratings assigned over the last three months. At $660.39, the average NVIDIA stock price target implies upside potential of 36.7%.\n\nAdvanced Micro Devices (NASDAQ:AMD)\n\nAt a P/E of 1,120, Advanced Micro Devices has the opposite problem of NVIDIA. Its valuation has skyrocketed because it’s now barely profitable. However, the chipmaker certainly isn’t going anywhere anytime soon, so it’s only a matter of time before it bounces back. For now, though, a bearish view seems appropriate, pending a better entry price or improved earnings numbers.\n\nIn the third quarter, AMD reported $299 million in GAAP net income, although that was an improvement from net income of $66 million a year ago. On an adjusted basis, the company’s net income rose 4% year-over-year to $1.1 billion. AMD also reported revenue of $5.8 billion for the quarter, up from $5.6 billion a year ago.\n\nUnfortunately, AMD continues to play catch-up to NVIDIA in the area of artificial intelligence, although management did reveal some progress on its last earnings call, announcing improvements in the company’s AI software capabilities through R&D and acquisitions. Management also expects the MI300 data center chip, which will support AI models, to be “the fastest product to ramp to $1 billion in sales in AMD history.” In short, AMD will likely catch up to NVIDIA at some point, but we’re not there yet.\n\nWhat is the Price Target for AMD Stock?\n\nAdvanced Micro Devices has a Strong Buy consensus rating based on 22 Buys, seven Holds, and zero Sell ratings assigned over the last three months. At $126.79, the average AMD stock price target implies upside potential of 2.9%.\n\nConclusion: Bullish on NVDA, Bearish on AMD\n\nThe battle between NVIDIA and Advanced Micro Devices has been going on for years, with one company pulling out in front of the other and then the other catching up and trading places. Nonetheless, neither of these companies is going anywhere anytime soon.\n\nHowever, AMD could be playing catch-up to NVIDIA on AI for some time, calling for a wait-and-see approach. Meanwhile, NVIDIA will likely rerate higher once the market digests management’s warning about the new export restrictions.\n\nDisclosure', '&#8226; Enterprise Services, including Enterprise Support Services, Industry Solutions (formerly Microsoft Consulting Services), and Nuance professional services. More Personal Computing Our More Personal Computing segment consists of products and services that put customers at the center of the experience with our technology. This segment primarily comprises: &#8226; Windows, including Windows OEM licensing and other non-volume licensing of the Windows operating system; Windows Commercial, comprising volume licensing of the Windows operating system, Windows cloud services, and other Windows commercial offerings; patent licensing; and Windows Internet of Things. &#8226; Devices, including Surface, HoloLens, and PC accessories. PART II Item 8 &#160; &#8226; Gaming, including Xbox hardware and Xbox content and services, comprising first- and third-party content (including games and in-game content), Xbox Game Pass and other subscriptions, Xbox Cloud Gaming, advertising, third-party disc royalties, and other cloud services. &#8226; Search and news advertising, comprising Bing (including Bing Chat), Microsoft News, Microsoft Edge, and third-party affiliates. Revenue and costs are generally directly attributed to our segments. However, due to the integrated structure of our business, certain revenue recognized and costs incurred by one segment may benefit other segments. Revenue from certain contracts is allocated among the segments based on the relative value of the underlying products and services, which can include allocation based on actual prices charged, prices when sold separately, or estimated costs plus a profit margin. Cost of revenue is allocated in certain cases based on a relative revenue methodology. Operating expenses that are allocated primarily include those relating to marketing of products and services from which multiple segments benefit and are generally allocated based on relative gross margin. In addition, certain costs are incurred at a corporate level and allocated to our segments. These allocated costs generally include legal, including settlements and fines, information technology, human resources, finance, excise taxes, field selling, shared facilities services, customer service and support , and severance incurred as part of a corporate program. Each allocation is measured differently based on the specific facts and circumstances of the costs being allocated and is generally based on relative gross margin or relative headcount. Segment revenue and operating income were as follows during the periods presented: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Year Ended June 30, &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Revenue &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes &#160; $ 69,274 &#160; &#160; $ 63,364 &#160; &#160; $ 53,915 &#160; Intelligent Cloud &#160; &#160; 87,907 &#160; &#160; &#160; 74,965 &#160; &#160; &#160; 59,728 &#160; More Personal Computing &#160; &#160; 54,734 &#160; &#160; &#160; 59,941 &#160; &#160; &#160; 54,445 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total &#160; $ 211,915 &#160; &#160; $ 198,270 &#160; &#160; $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Operating Income &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Productivity and Business Processes $ 34,189 &#160; $ 29,690 &#160; $ 24,351 &#160; Intelligent Cloud &#160; 37,884 33,203 &#160; 26,471 More Personal Computing &#160; 16,450 &#160; &#160; 20,490 &#160; &#160; 19,094 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 88,523 &#160; $ 83,383 &#160; $ 69,916 &#160; &#160; &#160; &#160; ##TABLE_END &#160; No sales to an individual customer or country other than the United States accounted for more than 10% of revenue for fiscal years 2023, 2022, or 2021. Revenue, classified by the major geographic areas in which our customers were located, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; United States (a) $ 106,744 $ 100,218 $ 83,953 Other countries 105,171 98,052 84,135 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; ##TABLE_END &#160; (a) Includes billings to OEMs and certain multinational organizations because of the nature of these businesses and the impracticability of determining the geographic source of the revenue. PART II Item 8 &#160; Revenue, classified by significant product and service offerings, was as follows: &#160; ##TABLE_START (In millions) &#160; &#160; &#160; &#160; &#160; Year Ended June 30, 2022 &#160; &#160; &#160; Server products and cloud services &#160; $ 79,970 $ 67,350 $ 52,589 Office products and cloud services 48,728 &#160; 44,862 39,872 Windows 21,507 24,732 22,488 Gaming 15,466 &#160; 16,230 &#160; 15,370 LinkedIn &#160; 15,145 &#160; &#160; 13,816 &#160; 10,289 Search and news advertising 12,208 &#160; 11,591 &#160; 9,267 Enterprise Services &#160; &#160; 7,722 &#160; &#160; &#160; 7,407 &#160; &#160; &#160; 6,943 &#160; Devices &#160; &#160; 5,521 &#160; &#160; &#160; 7,306 &#160; &#160; &#160; 7,143 &#160; Dynamics 5,437 4,687 3,754 Other &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; Total $ 211,915 $ 198,270 $ 168,088 &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; ##TABLE_END &#160; Our Microsoft Cloud revenue, which includes Azure and other cloud services, Office 365 Commercial, the commercial portion of LinkedIn, Dynamics 365, and other commercial cloud properties, was $ 111.6 billion, $ 91.4 billion, and $ 69.1 billion in fiscal years 2023, 2022, and 2021, respectively. These amounts are primarily included in Server products and cloud services, Office products and cloud services, LinkedIn, and Dynamics in the table above. Assets are not allocated to segments for internal reporting presentations. A portion of amortization and depreciation is included with various other costs in an overhead allocation to each segment. ']",,
"['31672b01-0394-5fad-097a-48e88fb4aac1', '7977861a-6481-9ffd-9f83-c5ca05060390', '960ff408-d29b-e155-298c-15dbc123661a', 'abcc1e96-6637-b573-e425-a668f873dfa6']","['AI Chipmaker Nvidia Smashes Quarterly Estimates On Strong Data-Center Sales', 'Giving Teens and Parents More Ways to Manage Their Time on Our Apps', 'META_1A', 'You Can Now Have Multiple Personal Profiles on Facebook']","['The software and hardware on which we rely has contained, and will in the future contain, errors, bugs, or vulnerabilities, and our systems are subject to certain technical limitations that may compromise our ability to meet our objectives. Some errors, bugs, or vulnerabilities inherently may be difficult to detect and may only be discovered after the code has been released for external or internal use. For example, in September 2018, we announced our discovery of a third-party cyber-attack that exploited a vulnerability in Facebook\'s code to steal user access tokens and access certain profile information from user accounts on Facebook. Errors, bugs, vulnerabilities, design defects, or technical limitations within the software and hardware on which we rely, or human error in using such systems, have led to, and may in the future lead to, outcomes including a negative experience or other adverse effects for users and marketers who use our products, compromised ability of our products to perform in a manner consistent with our terms, contracts, or policies, delayed product introductions or enhancements, targeting, measurement, or billing errors, compromised ability to protect the data of our users and/or our intellectual property or other data, or reductions in our ability to provide some or all of our services. For example, we make commitments to our users as to how their data will be collected, used, shared, and retained within and across our products, and our systems are subject to errors, bugs and technical limitations that may prevent us from fulfilling these commitments reliably. In addition, any errors, bugs, vulnerabilities, or defects in our systems or the software and hardware on which we rely, failures to properly address or mitigate the technical limitations in our systems, or associated degradations or interruptions of service or failures to fulfill our commitments to our users, have led to, and may in the future lead to, outcomes including damage to our reputation, loss of users, loss of marketers, loss of revenue, regulatory inquiries, litigation, or liability for fines, damages, or other remedies, any of which could adversely affect our business and financial results. If we are unable to protect our intellectual property, the value of our brands and other intangible assets may be diminished, and our business may be adversely affected. We rely and expect to continue to rely on a combination of confidentiality, assignment, and license agreements with our employees, consultants, and third parties with whom we have relationships, as well as trademark, copyright, patent, trade secret, and domain name protection laws, to protect our proprietary rights. In the United States and internationally, we have filed various applications for protection of certain aspects of our intellectual property, and we currently hold a significant number of registered trademarks and issued patents in multiple jurisdictions and have acquired patents and patent applications from third parties. Third parties may knowingly or unknowingly infringe our proprietary rights, third parties may challenge proprietary rights held by us, and pending and future trademark and patent applications may not be approved. In addition, effective intellectual property protection may not be available in every country in which we operate or intend to operate our business. In any or all of these cases, we may be required to expend significant time and expense in order to prevent infringement or to enforce our rights. Although we have generally taken measures to protect our proprietary rights, there can be no assurance that others will not offer products or concepts that are substantially similar to ours and compete with our business. In addition, we regularly contribute software source code under open source and other permissive licenses and have made other technology we developed available under such licenses, and we include open source software in our products. Additionally, our AI is trained on data sets that may include open source software and the outputs of our AI may be subject to open source license restrictions or obligations. As a result of our open source contributions and the use of open source in our products, we may license or be required to license or disclose code and/or innovations that turn out to be material to our business and may also be exposed to increased litigation risk. If the protection of our proprietary rights is inadequate to prevent unauthorized use or appropriation by third parties, the value of our brands and other intangible assets may be diminished and competitors may be able to more effectively mimic our products, services, and methods of operations. Any of these events could have an adverse effect on our business and financial results. Table of Contents We are currently, and expect to be in the future, party to patent, trademark, and copyright lawsuits and other intellectual property rights claims that are expensive and time consuming and, if resolved adversely, could have a significant impact on our business, financial condition, or results of operations. Companies in the internet, technology, and media industries own large numbers of patents, copyrights, trademarks, and trade secrets, and frequently enter into litigation based on allegations of infringement, misappropriation, or other violations of intellectual property or other rights. In addition, various ""non-practicing entities"" that own patents and other intellectual property rights often attempt to aggressively assert their rights in order to extract value from technology companies. Furthermore, from time to time we may introduce or acquire new products, including in areas where we historically have not competed, or introduce new features for existing products, which could increase our exposure to intellectual property claims from competitors, non-practicing entities, and other rights holders. From time to time, we receive notice from patent, copyright, and trademark holders and other parties alleging that certain of our products and services, trademarks, or user content, infringe their intellectual property rights. We presently are involved in a number of intellectual property lawsuits, and as we face increasing competition and develop new products and services, we expect the number of intellectual property claims against us to grow. Defending intellectual property litigation is often costly and can impose a significant burden on management and employees, and there can be no assurances that favorable final outcomes will be obtained in all cases. ', 'Update on January 18, 2024 at 3:00AM PT:\n\nSleep is important, particularly for young people, so we’re launching new nighttime nudges that will show up when teens have spent more than 10 minutes on Instagram in places like Reels or Direct Messages late at night. They’ll remind teens that it’s late, and encourage them to close the app.\n\nUpdate on November 9, 2023 at 9:00AM PT:\n\nParental supervision tools are now available globally on Facebook, in addition to Instagram, Messenger, and Horizon Worlds. Parents can access Facebook supervision via Settings to see insights like time spent, schedule breaks for their teens and access expert resources on managing their teens’ time online. We’re also adding more supervision features to Messenger, including giving parents the ability to set scheduled breaks and view their teens’ blocked contacts.\n\nUpdate on August 30, 2023 at 9:00PM PT:\n\nParental supervision tools on Messenger are now available globally.\n\nOriginally published on June 27, 2023 at 2:00AM PT:\n\nParental Supervision Tools on Messenger\n\nToday, we’re announcing parental supervision tools on Messenger. Now parents and guardians can access Messenger supervision tools and resources from leading experts to support their teens through the Meta Family Center. Parental Supervision on Messenger is available in the US, UK, and Canada today, with plans to expand to more countries around the world in the coming months.\n\nThese tools allow parents to see how their teen uses Messenger, from how much time they’re spending on messaging to providing information about their teen’s message settings. These tools do not allow parents to read their teen’s messages.\n\nSpecifically, our first set of parental supervision tools on Messenger will allow parents and guardians to:\n\nView how much time their teen spends on Messenger\n\nView and receive updates on their teen’s Messenger contacts list, as well as their teen’s privacy and safety settings\n\nGet notified if their teen reports someone (if the teen chooses to share that information)\n\nView who can message their teen (only their friends, friends of friends, or no one) and see if their teen changes this setting\n\nView who can see their teen’s Messenger stories and get notified if these settings change\n\nOver the next year, we’ll add more features to Parental Supervision on Messenger so parents can help their teens better manage their time and interactions, while still balancing their privacy as these tools function in both unencrypted and end-to-end encrypted chats.\n\nToday’s update is part of our ongoing work to establish Family Center as one central place where parents and guardians can find resources and tools to help manage their teens’ experiences across Meta technologies, and strengthen the dialogue between parents and teens about their online lives.\n\nTesting New Messaging Privacy Features\n\nWe want to protect people from unwanted interactions in Instagram DMs, and these protections are especially important when it comes to teens. We already show Safety Notices when adults who have shown potentially suspicious behavior message teens, and we restrict people over 19 years old from sending private messages to teens who don’t follow them. We’re now testing additional features to limit how people can interact with and message others who don’t follow them:\n\nBefore being able to message someone who doesn’t follow them, people must now send an invite to get their permission to connect. People can only send one invite at a time and can’t send more until the recipient accepts the invitation to connect.\n\nWe’ll limit these message request invites to text only, so people can’t send any photos, videos, or voice messages, or make calls, until the recipient has accepted the invite to chat. These changes mean people won’t receive unwanted photos, videos, or other types of media from people they don’t follow.\n\nNudging Teens to Manage Their Time on Facebook and Instagram\n\nWe want teens to feel good about the time they spend on our apps, which is why we’ve built features like Take a Break on Instagram. Soon, teens will also see a notification when they’ve spent 20 minutes on Facebook, prompting them to take time away from the app and set daily time limits. We’re also exploring a new nudge on Instagram that suggests teens close the app if they are scrolling Reels at night.\n\nIn January, we introduced Quiet Mode on Instagram, a new feature to help people focus and to encourage them to set boundaries with their friends and followers. For example, when you turn on Quiet Mode, you won’t receive any notifications, your profile’s activity status will change to let people know you’re in Quiet Mode, and we’ll automatically send an auto-reply when someone sends you a DM. We’re making Quiet Mode available to everyone on Instagram globally in the coming weeks.\n\nAdditional Parental Supervision Features on Instagram\n\nWe’ve added additional tools to Parental Supervision on Instagram to give parents more visibility into their teens’ experiences on the app and to prompt teens to have conversations with their parents with new notifications. These updates include:\n\nA new notice to teens after they’ve blocked someone. The notice encourages teens to add their parents to supervise their Instagram account as an extra layer of support. Through this notice, we’re meeting teens at specific moments to remind them how they can benefit from parental guidance when it comes to navigating their online interactions.\n\nIn addition to seeing which accounts their teen follows and is followed by, parents will now be able to see how many friends their teen has in common with those accounts. This will help parents understand how well their teen knows these accounts, and help prompt offline conversations about those connections.\n\nMore ways for parents to customize which notifications from Parental Supervision on Instagram they want to receive and how often they receive them.\n\nToday’s updates were designed to help teens feel in control of their online experiences and help parents feel equipped to support their teens. We’ll continue to collaborate with parents and experts to develop additional features that support teens and their families.', 'Nvidia (NVDA) shares rocketed Thursday after the graphics-chip maker crushed Wall Street\'s targets for its fiscal first quarter on record data-center sales. NVDA stock surged more than 20% in morning trades.\n\nX\n\nThe Santa Clara, Calif.-based company late Wednesday said it earned an adjusted $1.09 a share on sales of $7.19 billion in the quarter ended April 30. Analysts polled by FactSet had expected Nvidia earnings of 92 cents a share on sales of $6.53 billion. On a year-over-year basis, Nvidia earnings dropped 20% while sales declined 13% amid continued weak gaming-chip sales.\n\nFor the current quarter, Nvidia forecast sales of $11 billion, up 64% year over year. That target obliterated Wall Street\'s consensus estimate of $7.2 billion for fiscal second-quarter revenue.\n\nChief Executive Jensen Huang said his company is ramping up production to meet the massive demand for artificial intelligence technology.\n\nNVDA Stock Surges After Report\n\nIn morning trades on the stock market today, NVDA stock screamed 24.4% higher to 379.85. During the regular session Wednesday, NVDA stock dropped 0.5% to close at 305.38.\n\n""The computer industry is going through two simultaneous transitions — accelerated computing and generative AI,"" Huang said in a news release. ""A trillion dollars of installed global data center infrastructure will transition from general purpose to accelerated computing as companies race to apply generative AI into every product, service and business process.""\n\nHe added, ""Our entire data center family of products — H100, Grace CPU, Grace Hopper Superchip, NVLink, Quantum 400 InfiniBand and BlueField-3 DPU — is in production. We are significantly increasing our supply to meet surging demand for them.""\n\nIn the first quarter, Nvidia\'s data-center sales rose 14% year over year to $4.28 billion.\n\nThat growth reflected strong demand from large consumer internet companies and cloud service providers for its graphics processing units and related tech, Chief Financial Officer Colette Kress said in a statement. Customers are using its chips for artificial intelligence applications, including generative AI, she said.\n\nGaming-Chip Sales Remain Soft\n\nMeanwhile, Nvidia\'s gaming-chip business saw sales decline 38% year over year to $2.24 billion in the first quarter. The decrease was the result of weaker demand due to the macroeconomic slowdown and lower shipments to normalize channel inventory levels, Kress said.\n\nWall Street analysts gushed about Nvidia\'s beat-and-raise report.\n\n""Nvidia delivered strong upside in terms of reported fiscal Q1 results, as well as fiscal Q2 guide,"" Wells Fargo analyst Aaron Rakers said in a note to clients. He called Nvidia\'s report ""positive"" in all caps with an exclamation point.\n\n""Nvidia absolutely blew away prior expectations with their guide,"" Wedbush Securities analyst Matt Bryson said in a note to clients. ""I can\'t remember a semiconductor/hardware company as big as Nvidia (multiple billions in sales) ever surprising with a guide this much higher vs. expectations in my 20 years covering technology stocks.""\n\nNvidia Chief Warns Of Trade War Fallout\n\nEarlier Wednesday, the Financial Times posted an interview with Nvidia Chief Executive Jensen Huang in which he warned about the negative impact of U.S. trade restrictions on China.\n\nThe U.S. tech industry is at risk of ""enormous damage"" from the escalating battle over chips between Washington and Beijing, Huang said. U.S. export controls introduced by the Biden administration are cutting off American companies from a huge market, he said.\n\nNvidia is barred from selling its most advanced chips to China. The U.S. government is worried that China will use advanced processors for military applications.\n\nNVDA Stock Gets AI Boost\n\nNVDA stock has risen 109% year to date through Wednesday\'s close over investor enthusiasm for its critical role in the burgeoning artificial intelligence field. On Tuesday, Nvidia announced AI technology partnerships with Microsoft (MSFT) and Dell Technologies (DELL).\n\nAnd last week, Nvidia announced a collaboration with ServiceNow (NOW) to develop enterprise-grade capabilities in generative AI.\n\nNvidia ranks fourth out of 37 stocks in IBD\'s fabless semiconductor industry group, according to IBD Stock Checkup. NVDA stock has an IBD Composite Rating of 98 out of 99.\n\nAlso, NVDA stock is on the IBD Leaderboard and Tech Leaders lists.\n\nFollow Patrick Seitz on Twitter at @IBD_PSeitz for more stories on consumer technology, software and semiconductor stocks.\n\nYOU MAY ALSO LIKE:\n\nChipmaker Analog Devices Tops Targets But Warns Of Slowing Sales\n\nAdobe Revamps Its Prized Photoshop App With Generative AI Tools\n\nChina Action Against Micron Called Political, Seen Crimping Sales\n\nSee Stocks On The List Of Leaders Near A Buy Point\n\nFind Winning Stocks With MarketSmith Pattern Recognition & Custom Screens', 'Sometimes separate is simpler, so we’re making it easier to customize your experience on Facebook with multiple personal profiles. Whether you’re new to Facebook or a longtime user, you may want to keep your personal and professional relationships separate, or you may want to keep one profile tied to a community you’re a part of and another profile just for friends. Creating multiple personal profiles lets you easily organize who you share with and what content you see for the various parts of your life. Think one profile for the foodie scene you love and another one to keep up with your friends and family.\n\nWe already offer controls that let you choose what audience you’re sharing with on Facebook, but after experimenting with multiple profiles over the last year, we heard from people that clearer organization of friends, groups, and interests helps them feel freer to engage with the audience they believe is most relevant. And we’ve seen the success of separate interest-based accounts on Instagram, so we’re excited to bring this option to Facebook. The ability to create multiple personal profiles is starting to roll out globally today and will continue over the next few months.\n\nHow it works\n\nChoose a name and have an @username for up to four additional personal profiles.\n\nConnect with the people or communities you choose so each profile has a unique Feed with relevant content and shared interests.\n\nEasily switch between your profiles, with no login required.\n\nAt launch, some Facebook features — such as Dating, Marketplace, Professional Mode and payments — will not be available to additional personal profiles. To start, messaging will be available within the Facebook app and on the web for additional personal profiles. We plan to expand Messenger support for additional profiles in the coming months. The option for an additional personal profile will be available only to eligible adult accounts.\n\nControls\n\nWhen you create an additional personal profile, its settings are automatically set to default settings — notification and privacy settings from one profile don’t carry over to your other profiles. Additionally, some settings are managed separately for each profile, such as choosing who can see that profile’s posts or who can send friend requests to that profile. We recommend checking your privacy settings for each new profile you create, and you can update privacy settings for your profiles at any time. Your main Facebook profile won’t show that you have additional personal profiles.\n\nAuthenticity and Responsibility\n\nOur longstanding policy on Account Integrity and Authentic Identity states that your main Facebook profile must be in the name you go by in everyday life — and this is not changing. You can choose any name for your additional profiles, but not for your main profile. We remain committed to preventing impersonation and identity misrepresentation, so additional profiles cannot impersonate others or be used to misrepresent your identity (including your age or location).\n\nAs always, all profiles must comply with Facebook’s Community Standards. If someone has recently or repeatedly violated our policies, they will not be able to create additional profiles. If someone repeatedly violates our policies using any of their additional personal profiles, appropriate action will be taken on their account and all associated profiles. You can learn more about policies specific to additional personal profiles here.']",,
"['48d62276-3034-6eea-7ce5-d44bef3ecf14', '4a1049ff-100e-af8a-f176-2e35e7a2beb8', 'a9a2c391-b9c0-2c62-b5f0-42411e07809c', 'b506d5f1-3896-7e3f-3e51-5ecb4c32fe78', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['Here is What to Know Beyond Why NVIDIA Corporation (NVDA) is a Trending Stock', 'Nvidia Stock Tests Buy Point After Finding Key Support — Is AI Chip Leader A Buy In December 2023?', 'NVDA_7', 'Why Nvidia (NVDA) is a Top Stock for the Long-Term', 'NVDA_1']","['Item 1. Business Our Company NVIDIA pioneered accelerated computing to help solve the most challenging computational problems. NVIDIA is now a full-stack computing infrastructure company with data-center-scale offerings that are reshaping industry. Our full-stack includes the foundational CUDA programming model that runs on all NVIDIA GPUs, as well as hundreds of domain-specific software libraries, software development kits, or SDKs, and Application Programming Interfaces, or APIs. This deep and broad software stack accelerates the performance and eases the deployment of NVIDIA accelerated computing for computationally intensive workloads such as artificial intelligence, or AI, model training and inference, data analytics, scientific computing, and 3D graphics, with vertical-specific optimizations to address industries ranging from healthcare and telecom to automotive and manufacturing. Our data-center-scale offerings are comprised of compute and networking solutions that can scale to tens of thousands of GPU-accelerated servers interconnected to function as a single giant computer; this type of data center architecture and scale is needed for the development and deployment of modern AI applications. The GPU was initially used to simulate human imagination, enabling the virtual worlds of video games and films. Today, it also simulates human intelligence, enabling a deeper understanding of the physical world. Its parallel processing capabilities, supported by thousands of computing cores, are essential for deep learning algorithms. This form of AI, in which software writes itself by learning from large amounts of data, can serve as the brain of computers, robots and self-driving cars that can perceive and understand the world. GPU-powered AI solutions are being developed by thousands of enterprises to deliver services and products that would have been immensely difficult or even impossible with traditional coding. Examples include generative AI, which can create new content such as text, code, images, audio, video, and molecule structures, and recommendation systems, which can recommend highly relevant content such as products, services, media or ads using deep neural networks trained on vast datasets that capture the user preferences. NVIDIA has a platform strategy, bringing together hardware, systems, software, algorithms, libraries, and services to create unique value for the markets we serve. While the computing requirements of these end markets are diverse, we address them with a unified underlying architecture leveraging our GPUs and networking and software stacks. The programmable nature of our architecture allows us to support several multi-billion-dollar end markets with the same underlying technology by using a variety of software stacks developed either internally or by third-party developers and partners. The large and growing number of developers and installed base across our platforms strengthens our ecosystem and increases the value of our platform to our customers. Innovation is at our core. We have invested over $45.3 billion in research and development since our inception, yielding inventions that are essential to modern computing. Our invention of the GPU in 1999 sparked the growth of the PC gaming market and redefined computer graphics. With our introduction of the CUDA programming model in 2006, we opened the parallel processing capabilities of our GPU to a broad range of compute-intensive applications, paving the way for the emergence of modern AI. In 2012, the AlexNet neural network, trained on NVIDIA GPUs, won the ImageNet computer image recognition competition, marking the &#8220;Big Bang&#8221; moment of AI. We introduced our first Tensor Core GPU in 2017, built from the ground-up for the new era of AI, and our first autonomous driving system-on-chips, or SoC, in 2018. Our acquisition of Mellanox in 2020 expanded our innovation canvas to include networking and led to the introduction of a new processor class &#8211; the data processing unit, or DPU. Over the past 5 years, we have built full software stacks that run on top of our GPUs and CUDA to bring AI to the world&#8217;s largest industries, including NVIDIA DRIVE stack for autonomous driving, Clara for healthcare, and Omniverse for industrial digitalization; and introduced the NVIDIA AI Enterprise software &#8211; essentially an operating system for enterprise AI applications. In 2023, we introduced our first data center CPU, Grace, built for giant-scale AI and high-performance computing. With a strong engineering culture, we drive fast, yet harmonized, product and technology innovations in all dimensions of computing including silicon, systems, networking, software and algorithms. More than half of our engineers work on software. The world&#8217;s leading cloud service providers, or CSPs, and consumer internet companies use our data center-scale accelerated computing platforms to enable, accelerate or enrich the services they deliver to billions of end users, including AI solutions and assistants, search, recommendations, social networking, online shopping, live video, and translation. Enterprises and startups across a broad range of industries use our accelerated computing platforms to build new generative AI-enabled products and services, or to dramatically accelerate and reduce the costs of their workloads and workflows. The enterprise software industry uses them for new AI assistants and chatbots; the transportation industry for autonomous driving; the healthcare industry for accelerated and computer-aided drug discovery; and the financial services industry for customer support and fraud detection. Researchers and developers use our computing solutions to accelerate a wide range of important applications, from simulating molecular dynamics to climate forecasting. With support for more than 3,500 applications, NVIDIA computing enables some of the most promising areas of discovery, from climate prediction to materials science and from wind tunnel simulation to genomics. Including GPUs and networking, NVIDIA powers over 75% of the supercomputers on the global TOP500 list, including 24 of the top 30 systems on the Green500 list. Gamers choose NVIDIA GPUs to enjoy immersive, increasingly cinematic virtual worlds. In addition to serving the growing number of gamers, the market for PC GPUs is expanding because of the burgeoning population of live streamers, broadcasters, artists, and creators. With the advent of generative AI, we expect a broader set of PC users to choose NVIDIA GPUs for running generative AI applications locally on their PC, which is critical for privacy, latency, and cost-sensitive AI applications. Professional artists, architects and designers use NVIDIA partner products accelerated with our GPUs and software platform for a range of creative and design use cases, such as creating visual effects in movies or designing buildings and products. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Nvidia (NVDA), a giant in data centers and gaming, is supercharging investor interest in artificial intelligence. Is Nvidia stock a buy?\n\nX\n\nSemiconductor, AI News\n\nOn Dec. 6, AMD (AMD) released a new AI chip, offering new competition to Nvidia in the huge, fast-growing market.\n\nIn November, Nvidia delivered another quarterly earnings beat-and-raise report. It also unveiled the H200, its latest graphics processing unit for training AI models.\n\nThe AI chip leader has suffered recently from reports that the U.S. will move to crack down on redesigned Nvidia AI (artificial intelligence) chips, which were intended to get around export controls.\n\nCompanies like Nvidia, AMD and Microsoft (MSFT) tap the emerging market for generative AI. Generative AI can create content, including written articles, from simple phrases by analyzing vast amounts of data. It can also write programming code.\n\nFor those looking for the top large-cap stocks to buy now, here\'s a dive into NVDA.\n\nNvidia Stock Technical Analysis\n\nThe AI chip leader broke out past a 476.09 buy point from a double-bottom base in early November, reaching a record 505.48 on Nov. 20. However, the advance from the Oct. 31 low came on light volume, the IBD MarketSmith chart shows.\n\nThe stock stumbled after Nvidia\'s Nov. 21 earnings report, falling back below the buy point and 21-day line. But it has found recent support at the 50-day line.\n\nIf NVDA stock gets back above the entry, the buy zone would go to 499.89, according to IBD Leaderboard.\n\nNvidia stock tested the still-valid 476.09 buy point on Dec. 8, but closed below it.\n\nThe relative strength line for Nvidia stock is starting to show some lag after rallying for most of 2023. A rising RS line, the blue line in IBD charts, shows that a stock is outperforming the S&P 500.\n\nAfter a painful 2022, NVDA stock has soared more than 223% year to date. It mostly held up better than growth stocks at large during recent market sell-offs.\n\nNvidia joined IBD Leaderboard after gapping up on earnings in February.\n\nNVDA earns an IBD Composite Rating of 98 out of 99. In other words, Nvidia stock is in the top 2% of all stocks in terms of technical and fundamental metrics.\n\nInvestors generally should focus on stocks with Comp Ratings of 90 or even 95 and above. Nvidia stock often earns a spot on the IBD 50, Big Cap 20 and Sector Leaders lists.\n\nThe IBD Stock Checkup tool shows that NVDA carries a Relative Strength Rating of 97. That means it has outperformed 97% of all other stocks over the past year.\n\nThe iShares PHLX Semiconductor ETF (SOXX) holds both Nvidia stock and AMD stock.\n\nIBD Live: A New Tool For Daily Stock Market Analysis\n\nNvidia Earnings\n\nNvidia\'s EPS Rating is a perfect 99 and its SMR Rating is an A, on a scale of A to a worst E. The EPS rating compares a company\'s earnings growth to other stocks. Its SMR Rating gauges sales growth, profit margins and return on equity.\n\nOn Nov. 21, Nvidia disclosed earnings rocketed 593% in the third quarter and revenue soared 206%, an overall beat.\n\nNvidia earnings accelerated from a 429% gain the prior quarter. Sales growth also sped up sharply from the previous quarter. The chip giant guided Q4 sales of $20 billion, up 231%.\n\nIn Q3, data-center revenue surged 279%. The business includes the A100 and H100 AI chips.\n\nFor the full year, analysts now expect Nvidia earnings to rebound 264% as sales jump 118%. Last year, Nvidia earnings fell 25% per share.\n\nOut of 54 analysts covering NVDA stock, 51 rate it a buy. Three have a hold and no one has a sell, according to FactSet.\n\nLooking For The Next Big Stock Market Winners? Start With These 3 Steps\n\nNVDA Backstory, Rivals\n\nThe fabless chipmaker pioneered graphics processing units, or GPUs, to make video games more realistic. It\'s expanding in AI chips, used in supercomputers, data centers and drug development.\n\nNvidia\'s GPUs act as accelerators for central processing units, or CPUs, made by other companies. It\'s working on ""supercomputers"" combining its own CPUs and GPUs.\n\nIn addition, Nvidia chips are used for Bitcoin mining and self-driving electric cars.\n\nNvidia has made a big push into metaverse applications.\n\nFabless chip stocks include Qualcomm (QCOM), Broadcom (AVGO) and Monolithic Power Systems (MPWR).\n\nCurrently, the fabless group ranks No. 92 out of 197 industry groups. Fabless companies design the hardware while outsourcing the manufacturing to a third-party firm.\n\nFor the best returns, investors should focus on companies that are leading the market and their own industry group.\n\nIs Nvidia Stock A Buy?\n\nOn a fundamental level, Nvidia is poised for explosive growth. Earnings should more than triple this fiscal year, driven by booming chip sales for data centers and artificial intelligence.\n\nThe fabless chipmaker is expanding in other growth areas, such as automated electric cars, cloud gaming and the metaverse as well.\n\nBut AI competition is intensifying. Macroeconomic uncertainties linger. Geopolitical risks are also rife, from the U.S.-China trade war to actual war in Ukraine and Israel.\n\nNVDA stock has staged a massive comeback, more than tripling in 2023 so far. Nvidia came under pressure after its latest earnings report. Shares are now rebounding from a key level, with the AI chip stock flirting with the buy point again.\n\nBottom line: Nvidia stock is not a buy right now, but it could be soon. As a chip company with exposure to top growth markets, NVDA is always one to watch.\n\nCheck out IBD Stock Lists and other IBD content to find dozens of the best stocks to buy or watch.\n\nYOU MAY ALSO LIKE:\n\nSee The Best Stocks To Buy And Watch\n\nCatch The Next Big Winning Stock With MarketSmith\n\nJoin IBD Live And Learn Top Chart-Reading And Trading Techniques From The Pros\n\n', ""Kickstarting your investment journey can be both exciting and scary at the same time, and if you're new to investing, you may not know where to even begin. However, one thing is for certain -- stocks set to beat the market over the next 12 months serve as the perfect foundation for any kind of investor.\n\nNow, let's break down why adding this one exceptional stock, highlighted below, to your portfolio could be a recipe for success.\n\nWhy You Should Pay Attention to Nvidia (NVDA)\n\nNVIDIA Corporation is the worldwide leader in visual computing technologies and the inventor of the graphic processing unit, or GPU. Over the years, the company’s focus has evolved from PC graphics to artificial intelligence (AI) based solutions that now support high performance computing (HPC), gaming and virtual reality (VR) platforms.\n\nOn May 20, 2019, NVDA was added to the Zacks Focus List at $39.13 per share. Shares have increased 1042.04% to $446.88 since then.\n\n15 analysts revised their earnings estimate higher in the last 60 days for fiscal 2024, while the Zacks Consensus Estimate has increased $2.95 to $10.74. NVDA also boasts an average earnings surprise of 9.8%.\n\nAdditionally, Nvidia's earnings are expected to grow 221.6% for the current fiscal year.\n\nIt can be very profitable to buy stocks with rising earnings estimates, as stock prices respond to revisions. By adding a Focus List stock like NVDA, there's a great chance you'll be getting into a company whose future earnings estimates will be raised, which can lead to price momentum.\n\nWant the latest recommendations from Zacks Investment Research? Today, you can download 7 Best Stocks for the Next 30 Days. Click to get this free report\n\nNVIDIA Corporation (NVDA) : Free Stock Analysis Report\n\nTo read this article on Zacks.com click here.\n\nZacks Investment Research"", ""Nvidia (NVDA) is one of the stocks most watched by Zacks.com visitors lately. So, it might be a good idea to review some of the factors that might affect the near-term performance of the stock.\n\nOver the past month, shares of this maker of graphics chips for gaming and artificial intelligence have returned -0.8%, compared to the Zacks S&P 500 composite's +4.9% change. During this period, the Zacks Semiconductor - General industry, which Nvidia falls in, has gained 3.2%. The key question now is: What could be the stock's future direction?\n\nWhile media releases or rumors about a substantial change in a company's business prospects usually make its stock 'trending' and lead to an immediate price change, there are always some fundamental facts that eventually dominate the buy-and-hold decision-making.\n\nRevisions to Earnings Estimates\n\nRather than focusing on anything else, we at Zacks prioritize evaluating the change in a company's earnings projection. This is because we believe the fair value for its stock is determined by the present value of its future stream of earnings.\n\nWe essentially look at how sell-side analysts covering the stock are revising their earnings estimates to reflect the impact of the latest business trends. And if earnings estimates go up for a company, the fair value for its stock goes up. A higher fair value than the current market price drives investors' interest in buying the stock, leading to its price moving higher. This is why empirical research shows a strong correlation between trends in earnings estimate revisions and near-term stock price movements.\n\nNvidia is expected to post earnings of $4.41 per share for the current quarter, representing a year-over-year change of +401.1%. Over the last 30 days, the Zacks Consensus Estimate has changed +20.8%.\n\nThe consensus earnings estimate of $12.17 for the current fiscal year indicates a year-over-year change of +264.4%. This estimate has changed +14.7% over the last 30 days.\n\nStory continues\n\nFor the next fiscal year, the consensus earnings estimate of $19.71 indicates a change of +61.9% from what Nvidia is expected to report a year ago. Over the past month, the estimate has changed +20.6%.\n\nWith an impressive externally audited track record, our proprietary stock rating tool -- the Zacks Rank -- is a more conclusive indicator of a stock's near-term price performance, as it effectively harnesses the power of earnings estimate revisions. The size of the recent change in the consensus estimate, along with three other factors related to earnings estimates, has resulted in a Zacks Rank #2 (Buy) for Nvidia.\n\nThe chart below shows the evolution of the company's forward 12-month consensus EPS estimate:\n\n12 Month EPS\n\nProjected Revenue Growth\n\nWhile earnings growth is arguably the most superior indicator of a company's financial health, nothing happens as such if a business isn't able to grow its revenues. After all, it's nearly impossible for a company to increase its earnings for an extended period without increasing its revenues. So, it's important to know a company's potential revenue growth.\n\nFor Nvidia, the consensus sales estimate for the current quarter of $20.1 billion indicates a year-over-year change of +232.2%. For the current and next fiscal years, $58.92 billion and $90.22 billion estimates indicate +118.4% and +53.1% changes, respectively.\n\nLast Reported Results and Surprise History\n\nNvidia reported revenues of $18.12 billion in the last reported quarter, representing a year-over-year change of +205.5%. EPS of $4.02 for the same period compares with $0.58 a year ago.\n\nCompared to the Zacks Consensus Estimate of $16.19 billion, the reported revenues represent a surprise of +11.9%. The EPS surprise was +19.64%.\n\nThe company beat consensus EPS estimates in each of the trailing four quarters. The company topped consensus revenue estimates each time over this period.\n\nValuation\n\nWithout considering a stock's valuation, no investment decision can be efficient. In predicting a stock's future price performance, it's crucial to determine whether its current price correctly reflects the intrinsic value of the underlying business and the company's growth prospects.\n\nWhile comparing the current values of a company's valuation multiples, such as price-to-earnings (P/E), price-to-sales (P/S) and price-to-cash flow (P/CF), with its own historical values helps determine whether its stock is fairly valued, overvalued, or undervalued, comparing the company relative to its peers on these parameters gives a good sense of the reasonability of the stock's price.\n\nThe Zacks Value Style Score (part of the Zacks Style Scores system), which pays close attention to both traditional and unconventional valuation metrics to grade stocks from A to F (an An is better than a B; a B is better than a C; and so on), is pretty helpful in identifying whether a stock is overvalued, rightly valued, or temporarily undervalued.\n\nNvidia is graded F on this front, indicating that it is trading at a premium to its peers. Click here to see the values of some of the valuation metrics that have driven this grade.\n\nConclusion\n\nThe facts discussed here and much other information on Zacks.com might help determine whether or not it's worthwhile paying attention to the market buzz about Nvidia. However, its Zacks Rank #2 does suggest that it may outperform the broader market in the near term.\n\nWant the latest recommendations from Zacks Investment Research? Today, you can download 7 Best Stocks for the Next 30 Days. Click to get this free report\n\nNVIDIA Corporation (NVDA) : Free Stock Analysis Report\n\nTo read this article on Zacks.com click here.\n\nZacks Investment Research""]",,
"['44cc608c-6d71-2020-34e3-c7c264b1935d', '911edbf3-396c-c1f4-e97f-18c212dee4c4', 'a6816efd-0b2a-a798-f112-cf2ebc36aeb0', 'a9a2c391-b9c0-2c62-b5f0-42411e07809c', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['AMD_1A', 'Nvidia Stock Tests Buy Point After Finding Key Support — Is AI Chip Leader A Buy In December 2023?', 'What metaverse? Meta says its single largest investment is now in ‘advancing AI’', 'NVDA_7', 'NVDA_1']","['Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'For example, our Client segment revenue decreased due to a decline in the PC market in the second half of 2022 and the first half of 2023, and our Embedded segment revenue decreased as a result of an inventory correction in several end markets in the second half of 2023. We may build inventories during periods of anticipated growth, and the cancellation or deferral of product orders or overproduction due to failure of anticipated orders to materialize could result in excess or obsolete inventory, which could result in write-downs of inventory and an adverse effect on gross margins. Our customers may also experience a shortage of, or delay in receiving certain components to build their products, which in turn may affect the demand for or the timing of our products. For instance, OEMs have and continue to experience industry-wide challenges securing matched component sets to build their products. Excess or obsolete inventory have resulted in, and may in the future result in, write-downs of the value of our inventory. For example, in the third quarter of 2022, we recorded certain charges primarily for inventory, pricing and related reserves in the Gaming and Client segments. Factors that may result in excess or obsolete inventory, a reduction in the average selling price, or a reduction in our gross margin include: a sudden or significant decrease in demand for our products; a production or design defect in our products; a higher incidence of inventory obsolescence because of rapidly changing technology and customer requirements; a failure to accurately estimate customer demand for our products, including for our older products as our new products are introduced; or our competitors introducing new products or taking aggressive pricing actions. Our ability to design and introduce new products in a timely manner includes the use of third-party intellectual property. In the design and development of new and enhanced products, we rely on third-party intellectual property such as development and testing tools for software and hardware. Furthermore, certain product features may rely on intellectual property acquired from third parties that incorporate into our software or hardware. The design requirements necessary to meet customer demand for more features and greater functionality from semiconductor products may exceed the capabilities of the third-party intellectual property or development or testing tools available to us. If the third-party intellectual property that we use becomes unavailable, is not available with required functionality or performance in the time frame, manufacturing technology, or price point needed for our new products or fails to produce designs that meet customer demands, or laws are adopted that affect our use of third party intellectual property in certain regions or products, our business could be materially adversely affected. We depend on third-party companies for the design, manufacture and supply of motherboards, software, memory and other computer platform components to support our business and products. We depend on third-party companies for the design, manufacture and supply of motherboards, graphics cards, software (e.g., BIOS, operating systems, drivers), memory and other components that we use to design, support and sell, and our customers utilize to support and/or use our product offerings. We also rely on our AIB partners to support our products. In addition, our microprocessors are not designed to function with motherboards and chipsets designed to work with Intel microprocessors. If the designers, manufacturers, AIBs and suppliers of motherboards, graphics cards, software, memory and other components cease or reduce their design, manufacture or production of current or future products that are based on, utilized in, or support our products, or laws are adopted that result in the same, our business could be materially adversely affected. If we lose Microsoft Corporation&#8217;s support for our products or other software vendors do not design and develop software to run on our products, our ability to sell our products could be materially adversely affected. Our ability to innovate beyond the x86 instruction set controlled by Intel depends partially on Microsoft designing and developing its operating systems to run on or support our x86-based microprocessor products. With respect to our graphics products, we depend in part on Microsoft to design and develop its operating system to run on or support our graphics products. Similarly, the success of our products in the market, such as our APU products, is dependent on independent software providers designing and developing software to run on our products. If Microsoft does not continue to design and develop its operating systems so that they work with our x86 instruction sets or does not continue to develop and maintain their operating systems to support our graphics products, independent software providers may forego designing their software applications to take advantage of our innovations and customers may not purchase PCs with our products. In addition, some software drivers licensed for use with our products are certified by Microsoft. If Microsoft did not certify a driver, or if we otherwise fail to retain the support of Microsoft or other software vendors, our ability to market our products would be materially adversely affected. Our reliance on third-party distributors and AIB partners subjects us to certain risks. We market and sell our products directly and through third-party distributors and AIB partners pursuant to agreements that can generally be terminated for convenience by either party upon prior notice. These agreements are non-exclusive and permit both our distributors and AIB partners to offer our competitors&#8217; products. We are dependent on our distributors and AIB partners to supplement our direct marketing and sales efforts. If any significant distributor or AIB partner or a substantial number of our distributors or AIB partners terminated their relationship with us, decided to market our competitors&#8217; products over our products or decided not to market our products at all, our ability to bring our products to market would be impacted and we would be materially adversely affected. We extend credit to certain of our distributors and AIB partners. If we are unable to collect accounts receivable from our significant distributors and/or AIB partners or incur higher allowances for credit losses, it could have a material adverse effect on our business. ', 'Nvidia (NVDA), a giant in data centers and gaming, is supercharging investor interest in artificial intelligence. Is Nvidia stock a buy?\n\nX\n\nSemiconductor, AI News\n\nOn Dec. 6, AMD (AMD) released a new AI chip, offering new competition to Nvidia in the huge, fast-growing market.\n\nIn November, Nvidia delivered another quarterly earnings beat-and-raise report. It also unveiled the H200, its latest graphics processing unit for training AI models.\n\nThe AI chip leader has suffered recently from reports that the U.S. will move to crack down on redesigned Nvidia AI (artificial intelligence) chips, which were intended to get around export controls.\n\nCompanies like Nvidia, AMD and Microsoft (MSFT) tap the emerging market for generative AI. Generative AI can create content, including written articles, from simple phrases by analyzing vast amounts of data. It can also write programming code.\n\nFor those looking for the top large-cap stocks to buy now, here\'s a dive into NVDA.\n\nNvidia Stock Technical Analysis\n\nThe AI chip leader broke out past a 476.09 buy point from a double-bottom base in early November, reaching a record 505.48 on Nov. 20. However, the advance from the Oct. 31 low came on light volume, the IBD MarketSmith chart shows.\n\nThe stock stumbled after Nvidia\'s Nov. 21 earnings report, falling back below the buy point and 21-day line. But it has found recent support at the 50-day line.\n\nIf NVDA stock gets back above the entry, the buy zone would go to 499.89, according to IBD Leaderboard.\n\nNvidia stock tested the still-valid 476.09 buy point on Dec. 8, but closed below it.\n\nThe relative strength line for Nvidia stock is starting to show some lag after rallying for most of 2023. A rising RS line, the blue line in IBD charts, shows that a stock is outperforming the S&P 500.\n\nAfter a painful 2022, NVDA stock has soared more than 223% year to date. It mostly held up better than growth stocks at large during recent market sell-offs.\n\nNvidia joined IBD Leaderboard after gapping up on earnings in February.\n\nNVDA earns an IBD Composite Rating of 98 out of 99. In other words, Nvidia stock is in the top 2% of all stocks in terms of technical and fundamental metrics.\n\nInvestors generally should focus on stocks with Comp Ratings of 90 or even 95 and above. Nvidia stock often earns a spot on the IBD 50, Big Cap 20 and Sector Leaders lists.\n\nThe IBD Stock Checkup tool shows that NVDA carries a Relative Strength Rating of 97. That means it has outperformed 97% of all other stocks over the past year.\n\nThe iShares PHLX Semiconductor ETF (SOXX) holds both Nvidia stock and AMD stock.\n\nIBD Live: A New Tool For Daily Stock Market Analysis\n\nNvidia Earnings\n\nNvidia\'s EPS Rating is a perfect 99 and its SMR Rating is an A, on a scale of A to a worst E. The EPS rating compares a company\'s earnings growth to other stocks. Its SMR Rating gauges sales growth, profit margins and return on equity.\n\nOn Nov. 21, Nvidia disclosed earnings rocketed 593% in the third quarter and revenue soared 206%, an overall beat.\n\nNvidia earnings accelerated from a 429% gain the prior quarter. Sales growth also sped up sharply from the previous quarter. The chip giant guided Q4 sales of $20 billion, up 231%.\n\nIn Q3, data-center revenue surged 279%. The business includes the A100 and H100 AI chips.\n\nFor the full year, analysts now expect Nvidia earnings to rebound 264% as sales jump 118%. Last year, Nvidia earnings fell 25% per share.\n\nOut of 54 analysts covering NVDA stock, 51 rate it a buy. Three have a hold and no one has a sell, according to FactSet.\n\nLooking For The Next Big Stock Market Winners? Start With These 3 Steps\n\nNVDA Backstory, Rivals\n\nThe fabless chipmaker pioneered graphics processing units, or GPUs, to make video games more realistic. It\'s expanding in AI chips, used in supercomputers, data centers and drug development.\n\nNvidia\'s GPUs act as accelerators for central processing units, or CPUs, made by other companies. It\'s working on ""supercomputers"" combining its own CPUs and GPUs.\n\nIn addition, Nvidia chips are used for Bitcoin mining and self-driving electric cars.\n\nNvidia has made a big push into metaverse applications.\n\nFabless chip stocks include Qualcomm (QCOM), Broadcom (AVGO) and Monolithic Power Systems (MPWR).\n\nCurrently, the fabless group ranks No. 92 out of 197 industry groups. Fabless companies design the hardware while outsourcing the manufacturing to a third-party firm.\n\nFor the best returns, investors should focus on companies that are leading the market and their own industry group.\n\nIs Nvidia Stock A Buy?\n\nOn a fundamental level, Nvidia is poised for explosive growth. Earnings should more than triple this fiscal year, driven by booming chip sales for data centers and artificial intelligence.\n\nThe fabless chipmaker is expanding in other growth areas, such as automated electric cars, cloud gaming and the metaverse as well.\n\nBut AI competition is intensifying. Macroeconomic uncertainties linger. Geopolitical risks are also rife, from the U.S.-China trade war to actual war in Ukraine and Israel.\n\nNVDA stock has staged a massive comeback, more than tripling in 2023 so far. Nvidia came under pressure after its latest earnings report. Shares are now rebounding from a key level, with the AI chip stock flirting with the buy point again.\n\nBottom line: Nvidia stock is not a buy right now, but it could be soon. As a chip company with exposure to top growth markets, NVDA is always one to watch.\n\nCheck out IBD Stock Lists and other IBD content to find dozens of the best stocks to buy or watch.\n\nYOU MAY ALSO LIKE:\n\nSee The Best Stocks To Buy And Watch\n\nCatch The Next Big Winning Stock With MarketSmith\n\nJoin IBD Live And Learn Top Chart-Reading And Trading Techniques From The Pros\n\n', ""We offer tuition reimbursement programs to subsidize educational programs and advanced certifications. We implemented a career coaching service to provide one-on-one guidance to employees, and encourage internal job mobility. We have implemented specifically designed mentoring and development programs for women and employees from traditionally underrepresented groups to ensure widespread readiness for future advancement. To evaluate employee sentiment and engagement, we use pulse surveys, a suggestion box, and an anonymous third-party platform. Pulse surveys help us gain insight into employee experience and provides employee-generated ideas so that we can take targeted action. The suggestion box is an always-on, interactive tool where employees share their thoughts about making our company a better place to work. The anonymous third-party platform is designed to protect the identity of the reporter and provide a mechanism for reporters to follow an investigation and receive responses. We want NVIDIA to be a place where people can build their careers over their lifetime. Our employees tend to come and stay. In fiscal year 2024, our overall turnover rate was 2.7%. Compensation, Benefits, and Well-Being Our compensation program rewards performance and is structured to encourage employees to invest in the Company&#8217;s future. Employees receive equity, except where unavailable due to local regulations, that is tied to the value of our stock price and vests over time to retain employees while simultaneously aligning their interests with those of our shareholders. We offer comprehensive benefits to support our employees&#8217; and their families&#8217; physical health, well-being, and financial health. Programs include 401(k) programs in the U.S., statutory and supplemental pension programs outside the U.S., our employee stock purchase program, flexible work hours, and time off policies to address mental health, stress, and time-management challenges. We evaluate our benefit offerings globally and aim to provide comparable support across the regions where we operate. We are committed to providing tailored benefits based on the needs of our Community Resource Groups and continuing our support for parents, both new birth parents and those who wish to become parents. Our support is enhanced during times of crisis, such as war or economic volatility, to take care of our existing team of world-class talent and their families. Diversity, Inclusion, and Belonging We believe that diverse teams fuel innovation, and we are committed to creating an inclusive culture that supports all employees. When recruiting for new talent or developing our current employees, we strive to build a diverse talent pipeline that includes those underrepresented in the technology field, including women, Black/African American, and Hispanic/Latino candidates. To this end, we have been: &#8226; Partnering with institutions and professional organizations serving historically underrepresented communities; &#8226; Embedding dedicated recruiting teams to business areas to shepherd underrepresented candidates through the interview process and find internal opportunities; &#8226; Supporting the development of women employees through programs aimed at building a pipeline of future leaders; &#8226; Providing peer support and executive sponsors for our internal community resource groups; &#8226; Providing training and education to managers and peers on fostering supportive environments and recruiting for diversity; &#8226; Track equity and parity in retention, promotions, pay, and employee engagement scores; and &#8226; Measuring year over year progress and providing leadership visibility on diversity efforts. As of the end of fiscal year 2024, our global workforce was 79% male, 20% female, and 1% not declared, with 6% of our workforce in the United States composed of Black or African American and Hispanic or Latino employees. Flexible Working Environment We support a flexible work environment, understanding that many employees want the ability to work from home under certain conditions. This flexibility supports diverse hiring, retention, and employee engagement, which we believe makes NVIDIA a great place to work. During fiscal year 2025, we will continue to have a flexible work environment and maintain our company wide 2-days off a quarter for employees to rest and recharge. Information About Our Executive Officers The following sets forth certain information regarding our executive officers, their ages, and positions as of February 16, 2024: ##TABLE_START Name Age Position Jen-Hsun Huang 60 President and Chief Executive Officer Colette M. Kress 56 Executive Vice President and Chief Financial Officer Ajay K. Puri 69 Executive Vice President, Worldwide Field Operations Debora Shoquist 69 Executive Vice President, Operations Timothy S. Teter 57 Executive Vice President and General Counsel ##TABLE_END Jen-Hsun Huang co-founded NVIDIA in 1993 and has served as our President, Chief Executive Officer, and a member of the Board of Directors since our inception. From 1985 to 1993, Mr. Huang was employed at LSI Logic Corporation, a computer chip manufacturer, where he held a variety of positions including as Director of Coreware, the business unit responsible for LSI's SOC. From 1983 to 1985, Mr. Huang was a microprocessor designer for AMD, a semiconductor company. Mr. Huang holds a B.S.E.E. degree from Oregon State University and an M.S.E.E. degree from Stanford University. Colette M. Kress joined NVIDIA in 2013 as Executive Vice President and Chief Financial Officer. Prior to NVIDIA, Ms. Kress most recently served as Senior Vice President and Chief Financial Officer of the Business Technology and Operations Finance organization at Cisco Systems, Inc., a networking equipment company, since 2010. At Cisco, Ms. Kress was responsible for financial strategy, planning, reporting and business development for all business segments, engineering and operations. From 1997 to 2010 Ms. Kress held a variety of positions at Microsoft, a software company, including, beginning in 2006, Chief Financial Officer of the Server and Tools division, where Ms. Kress was responsible for financial strategy, planning, reporting and business development for the division. Prior to joining Microsoft, Ms. Kress spent eight years at Texas Instruments Incorporated, a semiconductor company, where she held a variety of finance positions. Ms. Kress holds a B.S. degree in Finance from University of Arizona and an M.B.A. degree from Southern Methodist University. Ajay K. Puri joined NVIDIA in 2005 as Senior Vice President, Worldwide Sales and became Executive Vice President, Worldwide Field Operations in 2009. Prior to NVIDIA, he held positions in sales, marketing, and general management over a 22-year career at Sun Microsystems, Inc., a computing systems company. "", 'CNN —\n\nRoughly a year-and-a-half after Facebook renamed itself “Meta” and said it would go all-in on building a future version of the internet dubbed the metaverse, the tech giant now says its top investment priority will be advancing artificial intelligence.\n\nIn a letter to staff Tuesday, CEO Mark Zuckerberg announced plans to lay off another 10,000 employees in the coming months, and doubled down on his new focus of “efficiency” for the company. The pivot to efficiency, first announced last month in Meta’s quarterly earnings call, comes after years of investing heavily in growth, including in areas with unproven potential like virtual reality.\n\nNow, Zuckerberg says the company will focus mostly on cutting costs and streamlining projects. Building the metaverse “remains central to defining the future of social connection,” Zuckerberg wrote, but that isn’t where Meta will be putting most of its capital.\n\n“Our single largest investment is in advancing AI and building it into every one of our products,” Zuckerberg said Tuesday. He nodded to how AI tools can help users of its apps express themselves and “discover new content,” but also said that new AI tools can be used to increase efficiencies internally by helping “engineers write better code faster.”\n\nThe comments come after what the CEO described as a “humbling wake-up call” last year, as the “world economy changed, competitive pressures grew, and our growth slowed considerably.”\n\nMeta and its predecessor Facebook have been involved in AI research for years, but the remarks come amid a heightened AI frenzy in the tech world, kicked off in late November when Microsoft-backed OpenAI publicly released ChatGPT. The technology quickly went viral for its ability to generate compelling, human-sounding responses to user prompts and then kicked off an apparent AI arms race among tech companies. Microsoft announced in early February that it was incorporating the tech behind ChatGPT into its search engine, Bing. A day before Microsoft’s announcement, Google unveiled its own AI-powered tool called Bard. And not to be left behind, Meta announced late last month that it was forming a “top-level product group” to “turbocharge” the company’s work on AI tools.\n\n“I do think it is a good thing to focus on AI,” Ali Mogharabi, a senior equity analyst at Morningstar, told CNN of Zuckerberg’s comments. Mogharabi said Meta’s investments in AI “has benefits on both ends” because it can improve efficiency for engineers creating products, and because incorporating AI features into Meta’s lineup of apps will potentially create more engagement time for users, which can then drive advertising revenue.\n\nAnd in the long run, Mogharabi said, “A lot of the investments in AI, and a lot of enhancements that come from those investments in AI, could actually be applicable to the entire metaverse project.”\n\nBut Zuckerberg’s emphasis on investing in AI, and using the buzzy technology’s tools to make the company more efficient and boost its bottom line, is also “what the shareholders and the market want to hear,” Mogharabi said. Many investors had previously griped at the company’s metaverse ambitions and spending. In 2022, Meta lost more than $13.7 billion in its “Reality Labs” unit, which houses its metaverse efforts.\n\nAnd investors appear to welcome Zuckerberg’s shift in focus from the metaverse to efficiency. After taking a beating in 2022, shares for Meta have surged more than 50% since the start of the year.\n\nAngelo Zino, a senior equity analyst at CFRA Research, said on Tuesday that the second round of layoffs at Meta “officially make us convinced that Mark Zuckerberg has completely switched gears, altering the narrative of the company to one focused on efficiencies rather than looking to grow the metaverse at any cost.”']",,
"['19857181-dd62-9d08-2747-3331540f0b81', '6977ce03-8b23-d59b-cb5c-52457b20a573', 'b212ddfc-cb92-43ac-de99-bf0def886139', 'c64e4be0-0a6b-a621-a919-864efa4ae279', 'fcfd1b5a-f708-0a3d-3ac6-172751a4c64d']","['META_1', 'NVIDIA (NVDA) Launches China-Specific Chip Amid US Restrictions', 'META_1A', 'META_7']","['NVIDIA Corporation NVDA formally launched a China-specific lower version of its most powerful gaming chip, which complies with the U.S. restrictions on the company’s export of advanced artificial intelligence (AI) chips to that country.\n\nThe graphic chip maker unveiled RTX 4090D on Thursday, which is available for sale on its China website. The newly launched graphic processing unit (GPU) has a reduced AI inference performance than the RTX 4090 sold in other countries.\n\nAccording to a Bloomberg report, the chip has approximately 10% fewer processing cores than the RTX 4090. NVIDIA has also undertaken measures to prevent end-users from modifying the China-specific chip into a regular RTX 4090.\n\nNVIDIA Corporation Price and Consensus\n\nNVIDIA Corporation price-consensus-chart | NVIDIA Corporation Quote\n\nNVIDIA Caught in the US-China Tech War\n\nOver the past year, President Joe Biden\'s administration has been imposing trade restrictions to restrict China from getting its hands on cutting-edge technologies that can strengthen its military. Last year, the U.S. government restricted NVIDIA from selling its A100, A100X and H100 integrated circuits to China and Russia. It also banned the company from exporting DGX or other systems using A100 or H100 integrated circuits.\n\nIn October 2023, the Biden administration imposed fresh restrictions on the sale of AI chips and manufacturing equipment to China. The newly expanded restrictions have blocked NVIDIA from selling two AI chips — A800 and H800 — specifically created for the Chinese market following last year’s export curb.\n\nNVIDIA had cautioned that the restrictions may hurt its business in China. In a filing with the Securities and Exchange Commission, the company revealed that it may be forced to discontinue its business operations from countries on the U.S. government’s export restriction list. The rules are expected to impact NVDA’s ability to support its existing customers and complete the development of certain products in a timely manner.\n\nStory continues\n\nHowever, by launching the less powerful version of RTX 4090, which complies with all US restrictions, this Zacks Rank #2 (Buy) company will be able to boost its sales in China. You can see the complete list of today’s Zacks #1 Rank (Strong Buy) stocks here.\n\nGenAI Investment Aids NVIDIA’s Growth\n\nNVIDIA has witnessed a remarkable run, showcasing a staggering 243% year-to-date surge in its stock price. The company also achieved a massive milestone in May 2023 by joining the exclusive club of companies with a $1 trillion market capitalization.\n\nNVIDIA’s robust stock price performance has been primarily driven by hopes that the company will be a prime beneficiary of growing investments in generative AI. The company dominates the market for AI chips. The meteoric rise of OpenAI’s ChatGPT and its adoption among enterprises have already proven generative AI technology’s usefulness across multiple industries, including marketing, advertising, customer service, education, content creation, healthcare, automotive, energy & utilities and video game development.\n\nHowever, generative AI requires vast knowledge to create content and needs huge computational power. As a result, enterprises looking to create generative AI-based applications will be required to upgrade their existing network infrastructure.\n\nNVIDIA’s next-generation chips with high computing power can be the top choice for enterprises. The company’s GPUs are already being applied in AI models. This is expanding NVDA’s footprint in untapped markets like automotive, healthcare and manufacturing.\n\nThe generative AI revolution is likely to create huge demand for its next-generation high computing powerful chips. Considering surging AI investments across the data center end market, NVDA expects its fourth-quarter fiscal 2024 revenues to reach $20 billion from $6.05 billion in the year-ago quarter.\n\nOther Companies Banking on AI Investment\n\nAs organizations pivot toward digital transformation, AI investments are set to soar in the coming years, becoming pivotal to staying competitive in the digital landscape. The latest projection from the International Data Corporation forecasts a monumental surge, estimating global AI spending to surpass $300 billion by 2026, indicating a remarkable compound annual growth rate (CAGR) of 27% from 2022 to 2026.\n\nTech behemoths like Meta Platforms, Inc. META, Intel Corporation INTC and UiPath Inc. PATH are seizing the immense potential of the AI sector.\n\nMeta is amplifying its presence in the AI realm with the groundbreaking Large Language Model Meta AI, or ""Llama."" Collaborating with Microsoft, Meta introduced Llama 2, the next-gen iteration, and Code Llama, an AI model proficient in generating and discussing code using text prompts. This Zacks Rank #2 company is set to launch Meta AI in beta — a sophisticated conversational assistant slated for integration across WhatsApp, Messenger and Instagram, extending to their Ray-Ban Meta smart glasses and Quest 3.\n\nIntel made a significant shift by launching AI chips for data centers and personal computers in 2023 — a strategic leap in more than four decades. This move targets a robust foothold in the expansive AI domain, spanning cloud, enterprise servers, network infrastructure and edge computing — an alignment with the ever-evolving market trends. The upcoming Intel Gaudi3 chips, slated for release in 2024, signify this Zacks Rank #3 (Hold) company\'s focus on advancing AI accelerators, catering to the growing demand for generative AI models and deep learning applications.\n\nUiPath is enhancing its platform with AI-centric services to foster top-line growth in 2024. These include augmentations to existing AutoPilot services and broader cross-platform connectivity options. This Zacks Rank #2 company\'s Clipboard AI, recognized as one of TIME\'s Best Inventions of 2023, streamlines operations by eliminating manual copy-pasting.\n\nWant the latest recommendations from Zacks Investment Research? Today, you can download 7 Best Stocks for the Next 30 Days. Click to get this free report\n\nIntel Corporation (INTC) : Free Stock Analysis Report\n\nNVIDIA Corporation (NVDA) : Free Stock Analysis Report\n\nUiPath, Inc. (PATH) : Free Stock Analysis Report\n\nMeta Platforms, Inc. (META) : Free Stock Analysis Report\n\nTo read this article on Zacks.com click here.\n\nZacks Investment Research', ""We also recently commenced implementation of end-to-end encryption across our messaging services on Facebook and Instagram, which has been subject to governmental and regulatory scrutiny in multiple jurisdictions. Table of Contents If our new products or changes to existing products fail to engage users, marketers, or developers, or if our business plans are unsuccessful, we may fail to attract or retain users or to generate sufficient revenue, operating margin, or other value to justify our investments, and our business may be adversely affected. We may not be successful in our artificial intelligence initiatives, which could adversely affect our business, reputation, or financial results. We are making significant investments in AI initiatives, including generative AI, to, among other things, recommend relevant content across our products, enhance our advertising tools, develop new products, and develop new features for existing products. In particular, we expect our AI initiatives will require increased investment in infrastructure and headcount. There are significant risks involved in developing and deploying AI and there can be no assurance that the usage of AI will enhance our products or services or be beneficial to our business, including our efficiency or profitability. For example, our AI-related efforts, particularly those related to generative AI, subject us to risks related to harmful or illegal content, accuracy, misinformation (including related to elections), bias, discrimination, toxicity, intellectual property infringement or misappropriation, defamation, data privacy, cybersecurity, and sanctions and export controls, among others. It is also uncertain how various laws related to online services, intermediary liability, and other issues will apply to content generated by AI. In addition, we are subject to the risks of new or enhanced governmental or regulatory scrutiny, litigation, or other legal liability, ethical concerns, negative consumer perceptions as to automation and AI, activities that threaten people's safety or well-being on- or offline, or other complications that could adversely affect our business, reputation, or financial results. As a result of the complexity and rapid development of AI, it is also the subject of evolving review by various governmental and regulatory agencies in jurisdictions around the world, which are applying, or are considering applying, platform moderation, intellectual property, cybersecurity, and data protection laws to AI and/or are considering general legal frameworks on AI. We may not always be able to anticipate how courts and regulators will apply existing laws to AI, predict how new legal frameworks will develop to address AI, or otherwise respond to these frameworks as they are still rapidly evolving. We may also have to expend resources to adjust our offerings in certain jurisdictions if the legal frameworks on AI are not consistent across jurisdictions. Further, we face significant competition from other companies that are developing their own AI features and technologies. Other companies may develop AI features and technologies that are similar or superior to our technologies or are more cost-effective to develop and deploy. Given the long history of development in the AI sector, other parties may have (or in the future may obtain) patents or other proprietary rights that would prevent, limit, or interfere with our ability to make, use, or sell our own AI features. Further, our ability to continue to develop and effectively deploy AI technologies is dependent on access to specific third-party equipment and other physical infrastructure, such as processing hardware and network capacity, as to which we cannot control the availability or pricing, especially in a highly competitive environment. We are also developing AI technology that we make available via open source, commercial, and non-commercial license agreements to third-parties that can use this technology for use in their own products and services. We may not have insight into, or control over, the practices of third parties who may utilize such AI technologies. As such, we cannot guarantee that third parties will not use such AI technologies for improper purposes, including through the dissemination of illegal, inaccurate, defamatory or harmful content, intellectual property infringement or misappropriation, furthering bias or discrimination, cybersecurity attacks, data privacy violations, other activities that threaten people's safety or well-being on- or offline, or to develop competing technologies. While we may mitigate certain risks associated with the improper use of our AI models through both technical measures and the inclusion of contractual restrictions on third-party use in any agreement between us and any third party, we cannot guarantee that such measures will be effective. Such improper use by any third party could adversely affect our business, reputation, or financial results or subject us to legal liability. It is not possible to predict all of the risks related to the use of AI and changes in laws, rules, directives, and regulations governing the use of AI may adversely affect our ability to develop and use AI or subject us to legal liability. Table of Contents We make product and investment decisions that may not prioritize short-term financial results and may not produce the long-term benefits that we expect. We frequently make product and investment decisions that may not prioritize short-term financial results if we believe that the decisions are consistent with our mission and benefit the aggregate user experience and will thereby improve our financial performance over the long term. For example, we have implemented, and we will continue to implement, changes to our user data practices. Some of these changes reduce our ability to effectively target ads, which has to some extent adversely affected, and will continue to adversely affect, our advertising business. For example, our Off-Facebook Activity tool enables users to place limits on our storage and use of information about their interactions with advertisers' apps and websites, which reduces our ability to deliver the most relevant and effective ads to our users. Similarly, from time to time we update our feed display and ranking algorithms or other product features to improve the user experience, and these changes have had, and may in the future have, the effect of reducing time spent and some measures of user engagement with our products, which could adversely affect our financial results. From time to time, we also change the size, frequency, or relative prominence of ads as part of our product and monetization strategies. "", ""Item 1. Business Overview Our mission is to give people the power to build community and bring the world closer together. All of our products, including our apps, share the vision of helping to bring the metaverse to life. We build technology that helps people connect and share, find communities, and grow businesses. Our products enable people to connect and share with friends and family through mobile devices, personal computers, virtual reality (VR) and mixed reality (MR) headsets, and wearables. We also help people discover and learn about what is going on in the world around them, enable people to share their experiences, ideas, photos and videos, and other activities with audiences ranging from their closest family members and friends to the public at large, and stay connected everywhere by accessing our products. Meta is moving our offerings beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the metaverse, which we believe is the next evolution in social technology. Our vision for the metaverse does not center on any single product, but rather an entire ecosystem of experiences, devices, and new technologies. While the metaverse is in the very early stages of its development, we believe it will become the next computing platform and the future of social interaction. Across our work, we are innovating in artificial intelligence (AI) technologies to build new experiences that help make our platform more social, useful, and immersive. We report financial results for two segments: Family of Apps (FoA) and Reality Labs (RL). Currently, we generate substantially all of our revenue from selling advertising placements on our family of apps to marketers, which is reflected in FoA. Ads on our platform enable marketers to reach people across a range of marketing objectives, such as generating leads or driving awareness. Marketers purchase ads that can appear in multiple places including on Facebook, Instagram, Messenger, and third-party applications and websites. RL generates revenue from sales of consumer hardware products, software, and content. We invest in our business based on our company priorities. In 2024, we intend to focus on six key investment areas: AI, the metaverse, our discovery engine, monetization of our products and services, regulatory readiness, and enhancing developer efficiency to build, iterate, and optimize products quickly. Our AI investments support initiatives across our products and services, helping power the systems that rank content in our apps, our discovery engine that recommends relevant content, the tools advertisers use to reach customers, the development of new generative AI experiences, and the tools that make our product development more efficient and productive. The majority of our investments are directed toward developing our family of apps. In 2023, 80% of our total costs and expenses were recognized in FoA and 20% were recognized in RL. Our FoA investments were $70.13 billion in 2023 and include expenses relating to headcount, data centers and technical infrastructure as part of our efforts to develop our apps and our advertising services. We are also making significant investments in our metaverse efforts, including developing virtual and augmented reality devices, software for social platforms, neural interfaces, and other foundational technologies. Our total RL investments were $18.02 billion in 2023 and include expenses relating to headcount and technology development across these efforts. These are fundamentally new technologies that we expect will evolve as the metaverse ecosystem develops, and many products for the metaverse may only be fully realized in the next decade. Although it is inherently difficult to predict when and how the metaverse ecosystem will develop, we expect our RL segment to continue to operate at a loss for the foreseeable future, and our ability to support our metaverse efforts is dependent on generating sufficient profits from other areas of our business. We expect this will be a complex, evolving, and long-term initiative. We are investing now because we believe this is the next chapter of the internet and will unlock monetization opportunities for businesses, developers, and creators, including around advertising, hardware, and digital goods. Family of Apps Products &#8226; Facebook. Facebook helps give people the power to build community and bring the world closer together. It's a place for people to share life's moments and discuss what's happening, nurture and build relationships, discover and connect to interests, and create economic opportunity. They can do this through Feed, Reels, Stories, Groups, Marketplace, and more. Table of Contents &#8226; Instagram. Instagram brings people closer to the people and things they love. Instagram Feed, Stories, Reels, Live, and messaging are places where people and creators can connect and express themselves through photos, video, and private messaging, and discover and shop from their favorite businesses. &#8226; Messenger. Messenger is a simple yet powerful messaging application for people to connect with friends, family, communities, and businesses across platforms and devices through text, audio, and video calls. &#8226; Threads. Threads is an application for text-based updates and public conversations, where communities come together to discuss topics of interest. People can connect directly with their favorite creators and others who love the same things or build a loyal following of their own to share their ideas, opinions, and creativity with the world. &#8226; WhatsApp. WhatsApp is a simple, reliable, and secure messaging application that is used by people and businesses around the world to communicate and transact in a private way. Within WhatsApp we launched WhatsApp Channels, a one-to-many broadcast service designed to help people follow information from people and organizations that are important to them. Reality Labs Products Many of our metaverse investments are directed toward long-term, cutting-edge research and development for products that are not on the market today and may only be fully realized in the next decade. This includes exploring new technologies such as neural interfaces using electromyography, which lets people control their devices using neuromuscular signals, as well as innovations in AI and hardware to help build next-generation interfaces. In the near term, we are continuing to develop early metaverse experiences through Reality Labs products that help people feel connected, anytime, anywhere. "", 'Users in India, Bangladesh, and Nigeria repr esented the top three sources of growth in DAUs during December 2023, relative to the same period in 2022. &#8226; Monthly Active Users (MAUs). We define a monthly active user as a registered and logged-in Facebook user who visited Facebook through our website or a mobile device, or used our Messenger application (and is also a registered Facebook user), in the last 30 days as of the date of measurement. MAUs are a measure of the size of our global active user community on Facebook. As of December 31, 2023, we had 3.07 billion MAUs, an increase of 3% from December 31, 2022. Users in India, Bangladesh, and Nigeria represented the top three sources of growth in 2023, relative to the same period in 2022. Table of Contents Trends in Our Monetization by Facebook User Geography We calculate our revenue by user geography based on our estimate of the geography in which ad impressions are delivered, virtual and digital goods are purchased, or consumer hardware products are shipped. We define ARPU as our total revenue in a given geography during a given quarter, divided by the average of the number of MAUs in the geography at the beginning and end of the quarter. While ARPU includes all sources of revenue, the number of MAUs used in this calculation only includes users of Facebook and Messenger as described in the definition of MAU above. While the share of revenue from users who are not also Facebook or Messenger MAUs has grown over time, we estimate that revenue from users who are Facebook or Messenger MAUs represents the substantial majority of our total revenue. See ""Average Revenue Per Person (ARPP)"" above for our estimates of trends in our monetization of our Family products. The geography of our users affects our revenue and financial results because we currently monetize users in different geographies at different average rates. Our revenue and ARPU in regions such as United States &#38; Canada and Europe are relatively higher primarily due to the size and maturity of those online and mobile advertising markets. For example, ARPU in 2023 in the United States &#38; Canada region was more than 11 times higher than in the Asia-Pacific region. --- ARPU: -- $11.57 --- $9.54 --- $9.82 --- $9.41 --- $10.86 ---- $9.62 ---- $10.63 ---- $11.23 --- $13.12 - - -- ARPU: -- $60.57 -- $48.29 -- $50.25 -- $49.13 --- $58.77 -- $48.85 --- $53.53 --- $56.11 --- $68.44 -------- ARPU: -- $19.68 -- $15.35 -- $15.64 -- $14.23 -- $17.29 --- $15.51 -- $17.88 --- $19.04 --- $23.14 - ARPU: -- $4.89 ---- $4.47 ---- $4.54 ---- $4.42 ---- $4.61 ---- $4.52 ---- $4.88 ----- $5.12 ---- $5.52 ------- ARPU: -- $3.43 ----- $3.14 ---- $3.35 ---- $3.21 ---- $3.52 ---- $3.35 ---- $3.76 ----- $4.22 ---- $4.50 ##TABLE_START Ad Revenue Non-Ad Revenue ##TABLE_END Note: Non-advertising revenue includes RL revenue generated from the delivery of consumer hardware products and FoA Other revenue, which consists of revenue from WhatsApp Business Platform, net fees we receive from developers using our Payments infrastructure, and revenue from various other sources. Table of Contents Our revenue by user geography in the charts above is geographically apportioned based on our estimation of the geographic location of our users when they perform a revenue-generating activity. This allocation differs from our revenue disaggregated by geography disclosure in Note 2 &#8212; Revenue in our consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplemental Data"" where revenue is geographically apportioned based on the addresses of our customers. Our annual worldwide ARPU in 2023, which represents the sum of quarterly ARPU during such period, was $44.60, an increase of 13% from 2022. For 2023, ARPU increased by 21% in Europe, 20% in Rest of World, 11% in Asia-Pacific, and 10% in United States &#38; Canada. User growth was mostly in geographies with relatively lower ARPU, such as Asia&#8209;Pacific and Rest of World. We expect that user growth in the future will be primarily concentrated in those regions where ARPU is relatively lower, such that worldwide ARPU may continue to increase at a slower rate relative to ARPU in any geographic region in a particular period, or potentially decrease even if ARPU increases in each geographic region. Table of Contents Critical Accounting Estimates Our consolidated financial statements are prepared in accordance with GAAP. The preparation of these consolidated financial statements requires us to make estimates and assumptions that affect the reported amounts of assets, liabilities, revenue, costs and expenses, and related disclosures. On an ongoing basis, we evaluate our accounting estimates based on historical experience and on various other assumptions that we believe are reasonable under the circumstances. The actual impact on our financial performance could differ from these estimates under different assumptions or conditions. An accounting estimate is considered critical if both (i) the nature of the estimates or assumptions is material due to the levels of subjectivity and judgment involved, and (ii) the impact within a reasonable range of outcomes of the estimates and assumptions is material to our consolidated financial statements. We believe that the estimates and assumptions associated with loss contingencies, income taxes, and valuation of assets, when applicable, have the greatest potential impact on our consolidated financial statements. Therefore, we consider these to be our critical accounting estimates. For further information on all of our significant accounting policies, see Note 1 &#8212; Summary of Significant Accounting Policies in the accompanying notes to the consolidated financial statements included in Part II, Item 8, ""Financial Statements and Supplementary Data"" of this Annual Report on Form 10-K. Loss Contingencies We are involved in legal proceedings, claims, and regulatory, tax or government inquiries and investigations that arise in the ordinary course of business. Certain of these matters include speculative claims for substantial or indeterminate amounts of damages. Additionally, we are required to comply with various legal and regulatory obligations around the world, and we regularly become subject to new laws and regulations in the jurisdictions in which we operate. ', 'Programs are designed and funded to support needs like autism care, cancer care, transgender services, holistic well-being, including mental health programs and retirement savings, which represent a few of the ways we support our employees and their dependents. Diverse and Inclusive Workplace We work to build a diverse and inclusive workplace where we can leverage our collective cognitive diversity to build the best products and make the best decisions for the global community we serve. In our 2023 Responsible Business Practices Report, we published our global diversity and U.S. ethnic diversity workforce data. As of December 31, 2022, our global employee base was composed of 45.4% underrepresented people, with 47.9% underrepresented people in the U.S., and 43.1% of our leaders in the U.S. being people of color. As published in our 2023 Responsible Business Practices Report, people with disabilities now represent 7.2% of our U.S. workforce, and based on voluntary self-identification, veterans represented 2.3% and members of the LGBTQ+ community make up 9.8% of our U.S. workforce. We want our products to work for people around the world and we need to grow and keep the best talent in order to do that. We also remain committed to having a skilled, inclusive and diverse workforce because we believe cognitive diversity fuels innovation. To aid in this effort, we have taken steps to reduce bias from our hiring processes and performance management systems, as well as offering learning and development courses for our employees. Corporate Information We were incorporated in Delaware in July 2004. We completed our initial public offering in May 2012 and our Class A common stock is currently listed on the Nasdaq Global Select Market under the symbol ""META."" Our principal executive offices are located at 1 Meta Way, Menlo Park, California 94025, and our telephone number is (650) 543-4800. Meta, the Meta logo, Meta Quest, Meta Horizon, Facebook, FB, Instagram, Oculus, WhatsApp, Reels, and our other registered or common law trademarks, service marks, or trade names appearing in this Annual Report on Form 10-K are the property of Meta Platforms, Inc. or its affiliates. Other trademarks, service marks, or trade names appearing in this Annual Report on Form 10&#8209;K are the property of their respective owners. Available Information Our Annual Reports on Form 10-K, Quarterly Reports on Form 10-Q, Current Reports on Form 8-K, and amendments to reports filed pursuant to Sections 13(a) and 15(d) of the Securities Exchange Act of 1934, as amended (Exchange Act), are filed with the U.S. Securities and Exchange Commission (SEC). We are subject to the informational requirements of the Exchange Act and file or furnish reports, proxy statements, and other information with the SEC. Such reports and other information filed by us with the SEC are available free of charge on our website at investor.fb.com when such reports are Table of Contents available on the SEC\'s website. We use our investor.fb.com and about.fb.com/news/ websites as well as Mark Zuckerberg\'s Facebook Page (www.facebook.com/zuck), Instagram account (www.instagram.com/zuck), and Threads profile (www.threads.net/zuck) as means of disclosing material non-public information and for complying with our disclosure obligations under Regulation FD. The SEC maintains an Internet site that contains reports, proxy and information statements, and other information regarding issuers that file electronically with the SEC at www.sec.gov. The contents of the websites referred to above are not incorporated into this filing. Further, our references to the URLs for these websites are intended to be inactive textual references only. Table of Contents ']",,
"['0a1faab8-a589-9b37-1c5a-00aa2c6047d3', '25c2084b-d2c7-2c1d-2bdf-5ac4b97e8d7e', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad', 'f49319ae-b60e-a439-3890-63db0fc3a737']","[""TSM and Jersey Mike's cook up multi-year esports partnership"", 'NVDA_7', 'AMD is quietly arming an entire new wave of Steam Deck competitors', 'The AMD Advancing AI & Instinct MI300 Launch Live Blog (Starts at 10am PT/18:00 UTC)']","['This morning is an important one for AMD – perhaps the most important of the year. After almost a year and a half of build-up, and even longer for actual development, AMD is launching their next generation GPU/APU/AI accelerator family, the Instinct MI300 series. Based on AMD\'s new CDNA 3 architecture, and combining it with AMD\'s proven Zen 4 cores, AMD will be making a full-court press for the high-end GPU and accelerator market with their new product, aiming to lead in both big-metal HPC as well as the burgeoning market for generative AI training and inference.\n\nTaking the stage for AMD\'s launch event will be AMD CEO Dr. LIsa Su, as well as a numerous AMD executives and ecosystem partners, to detail, at last, AMD\'s latest generation GPU architecture, and the many forms it will come in. With both the MI300X accelerator and MI300A APU, AMD is aiming to cover most of the accelerator market, whether clients just need a powerful GPU or a tightly-coupled GPU/CPU pairing.\n\nThe stakes for today\'s announcement are significant. The market for generative AI is all but hardware constrained at the moment, much to the benefit of (and profits for) AMD\'s rival NVIDIA. So AMD is hoping to capitalize on this moment to cut off a piece – perhaps a very big piece – of the market for generative AI accelerators. AMD has made breaking into the server space their highest priority over the last half-decade, and now, they believe, is their time to take a big piece of the server GPU market.\n\n12:56PM EST - We\'re here in San Jose for AMD\'s final and most important launch event of the year: Advancing AI\n\n12:57PM EST - Today AMD is making the eagerly anticipated launch of their next-generation MI300 series of accelerators\n\n12:58PM EST - Including MI300A, their first chiplet-based server APU, and MI300X, their stab at the most powerful GPU/accelerator possible for the AI market\n\n12:59PM EST - I\'d say the event is being held in AMD\'s backyard, but since AMD sold their campus here in the bay area several years ago, this is more like NVIDIA\'s backyard. Which is fitting, given that AMD is looking to capture a piece of the highly profitable Generative AI market from NVIDIA\n\n12:59PM EST - We\'re supposed to start at 10am local time here - so in another minute or so\n\n12:59PM EST - And hey, here we go. Right on time\n\n01:00PM EST - Starting with an opening trailer\n\n01:00PM EST - (And joining me on this morning\'s live blog is the always-awesome Gavin Bonshor)\n\n01:00PM EST - Advancing AI... together\n\n01:01PM EST - And here\'s AMD\'s CEO, Dr. Lisa Su\n\n01:01PM EST - Today ""is all about AI""\n\n01:01PM EST - And Lisa is diving right in\n\n01:02PM EST - It\'s only been just a bit over a year since ChatGPT was launched. And it\'s turned the computing industry on its head rather quickly\n\n01:02PM EST - AMD views AI as the single most transformative technology in the last 50 years\n\n01:02PM EST - And with a rather quick adoption rate, despite being at the very beginning of the AI era\n\n01:02PM EST - Lisa\'s listing off some of the use cases for AI\n\n01:03PM EST - And the key to it? Generative AI. Which requires significant investments in infrastructure\n\n01:03PM EST - (Which NVIDIA has captured the lion\'s share of thus far)\n\n01:03PM EST - In 2023 AMD projected the CAGR for the AI market would be $350B by 2027\n\n01:04PM EST - Now they think it\'s going to be $400B+ by 2027\n\n01:04PM EST - A greater than 70% compound annual growth rate\n\n01:04PM EST - AMD\'s AI strategy is centered around 3 big strategic priorities\n\n01:05PM EST - A broad hardware portfolio, an open and proven software ecosystem, and partnerships to co-innovate with\n\n01:05PM EST - (AMD has historically struggled with software in particular)\n\n01:05PM EST - Now to products, starting with the cloud\n\n01:06PM EST - Generative AI requires tens of thousands of accelerators at the high-end\n\n01:06PM EST - The more compute, the better the model, the faster the answers\n\n01:06PM EST - Launching today: AMD Instinct MI300X accelerator\n\n01:06PM EST - ""Highest performance accelerator in the world for generative AI""\n\n01:07PM EST - CDNA 3 comes wiht a new compute engine, sparsity support, industry-leading memory bandwidth and capacity, etc\n\n01:07PM EST - 3.4x more perf for BF16, 6.8x INT8 perf, 1.6x memory bandwidth\n\n01:07PM EST - 153B transistors for MI300X\n\n01:08PM EST - A dozen 5nm/6nm chiplets\n\n01:08PM EST - 4 I/O Dies in the base layer\n\n01:08PM EST - 256MB AMD Infinity Cache, Infinity Fabric Support, etc\n\n01:08PM EST - 8 XCD compute dies stacked on top\n\n01:08PM EST - 304 CDNA 3 compute units\n\n01:08PM EST - Wired to the IODs via TSVs\n\n01:09PM EST - And 8 stacks of HBM3 attached to the IODs, for 192GB of memory, 5.3 TB/second of bandwidth\n\n01:09PM EST - And immediately jumping to the H100 comparisons\n\n01:10PM EST - AMD has the advantage in memory capacity and bandwidth due to having more HBM stacks. And they think that\'s going to help carry them to victory over H100\n\n01:10PM EST - AMD finds they have the performance advantage in FlashAttention-2 and Llama 2 70B. At the kernel level in TFLOPS\n\n01:11PM EST - And how does MI300X scale?\n\n01:11PM EST - Comparing a single 8 accelerator server\n\n01:12PM EST - Bloom 176B (throughput) and Llama 2 70B (latency) inference performance.\n\n01:12PM EST - And now AMD\'s first guest of many, Microsoft\n\n01:13PM EST - MS CTO, Kevin Scott\n\n01:14PM EST - Lisa is asking Kevin for his thoughts on where the industry is on this AI journey\n\n01:15PM EST - Microsoft and AMD have been building the foundation for several years here\n\n01:16PM EST - And MS will be offering MI300X Azure instances\n\n01:16PM EST - MI300X VMs are available in preview today\n\n01:17PM EST - (So MS apparently already has a meaningful quanity of the accelerators)\n\n01:17PM EST - And that\'s MS. Back to Lisa\n\n01:17PM EST - Now talking about the Instinct platform\n\n01:18PM EST - Which is based on an OCP (OAM) hardware design\n\n01:18PM EST - (No fancy name for the platform, unlike HGX)\n\n01:18PM EST - So here\'s a whole 8-way MI300X board\n\n01:18PM EST - Can be dropped into almost any OCP-compliant design\n\n01:19PM EST - Making it easy to install MI300X\n\n01:19PM EST - And making a point that AMD supports all of the same I/O and networking capabilities of the competition (but with better GPUs and memory, of course)\n\n01:20PM EST - Customers are trying to maximize not just space, but capital expedetures and operational expedetures as well\n\n01:20PM EST - On the OpEx side, more memory means being able to run either more models or bigger models\n\n01:21PM EST - Which saves on CapEx expenses by buying fewer hardware units overall\n\n01:21PM EST - And now for the next partner, Oracle. Karan Batta, the SVP of Oracle Cloud Infrastructure\n\n01:22PM EST - Oracle is one of AMD\'s major cloud computing customers\n\n01:23PM EST - Oracle will be supporting MI300X as part of their bare metal compute offerings\n\n01:23PM EST - And MI300X in a generative AI service that is in the works\n\n01:24PM EST - Now on stage: AMD President Victor Peng to talk about software progress\n\n01:25PM EST - AMD\'s software stack is traditionally been their achilles heel, despite efforts to improve it. Peng\'s big project has been to finally get things in order\n\n01:25PM EST - Including building a unified AI software stack\n\n01:25PM EST - Today\'s focus is on ROCm, AMD\'s GPU software stack\n\n01:26PM EST - AMD has firmly attached their horse to open source, which they consider a huge benefit\n\n01:26PM EST - Improving ROCm support for Radeon GPUs continues\n\n01:26PM EST - ROMc 6 shipping later this month\n\n01:27PM EST - It\'s been optimized for generative AI, for MI300 and other hardware\n\n01:27PM EST - ""ROCm 6 delivers a quantum leap in performance and capability""\n\n01:28PM EST - Software perf optimization example with LLMs\n\n01:28PM EST - 2.6x from optimized libraries, 1.4x from HIP Graph, etc\n\n01:28PM EST - This, combined with hardware changes, is how AMD is delivering 8x more GenAI perf on MI300X versus MI250 (with ROCm 5)\n\n01:29PM EST - Recapping recent acquisitions as well, such as the nod AI compiler\n\n01:30PM EST - And on the ecosystem level, AMD has an increasing number of partners\n\n01:30PM EST - Hugging Face arguably being the most important, with 62K+ models up and running on AMD hardware\n\n01:31PM EST - AMD GPUs will be supported in the OpenAI Triton 3.0 release\n\n01:32PM EST - Now for more guests: Databricks, Essential AI, and Lamini\n\n01:33PM EST - The four of them are having a short chat about the AI world and their experience with AMD\n\n01:34PM EST - Talking about the development of major tools such as vLLM\n\n01:34PM EST - Cost is a huge driver\n\n01:36PM EST - It was very easy to incluide ROCm in Databricks\' stack\n\n01:36PM EST - Meanwhile Essential AI is taking a full stack approach\n\n01:37PM EST - The ease of use of AMD\'s software was ""very pleasant""\n\n01:38PM EST - And finally, Lamini\'s CEO, who has a PhD in Generative AI\n\n01:39PM EST - Customers get to fully own their models\n\n01:39PM EST - Imbuing LLNs with real knowledge\n\n01:39PM EST - Had an AMD cloud in production for over the past year on MI210s/MI250s\n\n01:40PM EST - Lamini has reached software parity with CUDA\n\n01:41PM EST - Many of the genAI tools available today are open source\n\n01:41PM EST - Many of them can run on ROCm today\n\n01:43PM EST - AMD\'s Instinct products are critical to supporting the future of business software\n\n01:46PM EST - And that\'s the mini-roundtable\n\n01:47PM EST - Summing up the last 6 months of work on software\n\n01:47PM EST - ROCm 6 shipping soon\n\n01:47PM EST - 62K models running today, and more coming soon\n\n01:48PM EST - And that\'s a wrap for Victor Peng. Back to Lisa Su\n\n01:49PM EST - And now for another guest spot: Meta\n\n01:49PM EST - Ajit Mathews, Sr. Director of Engineering at Meta AI\n\n01:50PM EST - Meta opened access to the Llama 2 model family in July\n\n01:50PM EST - ""An open approach leads to better and safer technology in the long-run""\n\n01:51PM EST - Meta has been working with EPYC CPUs since 2019. And recently deployed Genoa at scale\n\n01:51PM EST - But that partnership is much broader than CPUs\n\n01:52PM EST - Been using the Instinct since 2020\n\n01:53PM EST - And Meta is quite excited about MI300\n\n01:53PM EST - Expanding their partnership to include Instinct in Facebook\'s datacenters\n\n01:53PM EST - MI300X is one of their fastest design-to-deploy projects\n\n01:54PM EST - And Meta is pleased with the optimizations done for ROCm\n\n01:55PM EST - (All of these guests are here for a reason: AMD wants to demonstate that their platform is ready. That customers are using it today and are having success with it)\n\n01:55PM EST - Now another guest: Dell\n\n01:56PM EST - Arthur Lewer, President of Core Business Operations for the Global Infrastrucutre Solutions Group\n\n01:56PM EST - (Buying NVIDIA is the safe bet; AMD wants to demonstrate that buying AMD isn\'t an unsafe bet)\n\n01:57PM EST - Customers need a better solution than today\'s ecosystem\n\n01:58PM EST - Dell is announcing an update to the Poweredge 9680 servers. Now offering them with MI300X accelerators\n\n01:58PM EST - Up to 8 accelerators in a box\n\n01:58PM EST - Helping customers consolidate LLM training to fewer boxes\n\n01:59PM EST - Ready to quote and taking orders today\n\n02:01PM EST - And that\'s Dell\n\n02:02PM EST - And here\'s another guest: Supermicro (we\'ve now pivoted from cloud to enterprise)\n\n02:02PM EST - Charles Liang, Founder, President, and CEO of Supermicro\n\n02:03PM EST - Supermicro is a very important AMD server partner\n\n02:05PM EST - What does Supermicro have planned for MI300X?\n\n02:05PM EST - 8U air cooled system, and 4U system with liquid cooling\n\n02:05PM EST - Up to 100kW racks of the latter\n\n02:05PM EST - And that\'s Supermicro\n\n02:06PM EST - And another guest: Lenovo\n\n02:06PM EST - Kirk Skaugen, President of Lenovo\'s Infrastructure Solutions Group\n\n02:07PM EST - Lenovo believes that genAI will be a hybrid approach\n\n02:07PM EST - And AI will be needed at the edge\n\n02:08PM EST - 70 AI-ready server and infrastructure products\n\n02:09PM EST - Lenovo also has an AI innovators program for key verticals for simplifying things for customers\n\n02:10PM EST - Lenovo thinks inference will be the dominate AI workload. Training only needs to happen once; inference happens all the time\n\n02:11PM EST - Lenovo is bring MI300X to their ThinkSystem platform\n\n02:11PM EST - And available as a service\n\n02:12PM EST - And that\'s Lenovo\n\n02:13PM EST - And that\'s still just the tip of the iceberg for the number of partners AMD has lined up for Mi300X\n\n02:13PM EST - And now back to AMD with Forrest Norrod to talk about networking\n\n02:14PM EST - The compute required to train the most advanced models has increased by leaps and bounds over the last decade\n\n02:14PM EST - Leading AI clusters are tens-of-thousands of GPUs, and that will only increase\n\n02:14PM EST - So AMD has worked to scale things up on multiple fronts\n\n02:14PM EST - Internally with Infinity Fabric\n\n02:15PM EST - Near-linear scaling performance as you increase the number of GPUs\n\n02:15PM EST - AMD is extending access to Infinity Fabric to innovators and strategic partners across the industry\n\n02:15PM EST - We\'ll hear more about this initiative next year\n\n02:16PM EST - Meanwhile the back-end network connecting the servers together is just as critical\n\n02:16PM EST - And AMD believes that network needs to be open\n\n02:17PM EST - And AMD is backing Ethernet (as opposed to InfiniBand)\n\n02:17PM EST - And Ethernet is open\n\n02:18PM EST - Now coming to the stage are a few netowrking leaders, including Arista, Broadcom, and Cisco\n\n02:19PM EST - Having a panel discussion on Ethernet\n\n02:21PM EST - What are the advantages of Ethernet for AI?\n\n02:22PM EST - Majority of hyperscalers are using Ethernet or have a high desire to\n\n02:23PM EST - The NIC is critical. People want choices\n\n02:24PM EST - ""We need to continue to innovate""\n\n02:24PM EST - AI networks need to be open standards based. Customers need choices\n\n02:25PM EST - Ultra Ethernet is a critical next step\n\n02:26PM EST - https://www.anandtech.com/show/18965/ultra-ethernet-consortium-to-adapt-ethernet-for-ai-and-hpc-needs\n\n02:28PM EST - UEC is solving a very important technical problem of modern RDMA at scale\n\n02:28PM EST - And that\'s the networking panel\n\n02:28PM EST - Now on to high-performance computing (HPC)\n\n02:29PM EST - Recapping AMD\'s experience thus far, including the most recent MI250X\n\n02:29PM EST - MI250X + EPYC had a coherent memory space, but still the GPU and CPU separated by a somewhat slow link\n\n02:29PM EST - But now MI300A is here with a unified memory system\n\n02:29PM EST - Volume production began earlier this quarter\n\n02:30PM EST - MI300 architecture, but with 3 Zen 4 CCDs layered on top of some of the IODs\n\n02:31PM EST - 128GB of HBM3 memory, 4 IODs, 6 XCDs, 3 CCDs\n\n02:31PM EST - And truly unified memory, as both GPU and CPU tiles go through the shared IODs\n\n02:32PM EST - Performance comparisons with H100\n\n02:32PM EST - 1.8x the FP64 and FP32 (vector?) performance\n\n02:33PM EST - 4x performnace on OpenFOAM with MI300A versus H100\n\n02:33PM EST - Most of the improvement comes from unified memory, avoiding having to copy around memory before it can be used\n\n02:34PM EST - 2x the perf-per-watt than Grace Hopper (unclear by what metric)\n\n02:35PM EST - MI300A will be in the El Capitan supercomputer. Over 2 EFLOPS of FP64 compute\n\n02:35PM EST - Now rolling a video from HPE and the Lawrence Livermore National Lab\n\n02:35PM EST - ""El Capitan will be the most capable AI machine""\n\n02:36PM EST - El Capitan will be 16x faster than LLNL\'s current supercomputer\n\n02:37PM EST - And now another guest on stage: HPE\n\n02:37PM EST - Trish Damkroger, SVP and Chief Product Officer\n\n02:38PM EST - Frontier was great. El Capitan will be even better\n\n02:39PM EST - AMD and HPE power a large number of the most power efficient supercomputers\n\n02:40PM EST - (Poor Forrest is a bit tongue tied)\n\n02:40PM EST - ElCap will have MI300A nodes with SlingShot fabric\n\n02:41PM EST - One of the most capable AI systems in the world\n\n02:41PM EST - Supercomputing is the foundation needed to run AI\n\n02:42PM EST - And that\'s HPE\n\n02:43PM EST - MI300A: A new level of high-performance leadership\n\n02:43PM EST - MI300A systems avaialble soon from partners around the world\n\n02:43PM EST - (So it sounds like MI300A is trailing MI300X by a bit)\n\n02:43PM EST - Now back to Lisa\n\n02:44PM EST - To cap off the day: Advancing AI PCs\n\n02:44PM EST - AMD started including NPUs this year with the Ryzen Mobile 7000 series. The first x86 company to do so\n\n02:44PM EST - Using AMD\'s XDNA architecture\n\n02:45PM EST - A large computing array that is extremely performant and efficient\n\n02:45PM EST - Shipped millions of NPU-enabled PCs this year\n\n02:46PM EST - Showing off some of the software applications out there that offer AI acceleration\n\n02:46PM EST - Adobe, Windows studio effects, etc\n\n02:46PM EST - Announcing Ryzen AI 1.0 software for developers\n\n02:46PM EST - So AMD\'s software SDK is finally available\n\n02:47PM EST - Deploy tained and quantized models using ONNX\n\n02:47PM EST - Announcing Ryzen Mobile 8040 series processors\n\n02:47PM EST - Hawk Point\n\n02:47PM EST - This is (still) the Phoenix die\n\n02:48PM EST - With one wrinkle: faster AI performance thanks to a higher clocked NPU\n\n02:48PM EST - AMD\'s own perf benchmarks show 1.4x over 7040 series\n\n02:48PM EST - Now time for another guest: Microsoft\n\n02:49PM EST - Pavan Davuluri, CVP for Windows and Devices\n\n02:49PM EST - Talking about the work AMD and MS are doing together for client AI\n\n02:50PM EST - Microsoft\'s marquee project is Copilot\n\n02:52PM EST - MS wants to be able to load-shift between the cloud and the client. Seamless computing between the two\n\n02:52PM EST - Showing AMD\'s NPU roadmap\n\n02:53PM EST - Next-gen Strix Point processors in the works. Using a new NPU based on XDNA 2\n\n02:53PM EST - Launching in 2024\n\n02:53PM EST - XDNA 2 designed for ""leadership"" AI performance\n\n02:53PM EST - AMD has silicon. So does MS\n\n02:54PM EST - More than 3x the genAI perf (versus Hawk Point?)\n\n02:55PM EST - And that\'s AI on the PC\n\n02:55PM EST - Now recapping today\'s announcements\n\n02:55PM EST - MI300X, shipping today. MI300A, in volume production\n\n02:55PM EST - Ryzen Mobile 8040 Series, shipping now\n\n02:56PM EST - ""Today is an incredibly proud moment for AMD""\n\n02:57PM EST - And that\'s it for Lisa, and for today\'s presentation\n\n02:58PM EST - Thanks for joining us, and be sure to check out our expanded coverage of AMD\'s announcements\n\n02:58PM EST - https://www.anandtech.com/show/21177/amd-unveils-ryzen-8040-mobile-series-apus-hawk-point-with-zen-4-and-ryzen-ai\n\n02:58PM EST - https://www.anandtech.com/show/21178/amd-widens-availability-of-ryzen-ai-software-for-developers-xdna-2-coming-with-strix-point-in-2024', 'TSM, the premier championship esports organization, and Jersey Mike’s, known for its fresh sliced/fresh grilled subs, have set a three-year, North American partnership, making Jersey Mike\'s the official Sub Sandwich of TSM.\n\nWhile the key ingredients of branding and content production are baked in to the partnership, this made-to-order deal brings TSM and Jersey Mike\'s fans alike loads of meaty offerings, including:\n\n● A freshly-made fan sweepstakes offering the chance to win epic prizes\n\n● The tasty “Subs for Subs” initiative where Jersey Mike\'s will gift thousands of subscriptions and free subs to up-and-coming Twitch streamers to grow their audiences and support their dreams of becoming full time content creators.\n\n● A custom crafted Jersey Mike\'s Blitz Arena on TSM\'s esports coaching app Blitz\n\nAnd in keeping with both organizations’ desires to give back to their community, this collaboration also funds a unique, first-of-its-kind internship program. Students from TSM partner campuses, Jersey Mike\'s university partners and HBCUs will have the opportunity for hands-on experience in the gaming business including working at an esports-focused event.\n\n“This partnership stands for everything our fans crave- and it will leave them hungry for more!” said TSM CRO Stephan Cieplik. “Jersey Mike\'s commitment to quality and excellence aligns with our own values at TSM, and we look forward to bringing this partnership to life with authentic activations to engage with our fans, gamers and streamers.”\n\n“TSM is a leader in the esports industry and we are honored to partner with them,"" said Rich Hope, Chief Marketing Officer, Jersey Mike’s Franchise Systems, Inc. “We are excited to bring our delicious subs to the TSM community and support the next generation of esports stars through our internship program.”\n\nAbout TSM\n\nTSM is an elite, holistic gaming brand composed of championship esports teams, world-class influencers, and gaming strategy platforms that level up the casual player all the way to the professional. A platform of champions, TSM seeks to provide maximum value through the competitive excellence of its teams and the creation of exciting, educational, and entertaining content that deliver the ultimate esports and gaming fan experience. For more: tsm.gg.\n\nAbout Jersey Mike’s Subs\n\nJersey Mike’s Subs, with nearly 2,500 locations nationwide, serves authentic fresh sliced/fresh grilled subs on in-store freshly baked bread — the same recipe it started with in 1956. Passion for giving in Jersey Mike’s local communities is reflected in its mission statement “Giving…making a difference in someone’s life.” For more information, please visit jerseymikes.com or follow us on Facebook, Instagram, and Twitter.', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'You’ve obviously heard of the Steam Deck, and perhaps Asus drew your attention to the upcoming ROG Ally with its not-an-April-Fools’-joke. But that’s apparently just the tip of the iceberg for AMD-powered Steam Deck rivals, which have at least four handhelds based on slivers of silicon the chipmaker has yet to reveal.\n\nOne of the reasons we got so excited about the Asus ROG Ally is that Asus hinted it might be the first handheld since Steam Deck to offer a custom part specifically tuned for portables — and a growing body of leaks suggests that collaboration with AMD is called the Ryzen Z1.\n\nAnd today, Geekbench leaks (which should always be taken with a grain of salt) suggest Asus may actually be using two such chips: a six-core, 12-thread Ryzen Z1 with two RDNA 3 graphics compute units (CUs) and an eight-core, 16-thread Ryzen Z1 Extreme with six RNDA3 CUs, which could have higher performance and power consumption.\n\nBut get this. A shipping manifest spotted by VideoCardz also shows an ROG Ally with another unannounced name: the Ryzen 7 7840U, a 3.3GHz chip with Radeon 780M graphics that’s suspected to be all but identical to that Z1 Extreme.\n\nAnd that Ryzen 7 7840U appears to be very much not exclusive to Asus — it has now been tipped for the Aokzoe A1 Pro, an unannounced Ayaneo 2S, and a GPD Win Mini clamshell, according to rumors and leaks.\n\nThis wouldn’t be the first time those boutique portable PC makers have attempted to challenge the Steam Deck. A year ago, I wrote how they were all gearing up with the off-the-shelf AMD 6800U laptop chip, which sadly didn’t turn out to be efficient enough for a competent portable. (Read my Ayaneo 2 review for details.)\n\nBut Aokzoe, at least, seems pretty confident that it can match the Steam Deck with a 7840U: it’s been posting video after video of its A1 Pro’s performance to YouTube, including one tiny clip where the A1 Pro is running the same game at the same processor wattage and with similar battery drain to the Steam Deck and still manages to run notably faster.\n\nIf that’s what a 7840U can do, I’m heartened. (It wouldn’t be too much of a surprise considering we’re looking at Zen 4 and RDNA 3 instead of the Zen 2 and RDNA 2 in the Steam Deck’s Aerith chip.)\n\nBut it’s just a tiny glimpse for now, and we don’t know whether any of these companies can hit the right price with these chips or get Microsoft’s help to turn Windows into something easy and comfortable to use on a gaming handheld. And AMD didn’t immediately respond to a request for this story.\n\nAnother thing that heartens me, though:\n\nLast July, when I reached out to my AMD PR contacts about handheld gaming PCs, they told me they didn’t even have a contact who could handle such a request, adding:\n\nWe do not have any further details to share at this time regarding AMD chips in handheld gaming PCs. We’ll certainly be in touch with news and opportunities as it relates to AMD in the future but unfortunately at this time are not able to connect you directly.']",,
"['22f41c3d-ab20-b88e-0433-453a5447809b', '83399df2-a92b-3ab9-ff16-73f724743c0a', 'adfada1a-9035-2536-c50b-c83d3f18a36a', 'ba4ed5b4-450d-656d-5897-9dcc8f11851b', 'd8934572-b4ab-7b73-e2b0-fd72bf732bad']","['AMD_1', 'AMD_1A', 'NVDA_7', 'Testing Meta Verified to Help Creators Establish Their Presence', 'NVDA_1']","['ITEM 1A. RISK FACTORS The risks and uncertainties described below are not the only ones we face. If any of the following risks actually occurs, our business, financial condition or results of operations could be materially adversely affected. In addition, you should consider the interrelationship and compounding effects of two or more risks occurring simultaneously. Risk Factors Summary The following is a summary of the principal risks that could adversely affect our business, financial condition and results of operations. Economic and Strategic Risks &#8226; Intel Corporation&#8217;s dominance of the microprocessor market and its aggressive business practices may limit our ability to compete effectively on a level playing field. &#8226; Economic and market uncertainty may adversely impact our business and operating results. &#8226; The semiconductor industry is highly cyclical and has experienced severe downturns. &#8226; The demand for our products depends in part on the market conditions in the industries into which they are sold. There may be fluctuations in demand for our products or a market decline in any of these industries. &#8226; The loss of a significant customer may have a material adverse effect on us. &#8226; We are subject to risks associated with public health crises, such as pandemics and epidemics. &#8226; The markets in which our products are sold are highly competitive. &#8226; Our operating results are subject to quarterly and seasonal sales patterns. &#8226; If we cannot adequately protect our technology or other intellectual property through patents, copyrights, trade secrets, trademarks and other measures, we may lose a competitive advantage and incur significant expenses. &#8226; Unfavorable currency exchange rate fluctuations could adversely affect us. Operational and Technology Risks &#8226; We rely on third parties to manufacture our products, and if they are unable to do so on a timely basis in sufficient quantities and using competitive technologies, our business could be materially adversely affected. &#8226; Essential equipment, materials, substrates or manufacturing processes may not be available to us. &#8226; We may fail to achieve expected manufacturing yields for our products. &#8226; The success of our business is dependent upon our ability to introduce products on a timely basis with features and performance levels that provide value to our customers while supporting significant industry transitions. &#8226; Our revenue from our semi-custom System-on-Chip (SoC) products is dependent upon our semi-custom SoC products being incorporated into customers&#8217; products and the success of those products. &#8226; Our products may be subject to security vulnerabilities that could have a material adverse effect on us. &#8226; IT outages, data loss, data breaches and cyberattacks could disrupt operations and compromise our intellectual property or other sensitive information, be costly to remediate or cause significant damage to our business, reputation, financial condition and results of operations. &#8226; We may encounter difficulties in operating our newly upgraded enterprise resource planning (ERP) system. &#8226; Uncertainties involving the ordering and shipment of our products could materially adversely affect us. &#8226; Our ability to design and introduce new products includes the use of third-party intellectual property. &#8226; We depend on third-party companies for the design, manufacture and supply of motherboards, software, memory and other computer platform components to support our business and products. &#8226; If we lose Microsoft Corporation&#8217;s support for our products or other software vendors do not design and develop software to run on our products, our ability to sell our products could be materially adversely affected. &#8226; Our reliance on third-party distributors and add-in-board (AIB) partners subjects us to certain risks. &#8226; Our business depends on the proper functioning of our internal business processes and information systems. &#8226; Our products may not be compatible with some or all industry-standard software and hardware. &#8226; Costs related to defective products could have a material adverse effect on us. &#8226; We may fail to maintain the efficiency of our supply chain as we respond to changes in customer demand. &#8226; We outsource to third parties certain supply-chain logistics functions. &#8226; We may be unable to effectively control the sales of our products on the gray market. &#8226; Climate change may have a long-term impact on our business. Legal and Regulatory Risks &#8226; Government actions and regulations may limit our ability to export our products to certain customers. &#8226; If we cannot realize our deferred tax assets, our results of operations could be adversely affected. &#8226; Our business is subject to potential tax liabilities, including as a result of tax regulation changes. &#8226; We are party to litigation and may become a party to other claims or litigation. &#8226; We are subject to environmental laws, conflict minerals-related provisions of the Dodd-Frank Wall Street Reform and Consumer Protection Act, and other laws or regulations that could result in additional costs and liabilities. &#8226; Evolving expectations from governments, investors, customers and other stakeholders regarding corporate responsibility matters could result in additional costs, harm to our reputation and a loss of customers. &#8226; Issues related to the responsible use of AI may result in reputational, competitive and financial harm and liability. Merger, Acquisition and Integration Risks &#8226; Acquisitions, joint ventures, and/or investments, and the failure to integrate acquired businesses may fail to materialize their anticipated benefits and disrupt our business. &#8226; Any impairment of our tangible, definite-lived intangible or indefinite-lived intangible assets, including goodwill, may adversely impact our financial position and results of operations. Liquidity and Capital Resources Risks &#8226; The agreements governing our notes, our guarantees of Xilinx&#8217;s notes, and our Revolving Credit Agreement impose restrictions on us that may adversely affect our ability to operate our business. &#8226; Our indebtedness could adversely affect our financial position and prevent us from implementing our strategy or fulfilling our contractual obligations. &#8226; We may not generate sufficient cash to meet our working capital requirements. If we cannot generate sufficient revenue and operating cash flow, we may face a cash shortfall. Also, our cash and cash equivalents could be adversely affected if the financial institutions in which we hold our cash and cash equivalents fail. General Risks &#8226; Our worldwide operations are subject to political, legal and economic risks and natural disasters. ', 'Our policy is to include interest and penalties related to unrecognized tax benefits as a component of income tax expense. Revenue Recognition Revenue Allowances For products sold with a right of return, we record a reduction to revenue by establishing a sales return allowance for estimated product returns at the time revenue is recognized, based primarily on historical return rates. However, if product returns for a fiscal period are anticipated to exceed historical return rates, we may determine that additional sales return allowances are required to reflect our estimated exposure for product returns. Return rights for certain stocking distributors for specific products are contractually limited based on a percentage of prior quarter shipments. For shipments to other customers, we do not allow returns, although we may approve returns for credit or refund based on applicable facts and circumstances. We account for customer programs, which involve rebates and marketing development funds, as a reduction in revenue and accrue for such programs based on the amount we expect to be claimed by customers. Certain customer programs include distributor price incentives or other channel programs for specific products and customer classes which require judgement as to whether the applicable incentives will be attained. Estimates for customer program accruals include a combination of historical attainment and claim rates and may be adjusted based on relevant internal and external factors. License and Development Arrangements Revenue from License and Development Arrangements is recognized over the period in which the development services are performed. Each fiscal reporting period, we measure progress to completion based on actual cost incurred to date as a percentage of the estimated total cost required to complete each project. Estimated total cost for each project includes a forecast of internal engineer personnel time expected to be incurred and other third-party costs as applicable. Contracts with Multiple Performance Obligations Our contracts may contain more than one performance obligation. Judgement is required in determining whether each performance obligation within a customer contract is distinct. Except for License and Development Arrangements, NVIDIA products and services function on a standalone basis and do not require a significant amount of integration or interdependency. Therefore, multiple performance obligations contained within a customer contract are considered distinct and are not combined for revenue recognition purposes. We allocate the total transaction price to each distinct performance obligation in a multiple performance obligations arrangement on a relative standalone selling price basis. In certain cases, we can establish standalone selling price based on directly observable prices of products or services sold separately in comparable circumstances to similar customers. If standalone selling price is not directly observable, such as when we do not sell a product or service separately, we determine standalone selling price based on market data and other observable inputs. Change in Accounting Estimate In February 2023, we assessed the useful lives of our property, plant, and equipment. Based on advances in technology and usage rate, we increased the estimated useful life of a majority of the server, storage, and network equipment from three years to a range of four to five years, and assembly and test equipment from five years to seven years. The estimated effect of this change for fiscal year 2024 was a benefit of $33 million and $102 million for cost of revenue and operating expenses, respectively, which resulted in an increase in operating income of $135 million and net income of $114 million after tax, or $0.05 per both basic and diluted share. Results of Operations A discussion regarding our financial condition and results of operations for fiscal year 2024 compared to fiscal year 2023 is presented below. A discussion regarding our financial condition and results of operations for fiscal year 2023 compared to fiscal year 2022 can be found under Item 7 in our Annual Report on Form 10-K for the fiscal year ended January 29, 2023, filed with the SEC on February 24, 2023, which is available free of charge on the SEC&#8217;s website at http://www.sec.gov and at our investor relations website, http://investor.nvidia.com. The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue. ##TABLE_START &#160; Year Ended &#160; Jan 28, 2024 Jan 29, 2023 Revenue 100.0 % 100.0 % Cost of revenue 27.3 43.1 Gross profit 72.7 56.9 Operating expenses &#160; Research and development 14.2 27.2 Sales, general and administrative 4.4 9.1 Acquisition termination cost &#8212; 5.0 Total operating expenses 18.6 41.3 Operating income 54.1 15.6 Interest income 1.4 1.0 Interest expense (0.4) (1.0) Other, net 0.4 (0.1) Other income (expense), net 1.4 (0.1) Income before income tax 55.5 15.5 Income tax expense (benefit) 6.6 (0.7) Net income 48.9 % 16.2 % ##TABLE_END Reportable Segments Revenue by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 47,405 $ 15,068 $ 32,337 215 % Graphics 13,517 11,906 1,611 14 % Total $ 60,922 $ 26,974 $ 33,948 126 % ##TABLE_END Operating Income by Reportable Segments ##TABLE_START Year Ended Jan 28, 2024 Jan 29, 2023 $ Change % Change ($ in millions) Compute &#38; Networking $ 32,016 $ 5,083 $ 26,933 530 % Graphics 5,846 4,552 1,294 28 % All Other (4,890) (5,411) 521 (10) % Total $ 32,972 $ 4,224 $ 28,748 681 % ##TABLE_END Compute &#38; Networking revenue &#8211; The year-on-year increase was due to higher Data Center revenue. Compute grew 266% due to higher shipments of the NVIDIA Hopper GPU computing platform for the training and inference of LLMs, recommendation engines and generative AI applications. Networking was up 133% due to higher shipments of InfiniBand. Graphics revenue &#8211; The year-on-year increase was led by growth in Gaming of 15% driven by higher sell-in to partners following the normalization of channel inventory levels. Reportable segment operating income &#8211; The year-on-year increase in Compute &#38; Networking and Graphics operating income was driven by higher revenue. All Other operating loss - The year-on-year decrease was due to the $1.4 billion Arm acquisition termination cost in fiscal year 2023, partially offset by a $839 million increase in stock-based compensation expense in fiscal year 2024. ', 'Update on June 27, 2023 at 7:30 AM PT:\n\nWe’re excited to begin rolling out Meta Verified to most markets globally over the coming months.\n\nWe’ve heard positive feedback from creators in our initial tests and continue to gather input about what’s most valuable for subscribers. We’ll continue to evolve Meta Verified based on these learnings and explore new features and benefits that create more value for subscribers.\n\nUpdate on June 7, 2023 at 7:30 AM PT:\n\nMeta Verified is now available in India and will soon be available in Brazil.\n\nUpdate on May 31, 2023 at 9:00 AM PT:\n\nMeta Verified is now available in Canada.\n\nUpdate on May 16, 2023 at 7:40 AM PT:\n\nMeta Verified is now available in the United Kingdom.\n\nUpdate on March 17, 2023 at 11 AM PT:\n\nWe’re expanding our test of Meta Verified to the US after seeing good results from our early testing. This test in the US will reflect some initial learnings and feedback. We’re removing increased reach as a subscription feature for now, as we gather more feedback and further evolve Meta Verified. We’re exploring elements to add to the subscription as we roll out to more places and will share more when we’re ready.\n\nOriginally published on February 19, 2023 at 12 PM PT:\n\nTo help up-and-coming creators grow their presence and build community faster, today Mark Zuckerberg announced that we’ll begin testing a new offering called Meta Verified, a subscription bundle on Instagram and Facebook that includes a verified badge that authenticates your account with government ID, proactive account protection, access to account support, and increased visibility and reach. We’re starting with a gradual test in Australia and New Zealand later this week to learn what’s most valuable, and we hope to bring Meta Verified to the rest of the world soon.\n\nSome of the top requests we get from creators are for broader access to verification and account support, in addition to more features to increase visibility and reach. Since last year, we’ve been thinking about how to unlock access to these features through a paid offering.\n\nWith Meta Verified, you’ll get:\n\nA verified badge, confirming you’re the real you and that your account has been authenticated with a government ID.¹\n\nMore protection from impersonation with proactive account monitoring for impersonators who might target people with growing online audiences.\n\nHelp when you need it with access to a real person for common account issues.\n\nIncreased visibility and reach with prominence in some areas of the platform– like search, comments and recommendations.²\n\nExclusive features to express yourself in unique ways.³\n\nMeta Verified is available for direct purchase on Instagram or Facebook in Australia and New Zealand starting later this week. People can purchase a monthly subscription for (USD) $11.99 on the web and (USD) $14.99 on iOS and Android.4\n\nAs we test and learn, there will be no changes to accounts on Instagram and Facebook that are already verified based on prior requirements. Long term, we want to build a subscription offering that’s valuable to everyone, including creators, businesses and our community at large. As part of this vision, we are evolving the meaning of verified accounts on our apps so we can expand access to verification and more people can trust the accounts they interact with are authentic.\n\nBuilding Safety from the Beginning\n\nIt’s important to feel confident that your identity and accounts are safe and that the people you’re interacting with are who they say they are. That’s why we’re building a series of checks into Meta Verified before, during, and after someone applies.\n\nTo be eligible, accounts must meet minimum activity requirements, such as prior posting history, and be at least 18 years old .\n\nApplicants are then required to submit a government ID that matches the profile name and photo of the Facebook or Instagram account they’re applying for .\n\nSubscriptions will include proactive monitoring for account impersonation.\n\nWe’re also committed to continuous monitoring and review of reported violations, as well as taking swift action against those who try to evade our systems.\n\nTo learn more about Meta Verified visit Mark Zuckerberg’s Meta Channel on Instagram on your mobile device.\n\n1. Where available, some subscribers may be required to submit a selfie video as part of the authentication process.\n\n2. We’ll offer exclusive stickers on Facebook and Instagram Stories and Facebook Reels, and 100 free stars a month on Facebook so you can show your support for other creators.\n\n3. AUD 19.99 on web, AUD 24.99 on iOS and Android. NZD 23.99 on web, NZD 29.99 on iOS and Android. Subscription features are the same for both web and app purchases.\n\n4. Businesses are not eligible to apply for Meta Verified at this time.', 'Original Equipment Manufacturers We focus on three types of OEM partners: multi-nationals, selected regional accounts and selected global and local system integrators, who target commercial and consumer end customers of all sizes. Large multi-nationals and regional accounts are the core of our OEM partners&#8217; business; however, we are increasingly focused on the VAR channel which resells OEM systems to the mid-market and the small and medium business (SMB) segments. Additionally, we have increased our focus on global system integrators, which resell OEM systems, coupled with their software and services solutions into Enterprise, high performance computing (HPC) and Cloud Service Provider customers. Our OEM customers include numerous foreign and domestic manufacturers of servers and workstations, desktops, notebooks, PC motherboards and game consoles. Hyperscale Data Centers Large multi-national public cloud service providers and hyperscale private data centers directly and indirectly purchase a substantial portion of our data center-focused products, including server CPUs, GPU accelerators, DPUs, FPGAs and Adaptive SOCs. These products are incorporated into servers and other data center appliances sold by OEMs to the hyperscale customers or into custom servers or hardware designed by or for these customers and manufactured by ODMs or contract manufacturers. Hyperscale data centers use these products to operate web-based applications or to support public cloud computing and storage service offerings, including but not limited to AI workloads such as generative AI models. Third-Party Distributors Our authorized channel distributors resell to sub-distributors and OEMs, ODMs, and other customers. Typically, distributors handle a wide variety of products, and may include products from other manufacturers that compete with our products. Distributors typically maintain an inventory of our products. In most instances, our agreements with distributors protect their inventory of our products against price reductions and provide certain return rights with respect to any product that we have removed from our price book or otherwise subject to discontinuation. In addition, some agreements with our distributors may contain standard stock rotation provisions permitting limited product returns. Add-in-Board (AIB) Manufacturers and System Integrators We offer component-level graphics and chipset products to AIB manufacturers who in turn build and sell board-level products using our technology to system integrators (SIs), retail buyers and sub distributors. Our agreements with AIBs protect their inventory of our products against price reductions. We also sell directly to our SI customers. SIs typically sell from positions of regional or product-based strength in the market. They usually operate on short design cycles and can respond quickly with new technologies. SIs often use discrete graphics solutions as a means to differentiate their products and add value to their customers. Competition The markets in which our products are sold are highly competitive and delivering the latest and best products to market on a timely basis is critical to achieving revenue growth. We believe that the main factors that determine our product competitiveness are total cost of ownership, timely product introductions, product quality, product features and capabilities (including accelerations for key workloads such as AI, energy efficiency (including power consumption and battery life, given their impact on total cost of ownership), reliability, processor clock speed, performance, size (or form factor), selling price, cost, adherence to industry standards (and the creation of open industry standards), level of integration, software and hardware compatibility, ease of use and functionality of software design tools, completeness of applicable software solutions, security and stability, brand recognition and availability. We expect that competition will continue to be intense due to rapid technological changes, frequent product introductions by our competitors or new competitors of products that may provide better performance or experience or that may include additional features that render our products comparatively less competitive. Competition in Data Center Segment In Data Center, we compete against Intel Corporation (Intel) and NVIDIA Corporation (NVIDIA) with our CPU, GPU and DPU server products. In addition, we compete against Intel with our FPGA and Adaptive SoC server products. A variety of smaller fabless silicon companies offer proprietary accelerator solutions and ARM based CPUs targeting data center use-cases. In addition, some of our customers are internally developing their own data center microprocessor products and accelerator products which could impact the available market for our products. Competition in Client Segment Our primary competitor in the supply of CPUs and APUs is Intel. A variety of companies provide or have developed ARM-based microprocessors and platforms. ARM-based designs are being used in the PC market, which could lead to further growth and development of the ARM ecosystem. Competition in Gaming Segment In the graphics market, our principal competitor in the supply of discrete graphics is NVIDIA, who is the market share leader, and Intel, who manufactures and sells integrated graphics processors and gaming-focused discrete GPUs. With respect to integrated graphics, higher unit shipments of our APUs and Intel&#8217;s integrated graphics may drive computer manufacturers to reduce the number of systems they build paired with discrete graphics components, particularly for notebooks, because they may offer satisfactory graphics performance for most mainstream PC users at a lower cost. We are the market share leader in semi-custom game console products, where graphics performance is critical. Competition in Embedded Segment We expect continued competition from our primary FPGA competitors such as Intel, Lattice Semiconductor Corporation and Microsemi Corporation (Microsemi, acquired by Microchip), from ASSP vendors such as Broadcom Corporation, Marvell Technology Group, Ltd., Analog Devices, Texas Instruments Incorporated and NXP Semiconductors N.V., and from NVIDIA. In addition, we expect continued competition from the ASIC market, which has been ongoing since the inception of FPGAs. Intel is our main competitor for embedded CPUs. Other competitors include manufacturers of high-density programmable logic products characterized by FPGA-type architectures; high-volume and low-cost FPGAs as programmable replacements for ASICs and ASSPs; ASICs and ASSPs with incremental amounts of embedded programmable logic; high-speed, low-density complex programmable logic devices (CPLDs); high-performance digital signal processing (DSP) devices; products with embedded processors; products with embedded multi-gigabit transceivers; discrete general-purpose GPUs targeting data center and automotive applications; and other new or emerging programmable logic products . Research and Development We focus our research and development (R&#38;D) activities on designing and developing products. ', 'In addition, generative AI is expanding the market for our workstation-class GPUs, as more enterprise customers develop and deploy AI applications with their data on-premises. Headquartered in Santa Clara, California, NVIDIA was incorporated in California in April 1993 and reincorporated in Delaware in April 1998. Our Businesses We report our business results in two segments. The Compute &#38; Networking segment is comprised of our Data Center accelerated computing platforms and end-to-end networking platforms including Quantum for InfiniBand and Spectrum for Ethernet; our NVIDIA DRIVE automated-driving platform and automotive development agreements; Jetson robotics and other embedded platforms; NVIDIA AI Enterprise and other software; and DGX Cloud software and services. The Graphics segment includes GeForce GPUs for gaming and PCs, the GeForce NOW game streaming service and related infrastructure; Quadro/NVIDIA RTX GPUs for enterprise workstation graphics; virtual GPU, or vGPU, software for cloud-based visual and virtual computing; automotive platforms for infotainment systems; and Omniverse Enterprise software for building and operating metaverse and 3D internet applications. Our Markets We specialize in markets where our computing platforms can provide tremendous acceleration for applications. These platforms incorporate processors, interconnects, software, algorithms, systems, and services to deliver unique value. Our platforms address four large markets where our expertise is critical: Data Center, Gaming, Professional Visualization, and Automotive. Data Center The NVIDIA Data Center platform is focused on accelerating the most compute-intensive workloads, such as AI, data analytics, graphics and scientific computing, delivering significantly better performance and power efficiency relative to conventional CPU-only approaches. It is deployed in cloud, hyperscale, on-premises and edge data centers. The platform consists of compute and networking offerings typically delivered to customers as systems, subsystems, or modules, along with software and services. Our compute offerings include supercomputing platforms and servers, bringing together our energy efficient GPUs, DPUs, interconnects, and fully optimized AI and high-performance computing, or HPC, software stacks. In addition, they include NVIDIA AI Enterprise software; our DGX Cloud service; and a growing body of acceleration libraries, APIs, SDKs, and domain-specific application frameworks. Our networking offerings include end-to-end platforms for InfiniBand and Ethernet, consisting of network adapters, cables, DPUs, and switch systems, as well as a full software stack. This has enabled us to architect data center-scale computing platforms that can interconnect thousands of compute nodes with high-performance networking. While historically the server was the unit of computing, as AI and HPC workloads have become extremely large spanning thousands of compute nodes, the data center has become the new unit of computing, with networking as an integral part. Our end customers include the world&#8217;s leading public cloud and consumer internet companies, thousands of enterprises and startups, and public sector entities. We work with industry leaders to help build or transform their applications and data center infrastructure. Our direct customers include original equipment manufacturers, or OEMs, original device manufacturers, or ODMs, system integrators and distributors which we partner with to help bring our products to market. We also have partnerships in automotive, healthcare, financial services, manufacturing, and retail among others, to accelerate the adoption of AI. At the foundation of the NVIDIA accelerated computing platform are our GPUs, which excel at parallel workloads such as the training and inferencing of neural networks. They are available in the NVIDIA accelerated computing platform and in industry standard servers from every major cloud provider and server maker. Beyond GPUs, our data center platform expanded to include DPUs in fiscal year 2022 and CPUs in fiscal year 2024. We can optimize across the entire computing, networking and storage stack to deliver data center-scale computing solutions. While our approach starts with powerful chips, what makes it a full-stack computing platform is our large body of software, including the CUDA parallel programming model, the CUDA-X collection of acceleration libraries, APIs, SDKs, and domain-specific application frameworks. In addition to software delivered to customers as an integral part of our data center computing platform, we offer paid licenses to NVIDIA AI Enterprise, a comprehensive suite of enterprise-grade AI software and NVIDIA vGPU software for graphics-rich virtual desktops and workstations. In fiscal year 2024, we launched the NVIDIA DGX Cloud, an AI-training-as-a-service platform which includes cloud-based infrastructure and software for AI, customizable pretrained AI models, and access to NVIDIA experts. We have partnered with leading cloud service providers to host this service in their data centers. Gaming Gaming is the largest entertainment industry, with PC gaming as the predominant platform. Many factors propel its growth, including new high production value games and franchises, the continued rise of competitive gaming, or eSports, social connectivity and the increasing popularity of game streamers, modders, or gamers who remaster games, and creators. Our gaming platforms leverage our GPUs and sophisticated software to enhance the gaming experience with smoother, higher quality graphics. We developed NVIDIA RTX to bring next generation graphics and AI to games. NVIDIA RTX features ray tracing technology for real-time, cinematic-quality rendering. Ray tracing, which has long been used for special effects in the movie industry, is a computationally intensive technique that simulates the physical behavior of light to achieve greater realism in computer-generated scenes. NVIDIA RTX also features deep learning super sampling, or NVIDIA DLSS, our AI technology that boosts frame rates while generating beautiful, sharp images for games. RTX GPUs will also accelerate a new generation of AI applications. With an installed base of over 100 million AI capable PCs, more than 500 RTX AI-enabled applications and games, and a robust suite of development tools, RTX is already the AI PC leader. Our products for the gaming market include GeForce RTX and GeForce GTX GPUs for gaming desktop and laptop PCs, GeForce NOW cloud gaming for playing PC games on underpowered devices, as well as SoCs and development services for game consoles. Professional Visualization We serve the Professional Visualization market by working closely with independent software vendors, or ISVs, to optimize their offerings for NVIDIA GPUs. Our GPU computing platform enhances productivity and introduces new capabilities for critical workflows in many fields, such as design and manufacturing and digital content creation. ']",,
